2025-06-03 23:41:22,316 - INFO - ==================================================
2025-06-03 23:41:22,317 - INFO - CIFAR-100 训练开始
2025-06-03 23:41:22,317 - INFO - ==================================================
2025-06-03 23:41:22,317 - INFO - 所有输出将保存到: ./logs/mlp_mixer_tiny/20250603-234122
2025-06-03 23:41:22,318 - INFO - PyTorch版本: 2.7.0+cu126
2025-06-03 23:41:22,318 - INFO - CUDA版本: 12.6
2025-06-03 23:41:22,318 - INFO - 可用GPU数量: 8
2025-06-03 23:41:22,318 - INFO - 当前设备: 0
2025-06-03 23:41:22,319 - INFO - GPU内存: 15.8 GB
2025-06-03 23:41:22,319 - INFO - TrainingArguments: {
  "output_dir": "./logs",
  "overwrite_output_dir": false,
  "num_train_epochs": 300,
  "per_device_train_batch_size": 256,
  "per_device_eval_batch_size": 512,
  "learning_rate": 0.001,
  "weight_decay": 0.05,
  "adam_epsilon": 1e-08,
  "max_grad_norm": 1.0,
  "warmup_epochs": 10,
  "lr_scheduler_type": "cosine_annealing",
  "logging_steps": 50,
  "eval_strategy": "epoch",
  "save_strategy": "epoch",
  "save_steps": 20,
  "dataloader_num_workers": 4,
  "dataloader_pin_memory": true,
  "dataloader_drop_last": true,
  "label_smoothing_factor": 0.1,
  "use_mixup": true,
  "mixup_alpha": 0.2,
  "optimizer_type": "adamw",
  "use_imagenet_norm": false,
  "model_constructor_params": {
    "dropout": 0.3
  },
  "resume_from_checkpoint": null,
  "model_name_for_log": "mlp_mixer_tiny",
  "run_name": null,
  "checkpoint_filename_best": "best_model.pth",
  "checkpoint_filename_epoch": "checkpoint_epoch_{epoch}.pth",
  "evaluation_filename": "evaluation_summary.json",
  "plot_filename": "training_curves.png"
}
2025-06-03 23:41:22,319 - INFO - 分布式训练 (DDP): True, Rank: 0, World Size: 8
2025-06-03 23:41:22,319 - INFO - 使用设备: cuda:0
2025-06-03 23:41:22,368 - INFO - ***** 开始训练 *****
2025-06-03 23:41:22,368 - INFO -   训练模型: mlp_mixer_tiny, 运行: 20250603-234122
2025-06-03 23:41:22,368 - INFO -   训练样本数 = 50000, 每轮步骤数 = 24
2025-06-03 23:41:22,368 - INFO -   总轮数 = 300
2025-06-03 23:41:22,368 - INFO -   每设备批次大小 = 256
2025-06-03 23:41:22,368 - INFO -   总批次大小 (所有GPU) = 2048
2025-06-03 23:41:22,368 - INFO -   初始学习率 = 1.00e-03
2025-06-03 23:41:24,050 - INFO - Epoch 1/300 | Batch 0/24 | Loss: 4.6714 | Acc: 0.87% | LR: 1.00e-03
2025-06-03 23:41:26,453 - INFO - Epoch 1 TRAIN Summary: Avg Loss: 4.5912, Avg Acc: 2.10%, Duration: 4.08s
2025-06-03 23:41:26,942 - INFO - Epoch 1 EVAL  Summary: Avg Loss: 4.4891, Avg Acc: 3.54%, Duration: 0.49s
2025-06-03 23:41:27,057 - INFO - Epoch 1: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:27,058 - INFO - Epoch 1: 新的最佳准确率: 3.54% (已保存至 best_model.pth)
2025-06-03 23:41:27,501 - INFO - Epoch 2/300 | Batch 0/24 | Loss: 4.5405 | Acc: 3.52% | LR: 1.00e-03
2025-06-03 23:41:29,978 - INFO - Epoch 2 TRAIN Summary: Avg Loss: 4.4981, Avg Acc: 3.25%, Duration: 2.92s
2025-06-03 23:41:30,433 - INFO - Epoch 2 EVAL  Summary: Avg Loss: 4.3652, Avg Acc: 3.99%, Duration: 0.45s
2025-06-03 23:41:30,586 - INFO - Epoch 2: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:30,587 - INFO - Epoch 2: 新的最佳准确率: 3.99% (已保存至 best_model.pth)
2025-06-03 23:41:31,139 - INFO - Epoch 3/300 | Batch 0/24 | Loss: 4.5279 | Acc: 1.83% | LR: 1.00e-03
2025-06-03 23:41:33,546 - INFO - Epoch 3 TRAIN Summary: Avg Loss: 4.4492, Avg Acc: 3.76%, Duration: 2.96s
2025-06-03 23:41:34,042 - INFO - Epoch 3 EVAL  Summary: Avg Loss: 4.2805, Avg Acc: 5.69%, Duration: 0.49s
2025-06-03 23:41:34,182 - INFO - Epoch 3: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:34,182 - INFO - Epoch 3: 新的最佳准确率: 5.69% (已保存至 best_model.pth)
2025-06-03 23:41:34,725 - INFO - Epoch 4/300 | Batch 0/24 | Loss: 4.3987 | Acc: 1.56% | LR: 1.00e-03
2025-06-03 23:41:37,234 - INFO - Epoch 4 TRAIN Summary: Avg Loss: 4.3816, Avg Acc: 5.10%, Duration: 3.05s
2025-06-03 23:41:37,720 - INFO - Epoch 4 EVAL  Summary: Avg Loss: 4.2121, Avg Acc: 7.50%, Duration: 0.48s
2025-06-03 23:41:37,855 - INFO - Epoch 4: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:37,855 - INFO - Epoch 4: 新的最佳准确率: 7.50% (已保存至 best_model.pth)
2025-06-03 23:41:38,317 - INFO - Epoch 5/300 | Batch 0/24 | Loss: 4.5100 | Acc: 3.25% | LR: 1.00e-03
2025-06-03 23:41:40,754 - INFO - Epoch 5 TRAIN Summary: Avg Loss: 4.3369, Avg Acc: 5.91%, Duration: 2.90s
2025-06-03 23:41:41,301 - INFO - Epoch 5 EVAL  Summary: Avg Loss: 4.1460, Avg Acc: 8.70%, Duration: 0.54s
2025-06-03 23:41:41,431 - INFO - Epoch 5: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:41,431 - INFO - Epoch 5: 新的最佳准确率: 8.70% (已保存至 best_model.pth)
2025-06-03 23:41:41,964 - INFO - Epoch 6/300 | Batch 0/24 | Loss: 4.3100 | Acc: 7.03% | LR: 9.99e-04
2025-06-03 23:41:44,389 - INFO - Epoch 6 TRAIN Summary: Avg Loss: 4.3237, Avg Acc: 6.24%, Duration: 2.96s
2025-06-03 23:41:44,867 - INFO - Epoch 6 EVAL  Summary: Avg Loss: 4.0915, Avg Acc: 9.67%, Duration: 0.48s
2025-06-03 23:41:45,004 - INFO - Epoch 6: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:45,005 - INFO - Epoch 6: 新的最佳准确率: 9.67% (已保存至 best_model.pth)
2025-06-03 23:41:45,514 - INFO - Epoch 7/300 | Batch 0/24 | Loss: 4.3105 | Acc: 5.99% | LR: 9.99e-04
2025-06-03 23:41:47,970 - INFO - Epoch 7 TRAIN Summary: Avg Loss: 4.2761, Avg Acc: 6.91%, Duration: 2.96s
2025-06-03 23:41:48,475 - INFO - Epoch 7 EVAL  Summary: Avg Loss: 4.0335, Avg Acc: 10.90%, Duration: 0.50s
2025-06-03 23:41:48,698 - INFO - Epoch 7: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:48,699 - INFO - Epoch 7: 新的最佳准确率: 10.90% (已保存至 best_model.pth)
2025-06-03 23:41:49,240 - INFO - Epoch 8/300 | Batch 0/24 | Loss: 4.2384 | Acc: 7.42% | LR: 9.99e-04
2025-06-03 23:41:51,626 - INFO - Epoch 8 TRAIN Summary: Avg Loss: 4.2524, Avg Acc: 7.28%, Duration: 2.92s
2025-06-03 23:41:52,111 - INFO - Epoch 8 EVAL  Summary: Avg Loss: 3.9885, Avg Acc: 11.66%, Duration: 0.48s
2025-06-03 23:41:52,276 - INFO - Epoch 8: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:52,277 - INFO - Epoch 8: 新的最佳准确率: 11.66% (已保存至 best_model.pth)
2025-06-03 23:41:52,799 - INFO - Epoch 9/300 | Batch 0/24 | Loss: 4.1425 | Acc: 9.38% | LR: 9.98e-04
2025-06-03 23:41:55,437 - INFO - Epoch 9 TRAIN Summary: Avg Loss: 4.1793, Avg Acc: 8.63%, Duration: 3.16s
2025-06-03 23:41:55,926 - INFO - Epoch 9 EVAL  Summary: Avg Loss: 3.9517, Avg Acc: 12.07%, Duration: 0.49s
2025-06-03 23:41:56,127 - INFO - Epoch 9: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:56,128 - INFO - Epoch 9: 新的最佳准确率: 12.07% (已保存至 best_model.pth)
2025-06-03 23:41:56,670 - INFO - Epoch 10/300 | Batch 0/24 | Loss: 4.1625 | Acc: 9.77% | LR: 9.98e-04
2025-06-03 23:41:59,110 - INFO - Epoch 10 TRAIN Summary: Avg Loss: 4.1728, Avg Acc: 8.22%, Duration: 2.98s
2025-06-03 23:41:59,614 - INFO - Epoch 10 EVAL  Summary: Avg Loss: 3.9097, Avg Acc: 13.70%, Duration: 0.50s
2025-06-03 23:41:59,764 - INFO - Epoch 10: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:41:59,765 - INFO - Epoch 10: 新的最佳准确率: 13.70% (已保存至 best_model.pth)
2025-06-03 23:42:00,362 - INFO - Epoch 11/300 | Batch 0/24 | Loss: 4.0949 | Acc: 11.72% | LR: 9.97e-04
2025-06-03 23:42:02,805 - INFO - Epoch 11 TRAIN Summary: Avg Loss: 4.1598, Avg Acc: 9.12%, Duration: 3.04s
2025-06-03 23:42:03,294 - INFO - Epoch 11 EVAL  Summary: Avg Loss: 3.8701, Avg Acc: 14.18%, Duration: 0.49s
2025-06-03 23:42:03,457 - INFO - Epoch 11: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:03,458 - INFO - Epoch 11: 新的最佳准确率: 14.18% (已保存至 best_model.pth)
2025-06-03 23:42:03,982 - INFO - Epoch 12/300 | Batch 0/24 | Loss: 4.0738 | Acc: 13.67% | LR: 9.97e-04
2025-06-03 23:42:06,522 - INFO - Epoch 12 TRAIN Summary: Avg Loss: 4.1235, Avg Acc: 9.88%, Duration: 3.06s
2025-06-03 23:42:07,008 - INFO - Epoch 12 EVAL  Summary: Avg Loss: 3.8453, Avg Acc: 14.67%, Duration: 0.48s
2025-06-03 23:42:07,230 - INFO - Epoch 12: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:07,230 - INFO - Epoch 12: 新的最佳准确率: 14.67% (已保存至 best_model.pth)
2025-06-03 23:42:07,766 - INFO - Epoch 13/300 | Batch 0/24 | Loss: 4.2319 | Acc: 8.26% | LR: 9.96e-04
2025-06-03 23:42:11,151 - INFO - Epoch 13 TRAIN Summary: Avg Loss: 4.1097, Avg Acc: 10.00%, Duration: 3.92s
2025-06-03 23:42:11,677 - INFO - Epoch 13 EVAL  Summary: Avg Loss: 3.8089, Avg Acc: 15.72%, Duration: 0.52s
2025-06-03 23:42:11,810 - INFO - Epoch 13: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:11,811 - INFO - Epoch 13: 新的最佳准确率: 15.72% (已保存至 best_model.pth)
2025-06-03 23:42:12,241 - INFO - Epoch 14/300 | Batch 0/24 | Loss: 4.3327 | Acc: 9.78% | LR: 9.95e-04
2025-06-03 23:42:14,721 - INFO - Epoch 14 TRAIN Summary: Avg Loss: 4.1013, Avg Acc: 10.53%, Duration: 2.91s
2025-06-03 23:42:15,255 - INFO - Epoch 14 EVAL  Summary: Avg Loss: 3.7812, Avg Acc: 16.02%, Duration: 0.53s
2025-06-03 23:42:15,425 - INFO - Epoch 14: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:15,426 - INFO - Epoch 14: 新的最佳准确率: 16.02% (已保存至 best_model.pth)
2025-06-03 23:42:15,976 - INFO - Epoch 15/300 | Batch 0/24 | Loss: 4.0137 | Acc: 12.47% | LR: 9.95e-04
2025-06-03 23:42:18,377 - INFO - Epoch 15 TRAIN Summary: Avg Loss: 4.1018, Avg Acc: 10.29%, Duration: 2.95s
2025-06-03 23:42:18,891 - INFO - Epoch 15 EVAL  Summary: Avg Loss: 3.7477, Avg Acc: 16.77%, Duration: 0.51s
2025-06-03 23:42:19,038 - INFO - Epoch 15: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:19,039 - INFO - Epoch 15: 新的最佳准确率: 16.77% (已保存至 best_model.pth)
2025-06-03 23:42:19,554 - INFO - Epoch 16/300 | Batch 0/24 | Loss: 4.0286 | Acc: 12.11% | LR: 9.94e-04
2025-06-03 23:42:22,025 - INFO - Epoch 16 TRAIN Summary: Avg Loss: 4.0786, Avg Acc: 10.33%, Duration: 2.99s
2025-06-03 23:42:22,542 - INFO - Epoch 16 EVAL  Summary: Avg Loss: 3.7379, Avg Acc: 16.62%, Duration: 0.52s
2025-06-03 23:42:23,103 - INFO - Epoch 17/300 | Batch 0/24 | Loss: 4.0572 | Acc: 9.77% | LR: 9.93e-04
2025-06-03 23:42:25,584 - INFO - Epoch 17 TRAIN Summary: Avg Loss: 4.0656, Avg Acc: 10.74%, Duration: 3.04s
2025-06-03 23:42:26,102 - INFO - Epoch 17 EVAL  Summary: Avg Loss: 3.7109, Avg Acc: 16.79%, Duration: 0.52s
2025-06-03 23:42:26,235 - INFO - Epoch 17: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:26,235 - INFO - Epoch 17: 新的最佳准确率: 16.79% (已保存至 best_model.pth)
2025-06-03 23:42:26,684 - INFO - Epoch 18/300 | Batch 0/24 | Loss: 3.9607 | Acc: 11.71% | LR: 9.92e-04
2025-06-03 23:42:29,130 - INFO - Epoch 18 TRAIN Summary: Avg Loss: 4.0228, Avg Acc: 12.13%, Duration: 2.89s
2025-06-03 23:42:29,651 - INFO - Epoch 18 EVAL  Summary: Avg Loss: 3.6885, Avg Acc: 17.59%, Duration: 0.52s
2025-06-03 23:42:29,809 - INFO - Epoch 18: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:29,809 - INFO - Epoch 18: 新的最佳准确率: 17.59% (已保存至 best_model.pth)
2025-06-03 23:42:30,332 - INFO - Epoch 19/300 | Batch 0/24 | Loss: 4.0901 | Acc: 10.55% | LR: 9.91e-04
2025-06-03 23:42:32,831 - INFO - Epoch 19 TRAIN Summary: Avg Loss: 4.0106, Avg Acc: 11.80%, Duration: 3.02s
2025-06-03 23:42:33,334 - INFO - Epoch 19 EVAL  Summary: Avg Loss: 3.6619, Avg Acc: 18.11%, Duration: 0.50s
2025-06-03 23:42:33,476 - INFO - Epoch 19: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:33,476 - INFO - Epoch 19: 新的最佳准确率: 18.11% (已保存至 best_model.pth)
2025-06-03 23:42:33,991 - INFO - Epoch 20/300 | Batch 0/24 | Loss: 4.2367 | Acc: 8.55% | LR: 9.90e-04
2025-06-03 23:42:36,444 - INFO - Epoch 20 TRAIN Summary: Avg Loss: 4.0593, Avg Acc: 10.75%, Duration: 2.97s
2025-06-03 23:42:36,991 - INFO - Epoch 20 EVAL  Summary: Avg Loss: 3.6568, Avg Acc: 17.57%, Duration: 0.55s
2025-06-03 23:42:37,111 - INFO - Epoch 20: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_20.pth
2025-06-03 23:42:37,644 - INFO - Epoch 21/300 | Batch 0/24 | Loss: 3.9861 | Acc: 12.87% | LR: 9.89e-04
2025-06-03 23:42:40,029 - INFO - Epoch 21 TRAIN Summary: Avg Loss: 3.9855, Avg Acc: 12.37%, Duration: 2.92s
2025-06-03 23:42:40,511 - INFO - Epoch 21 EVAL  Summary: Avg Loss: 3.6189, Avg Acc: 19.21%, Duration: 0.48s
2025-06-03 23:42:40,693 - INFO - Epoch 21: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:40,693 - INFO - Epoch 21: 新的最佳准确率: 19.21% (已保存至 best_model.pth)
2025-06-03 23:42:41,191 - INFO - Epoch 22/300 | Batch 0/24 | Loss: 3.9932 | Acc: 15.55% | LR: 9.88e-04
2025-06-03 23:42:43,614 - INFO - Epoch 22 TRAIN Summary: Avg Loss: 3.9864, Avg Acc: 13.24%, Duration: 2.92s
2025-06-03 23:42:44,101 - INFO - Epoch 22 EVAL  Summary: Avg Loss: 3.6138, Avg Acc: 18.92%, Duration: 0.48s
2025-06-03 23:42:44,688 - INFO - Epoch 23/300 | Batch 0/24 | Loss: 4.0800 | Acc: 11.98% | LR: 9.87e-04
2025-06-03 23:42:47,167 - INFO - Epoch 23 TRAIN Summary: Avg Loss: 4.0185, Avg Acc: 11.98%, Duration: 3.07s
2025-06-03 23:42:47,656 - INFO - Epoch 23 EVAL  Summary: Avg Loss: 3.5842, Avg Acc: 20.06%, Duration: 0.49s
2025-06-03 23:42:47,784 - INFO - Epoch 23: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:47,784 - INFO - Epoch 23: 新的最佳准确率: 20.06% (已保存至 best_model.pth)
2025-06-03 23:42:48,277 - INFO - Epoch 24/300 | Batch 0/24 | Loss: 3.8945 | Acc: 11.33% | LR: 9.86e-04
2025-06-03 23:42:50,662 - INFO - Epoch 24 TRAIN Summary: Avg Loss: 3.9772, Avg Acc: 13.14%, Duration: 2.88s
2025-06-03 23:42:51,192 - INFO - Epoch 24 EVAL  Summary: Avg Loss: 3.5794, Avg Acc: 19.76%, Duration: 0.53s
2025-06-03 23:42:51,754 - INFO - Epoch 25/300 | Batch 0/24 | Loss: 3.9570 | Acc: 13.67% | LR: 9.84e-04
2025-06-03 23:42:54,185 - INFO - Epoch 25 TRAIN Summary: Avg Loss: 3.9507, Avg Acc: 12.99%, Duration: 2.99s
2025-06-03 23:42:54,692 - INFO - Epoch 25 EVAL  Summary: Avg Loss: 3.5694, Avg Acc: 20.01%, Duration: 0.50s
2025-06-03 23:42:55,235 - INFO - Epoch 26/300 | Batch 0/24 | Loss: 4.0161 | Acc: 10.94% | LR: 9.83e-04
2025-06-03 23:42:57,662 - INFO - Epoch 26 TRAIN Summary: Avg Loss: 3.9581, Avg Acc: 12.75%, Duration: 2.97s
2025-06-03 23:42:58,187 - INFO - Epoch 26 EVAL  Summary: Avg Loss: 3.5413, Avg Acc: 20.81%, Duration: 0.52s
2025-06-03 23:42:58,318 - INFO - Epoch 26: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:42:58,319 - INFO - Epoch 26: 新的最佳准确率: 20.81% (已保存至 best_model.pth)
2025-06-03 23:42:58,826 - INFO - Epoch 27/300 | Batch 0/24 | Loss: 3.8645 | Acc: 14.34% | LR: 9.82e-04
2025-06-03 23:43:01,268 - INFO - Epoch 27 TRAIN Summary: Avg Loss: 3.8843, Avg Acc: 14.35%, Duration: 2.95s
2025-06-03 23:43:01,762 - INFO - Epoch 27 EVAL  Summary: Avg Loss: 3.5264, Avg Acc: 21.28%, Duration: 0.49s
2025-06-03 23:43:01,995 - INFO - Epoch 27: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:01,996 - INFO - Epoch 27: 新的最佳准确率: 21.28% (已保存至 best_model.pth)
2025-06-03 23:43:02,467 - INFO - Epoch 28/300 | Batch 0/24 | Loss: 3.8785 | Acc: 12.89% | LR: 9.80e-04
2025-06-03 23:43:04,901 - INFO - Epoch 28 TRAIN Summary: Avg Loss: 3.9539, Avg Acc: 13.67%, Duration: 2.90s
2025-06-03 23:43:05,367 - INFO - Epoch 28 EVAL  Summary: Avg Loss: 3.5255, Avg Acc: 21.34%, Duration: 0.46s
2025-06-03 23:43:05,507 - INFO - Epoch 28: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:05,507 - INFO - Epoch 28: 新的最佳准确率: 21.34% (已保存至 best_model.pth)
2025-06-03 23:43:06,018 - INFO - Epoch 29/300 | Batch 0/24 | Loss: 3.7741 | Acc: 17.19% | LR: 9.79e-04
2025-06-03 23:43:08,435 - INFO - Epoch 29 TRAIN Summary: Avg Loss: 3.9566, Avg Acc: 13.29%, Duration: 2.93s
2025-06-03 23:43:08,939 - INFO - Epoch 29 EVAL  Summary: Avg Loss: 3.5022, Avg Acc: 21.53%, Duration: 0.50s
2025-06-03 23:43:09,073 - INFO - Epoch 29: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:09,074 - INFO - Epoch 29: 新的最佳准确率: 21.53% (已保存至 best_model.pth)
2025-06-03 23:43:09,604 - INFO - Epoch 30/300 | Batch 0/24 | Loss: 3.7683 | Acc: 13.28% | LR: 9.77e-04
2025-06-03 23:43:12,113 - INFO - Epoch 30 TRAIN Summary: Avg Loss: 3.8803, Avg Acc: 14.50%, Duration: 3.04s
2025-06-03 23:43:12,591 - INFO - Epoch 30 EVAL  Summary: Avg Loss: 3.4866, Avg Acc: 22.24%, Duration: 0.47s
2025-06-03 23:43:12,730 - INFO - Epoch 30: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:12,731 - INFO - Epoch 30: 新的最佳准确率: 22.24% (已保存至 best_model.pth)
2025-06-03 23:43:13,261 - INFO - Epoch 31/300 | Batch 0/24 | Loss: 3.7771 | Acc: 18.75% | LR: 9.76e-04
2025-06-03 23:43:15,718 - INFO - Epoch 31 TRAIN Summary: Avg Loss: 3.8822, Avg Acc: 14.36%, Duration: 2.99s
2025-06-03 23:43:16,200 - INFO - Epoch 31 EVAL  Summary: Avg Loss: 3.4926, Avg Acc: 22.05%, Duration: 0.48s
2025-06-03 23:43:16,765 - INFO - Epoch 32/300 | Batch 0/24 | Loss: 4.0229 | Acc: 13.04% | LR: 9.74e-04
2025-06-03 23:43:19,248 - INFO - Epoch 32 TRAIN Summary: Avg Loss: 3.8574, Avg Acc: 14.85%, Duration: 3.05s
2025-06-03 23:43:19,744 - INFO - Epoch 32 EVAL  Summary: Avg Loss: 3.4692, Avg Acc: 22.29%, Duration: 0.49s
2025-06-03 23:43:19,895 - INFO - Epoch 32: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:19,895 - INFO - Epoch 32: 新的最佳准确率: 22.29% (已保存至 best_model.pth)
2025-06-03 23:43:20,394 - INFO - Epoch 33/300 | Batch 0/24 | Loss: 3.7601 | Acc: 16.41% | LR: 9.72e-04
2025-06-03 23:43:22,912 - INFO - Epoch 33 TRAIN Summary: Avg Loss: 3.9100, Avg Acc: 14.53%, Duration: 3.02s
2025-06-03 23:43:23,439 - INFO - Epoch 33 EVAL  Summary: Avg Loss: 3.4562, Avg Acc: 22.79%, Duration: 0.52s
2025-06-03 23:43:23,588 - INFO - Epoch 33: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:23,589 - INFO - Epoch 33: 新的最佳准确率: 22.79% (已保存至 best_model.pth)
2025-06-03 23:43:24,119 - INFO - Epoch 34/300 | Batch 0/24 | Loss: 3.8377 | Acc: 17.19% | LR: 9.70e-04
2025-06-03 23:43:26,552 - INFO - Epoch 34 TRAIN Summary: Avg Loss: 3.8466, Avg Acc: 15.96%, Duration: 2.96s
2025-06-03 23:43:27,041 - INFO - Epoch 34 EVAL  Summary: Avg Loss: 3.4407, Avg Acc: 22.91%, Duration: 0.49s
2025-06-03 23:43:27,228 - INFO - Epoch 34: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:27,229 - INFO - Epoch 34: 新的最佳准确率: 22.91% (已保存至 best_model.pth)
2025-06-03 23:43:27,775 - INFO - Epoch 35/300 | Batch 0/24 | Loss: 3.8204 | Acc: 14.45% | LR: 9.69e-04
2025-06-03 23:43:30,164 - INFO - Epoch 35 TRAIN Summary: Avg Loss: 3.9042, Avg Acc: 14.51%, Duration: 2.93s
2025-06-03 23:43:30,676 - INFO - Epoch 35 EVAL  Summary: Avg Loss: 3.4322, Avg Acc: 23.30%, Duration: 0.51s
2025-06-03 23:43:30,816 - INFO - Epoch 35: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:30,816 - INFO - Epoch 35: 新的最佳准确率: 23.30% (已保存至 best_model.pth)
2025-06-03 23:43:31,352 - INFO - Epoch 36/300 | Batch 0/24 | Loss: 3.7094 | Acc: 17.08% | LR: 9.67e-04
2025-06-03 23:43:33,794 - INFO - Epoch 36 TRAIN Summary: Avg Loss: 3.8756, Avg Acc: 14.42%, Duration: 2.98s
2025-06-03 23:43:34,289 - INFO - Epoch 36 EVAL  Summary: Avg Loss: 3.4226, Avg Acc: 23.59%, Duration: 0.49s
2025-06-03 23:43:34,460 - INFO - Epoch 36: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:34,461 - INFO - Epoch 36: 新的最佳准确率: 23.59% (已保存至 best_model.pth)
2025-06-03 23:43:35,000 - INFO - Epoch 37/300 | Batch 0/24 | Loss: 3.7379 | Acc: 14.44% | LR: 9.65e-04
2025-06-03 23:43:37,404 - INFO - Epoch 37 TRAIN Summary: Avg Loss: 3.8034, Avg Acc: 16.10%, Duration: 2.94s
2025-06-03 23:43:37,912 - INFO - Epoch 37 EVAL  Summary: Avg Loss: 3.4286, Avg Acc: 23.09%, Duration: 0.51s
2025-06-03 23:43:38,454 - INFO - Epoch 38/300 | Batch 0/24 | Loss: 3.7801 | Acc: 17.95% | LR: 9.63e-04
2025-06-03 23:43:40,916 - INFO - Epoch 38 TRAIN Summary: Avg Loss: 3.8702, Avg Acc: 15.14%, Duration: 3.00s
2025-06-03 23:43:41,418 - INFO - Epoch 38 EVAL  Summary: Avg Loss: 3.4103, Avg Acc: 23.89%, Duration: 0.50s
2025-06-03 23:43:41,567 - INFO - Epoch 38: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:41,567 - INFO - Epoch 38: 新的最佳准确率: 23.89% (已保存至 best_model.pth)
2025-06-03 23:43:42,125 - INFO - Epoch 39/300 | Batch 0/24 | Loss: 4.0736 | Acc: 13.35% | LR: 9.61e-04
2025-06-03 23:43:44,601 - INFO - Epoch 39 TRAIN Summary: Avg Loss: 3.8272, Avg Acc: 16.17%, Duration: 3.03s
2025-06-03 23:43:45,101 - INFO - Epoch 39 EVAL  Summary: Avg Loss: 3.3897, Avg Acc: 24.10%, Duration: 0.50s
2025-06-03 23:43:45,248 - INFO - Epoch 39: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:45,249 - INFO - Epoch 39: 新的最佳准确率: 24.10% (已保存至 best_model.pth)
2025-06-03 23:43:45,740 - INFO - Epoch 40/300 | Batch 0/24 | Loss: 3.8437 | Acc: 13.28% | LR: 9.59e-04
2025-06-03 23:43:48,224 - INFO - Epoch 40 TRAIN Summary: Avg Loss: 3.8244, Avg Acc: 15.92%, Duration: 2.97s
2025-06-03 23:43:48,723 - INFO - Epoch 40 EVAL  Summary: Avg Loss: 3.3966, Avg Acc: 24.06%, Duration: 0.50s
2025-06-03 23:43:48,832 - INFO - Epoch 40: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_40.pth
2025-06-03 23:43:49,381 - INFO - Epoch 41/300 | Batch 0/24 | Loss: 3.7731 | Acc: 15.23% | LR: 9.57e-04
2025-06-03 23:43:51,875 - INFO - Epoch 41 TRAIN Summary: Avg Loss: 3.8161, Avg Acc: 15.52%, Duration: 3.04s
2025-06-03 23:43:52,399 - INFO - Epoch 41 EVAL  Summary: Avg Loss: 3.3653, Avg Acc: 24.63%, Duration: 0.52s
2025-06-03 23:43:52,550 - INFO - Epoch 41: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:52,550 - INFO - Epoch 41: 新的最佳准确率: 24.63% (已保存至 best_model.pth)
2025-06-03 23:43:53,047 - INFO - Epoch 42/300 | Batch 0/24 | Loss: 3.8326 | Acc: 15.97% | LR: 9.55e-04
2025-06-03 23:43:55,489 - INFO - Epoch 42 TRAIN Summary: Avg Loss: 3.7293, Avg Acc: 17.50%, Duration: 2.94s
2025-06-03 23:43:55,988 - INFO - Epoch 42 EVAL  Summary: Avg Loss: 3.3475, Avg Acc: 25.64%, Duration: 0.50s
2025-06-03 23:43:56,121 - INFO - Epoch 42: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:43:56,122 - INFO - Epoch 42: 新的最佳准确率: 25.64% (已保存至 best_model.pth)
2025-06-03 23:43:56,644 - INFO - Epoch 43/300 | Batch 0/24 | Loss: 4.3598 | Acc: 5.48% | LR: 9.52e-04
2025-06-03 23:43:59,405 - INFO - Epoch 43 TRAIN Summary: Avg Loss: 3.7912, Avg Acc: 16.10%, Duration: 3.28s
2025-06-03 23:43:59,908 - INFO - Epoch 43 EVAL  Summary: Avg Loss: 3.3461, Avg Acc: 25.63%, Duration: 0.50s
2025-06-03 23:44:00,487 - INFO - Epoch 44/300 | Batch 0/24 | Loss: 3.9105 | Acc: 14.23% | LR: 9.50e-04
2025-06-03 23:44:02,995 - INFO - Epoch 44 TRAIN Summary: Avg Loss: 3.7697, Avg Acc: 17.45%, Duration: 3.08s
2025-06-03 23:44:03,532 - INFO - Epoch 44 EVAL  Summary: Avg Loss: 3.3426, Avg Acc: 25.56%, Duration: 0.53s
2025-06-03 23:44:04,096 - INFO - Epoch 45/300 | Batch 0/24 | Loss: 3.6549 | Acc: 16.41% | LR: 9.48e-04
2025-06-03 23:44:06,548 - INFO - Epoch 45 TRAIN Summary: Avg Loss: 3.8145, Avg Acc: 16.20%, Duration: 3.01s
2025-06-03 23:44:07,064 - INFO - Epoch 45 EVAL  Summary: Avg Loss: 3.3427, Avg Acc: 25.38%, Duration: 0.51s
2025-06-03 23:44:07,685 - INFO - Epoch 46/300 | Batch 0/24 | Loss: 3.6892 | Acc: 16.41% | LR: 9.46e-04
2025-06-03 23:44:10,136 - INFO - Epoch 46 TRAIN Summary: Avg Loss: 3.8068, Avg Acc: 16.06%, Duration: 3.07s
2025-06-03 23:44:10,629 - INFO - Epoch 46 EVAL  Summary: Avg Loss: 3.3200, Avg Acc: 26.01%, Duration: 0.49s
2025-06-03 23:44:10,783 - INFO - Epoch 46: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:10,783 - INFO - Epoch 46: 新的最佳准确率: 26.01% (已保存至 best_model.pth)
2025-06-03 23:44:11,340 - INFO - Epoch 47/300 | Batch 0/24 | Loss: 3.6917 | Acc: 20.31% | LR: 9.43e-04
2025-06-03 23:44:13,816 - INFO - Epoch 47 TRAIN Summary: Avg Loss: 3.8324, Avg Acc: 15.50%, Duration: 3.03s
2025-06-03 23:44:14,340 - INFO - Epoch 47 EVAL  Summary: Avg Loss: 3.3160, Avg Acc: 25.94%, Duration: 0.52s
2025-06-03 23:44:14,893 - INFO - Epoch 48/300 | Batch 0/24 | Loss: 3.6548 | Acc: 17.93% | LR: 9.41e-04
2025-06-03 23:44:17,393 - INFO - Epoch 48 TRAIN Summary: Avg Loss: 3.7763, Avg Acc: 17.03%, Duration: 3.05s
2025-06-03 23:44:17,866 - INFO - Epoch 48 EVAL  Summary: Avg Loss: 3.3259, Avg Acc: 25.53%, Duration: 0.47s
2025-06-03 23:44:18,448 - INFO - Epoch 49/300 | Batch 0/24 | Loss: 3.7352 | Acc: 17.58% | LR: 9.38e-04
2025-06-03 23:44:20,909 - INFO - Epoch 49 TRAIN Summary: Avg Loss: 3.7357, Avg Acc: 17.87%, Duration: 3.04s
2025-06-03 23:44:21,420 - INFO - Epoch 49 EVAL  Summary: Avg Loss: 3.3100, Avg Acc: 26.15%, Duration: 0.51s
2025-06-03 23:44:21,578 - INFO - Epoch 49: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:21,579 - INFO - Epoch 49: 新的最佳准确率: 26.15% (已保存至 best_model.pth)
2025-06-03 23:44:22,097 - INFO - Epoch 50/300 | Batch 0/24 | Loss: 3.6503 | Acc: 20.70% | LR: 9.36e-04
2025-06-03 23:44:24,591 - INFO - Epoch 50 TRAIN Summary: Avg Loss: 3.7683, Avg Acc: 17.22%, Duration: 3.01s
2025-06-03 23:44:25,133 - INFO - Epoch 50 EVAL  Summary: Avg Loss: 3.2949, Avg Acc: 26.30%, Duration: 0.54s
2025-06-03 23:44:25,267 - INFO - Epoch 50: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:25,267 - INFO - Epoch 50: 新的最佳准确率: 26.30% (已保存至 best_model.pth)
2025-06-03 23:44:25,782 - INFO - Epoch 51/300 | Batch 0/24 | Loss: 3.6625 | Acc: 19.14% | LR: 9.33e-04
2025-06-03 23:44:28,206 - INFO - Epoch 51 TRAIN Summary: Avg Loss: 3.8093, Avg Acc: 16.40%, Duration: 2.94s
2025-06-03 23:44:28,712 - INFO - Epoch 51 EVAL  Summary: Avg Loss: 3.2847, Avg Acc: 26.96%, Duration: 0.50s
2025-06-03 23:44:28,909 - INFO - Epoch 51: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:28,910 - INFO - Epoch 51: 新的最佳准确率: 26.96% (已保存至 best_model.pth)
2025-06-03 23:44:29,380 - INFO - Epoch 52/300 | Batch 0/24 | Loss: 3.5142 | Acc: 20.01% | LR: 9.30e-04
2025-06-03 23:44:31,852 - INFO - Epoch 52 TRAIN Summary: Avg Loss: 3.7536, Avg Acc: 17.88%, Duration: 2.94s
2025-06-03 23:44:32,367 - INFO - Epoch 52 EVAL  Summary: Avg Loss: 3.2762, Avg Acc: 27.14%, Duration: 0.51s
2025-06-03 23:44:32,504 - INFO - Epoch 52: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:32,505 - INFO - Epoch 52: 新的最佳准确率: 27.14% (已保存至 best_model.pth)
2025-06-03 23:44:33,000 - INFO - Epoch 53/300 | Batch 0/24 | Loss: 3.6450 | Acc: 18.25% | LR: 9.28e-04
2025-06-03 23:44:35,427 - INFO - Epoch 53 TRAIN Summary: Avg Loss: 3.7631, Avg Acc: 16.44%, Duration: 2.92s
2025-06-03 23:44:35,947 - INFO - Epoch 53 EVAL  Summary: Avg Loss: 3.2640, Avg Acc: 27.92%, Duration: 0.52s
2025-06-03 23:44:36,093 - INFO - Epoch 53: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:36,094 - INFO - Epoch 53: 新的最佳准确率: 27.92% (已保存至 best_model.pth)
2025-06-03 23:44:36,597 - INFO - Epoch 54/300 | Batch 0/24 | Loss: 3.7416 | Acc: 17.67% | LR: 9.25e-04
2025-06-03 23:44:39,125 - INFO - Epoch 54 TRAIN Summary: Avg Loss: 3.7606, Avg Acc: 17.37%, Duration: 3.03s
2025-06-03 23:44:39,634 - INFO - Epoch 54 EVAL  Summary: Avg Loss: 3.2712, Avg Acc: 27.23%, Duration: 0.51s
2025-06-03 23:44:40,173 - INFO - Epoch 55/300 | Batch 0/24 | Loss: 3.5512 | Acc: 18.75% | LR: 9.22e-04
2025-06-03 23:44:42,581 - INFO - Epoch 55 TRAIN Summary: Avg Loss: 3.6610, Avg Acc: 19.19%, Duration: 2.95s
2025-06-03 23:44:43,305 - INFO - Epoch 55 EVAL  Summary: Avg Loss: 3.2626, Avg Acc: 27.31%, Duration: 0.72s
2025-06-03 23:44:44,334 - INFO - Epoch 56/300 | Batch 0/24 | Loss: 3.6467 | Acc: 17.58% | LR: 9.19e-04
2025-06-03 23:44:47,594 - INFO - Epoch 56 TRAIN Summary: Avg Loss: 3.6891, Avg Acc: 17.80%, Duration: 4.29s
2025-06-03 23:44:48,141 - INFO - Epoch 56 EVAL  Summary: Avg Loss: 3.2453, Avg Acc: 28.20%, Duration: 0.54s
2025-06-03 23:44:48,295 - INFO - Epoch 56: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:44:48,296 - INFO - Epoch 56: 新的最佳准确率: 28.20% (已保存至 best_model.pth)
2025-06-03 23:44:48,899 - INFO - Epoch 57/300 | Batch 0/24 | Loss: 3.7323 | Acc: 19.53% | LR: 9.17e-04
2025-06-03 23:44:51,751 - INFO - Epoch 57 TRAIN Summary: Avg Loss: 3.7341, Avg Acc: 17.80%, Duration: 3.45s
2025-06-03 23:44:52,254 - INFO - Epoch 57 EVAL  Summary: Avg Loss: 3.2557, Avg Acc: 27.25%, Duration: 0.50s
2025-06-03 23:44:52,841 - INFO - Epoch 58/300 | Batch 0/24 | Loss: 3.5275 | Acc: 19.14% | LR: 9.14e-04
2025-06-03 23:44:55,318 - INFO - Epoch 58 TRAIN Summary: Avg Loss: 3.7117, Avg Acc: 18.48%, Duration: 3.06s
2025-06-03 23:44:55,856 - INFO - Epoch 58 EVAL  Summary: Avg Loss: 3.2310, Avg Acc: 28.05%, Duration: 0.54s
2025-06-03 23:44:56,431 - INFO - Epoch 59/300 | Batch 0/24 | Loss: 3.5257 | Acc: 21.48% | LR: 9.11e-04
2025-06-03 23:44:58,942 - INFO - Epoch 59 TRAIN Summary: Avg Loss: 3.7346, Avg Acc: 17.99%, Duration: 3.08s
2025-06-03 23:44:59,452 - INFO - Epoch 59 EVAL  Summary: Avg Loss: 3.2312, Avg Acc: 27.98%, Duration: 0.51s
2025-06-03 23:45:00,024 - INFO - Epoch 60/300 | Batch 0/24 | Loss: 4.0709 | Acc: 14.99% | LR: 9.08e-04
2025-06-03 23:45:02,482 - INFO - Epoch 60 TRAIN Summary: Avg Loss: 3.7252, Avg Acc: 18.45%, Duration: 3.03s
2025-06-03 23:45:03,017 - INFO - Epoch 60 EVAL  Summary: Avg Loss: 3.2204, Avg Acc: 28.25%, Duration: 0.53s
2025-06-03 23:45:03,159 - INFO - Epoch 60: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:03,159 - INFO - Epoch 60: 新的最佳准确率: 28.25% (已保存至 best_model.pth)
2025-06-03 23:45:03,287 - INFO - Epoch 60: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_60.pth
2025-06-03 23:45:03,809 - INFO - Epoch 61/300 | Batch 0/24 | Loss: 3.8386 | Acc: 18.02% | LR: 9.05e-04
2025-06-03 23:45:06,250 - INFO - Epoch 61 TRAIN Summary: Avg Loss: 3.6982, Avg Acc: 18.10%, Duration: 2.96s
2025-06-03 23:45:06,743 - INFO - Epoch 61 EVAL  Summary: Avg Loss: 3.2167, Avg Acc: 28.09%, Duration: 0.49s
2025-06-03 23:45:07,333 - INFO - Epoch 62/300 | Batch 0/24 | Loss: 3.4642 | Acc: 22.66% | LR: 9.02e-04
2025-06-03 23:45:09,795 - INFO - Epoch 62 TRAIN Summary: Avg Loss: 3.6971, Avg Acc: 18.99%, Duration: 3.05s
2025-06-03 23:45:10,302 - INFO - Epoch 62 EVAL  Summary: Avg Loss: 3.2023, Avg Acc: 28.86%, Duration: 0.50s
2025-06-03 23:45:10,495 - INFO - Epoch 62: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:10,495 - INFO - Epoch 62: 新的最佳准确率: 28.86% (已保存至 best_model.pth)
2025-06-03 23:45:11,053 - INFO - Epoch 63/300 | Batch 0/24 | Loss: 3.5663 | Acc: 22.17% | LR: 8.98e-04
2025-06-03 23:45:13,520 - INFO - Epoch 63 TRAIN Summary: Avg Loss: 3.6772, Avg Acc: 18.90%, Duration: 3.02s
2025-06-03 23:45:14,031 - INFO - Epoch 63 EVAL  Summary: Avg Loss: 3.1996, Avg Acc: 28.97%, Duration: 0.51s
2025-06-03 23:45:14,168 - INFO - Epoch 63: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:14,168 - INFO - Epoch 63: 新的最佳准确率: 28.97% (已保存至 best_model.pth)
2025-06-03 23:45:14,739 - INFO - Epoch 64/300 | Batch 0/24 | Loss: 3.9338 | Acc: 13.74% | LR: 8.95e-04
2025-06-03 23:45:17,172 - INFO - Epoch 64 TRAIN Summary: Avg Loss: 3.7479, Avg Acc: 17.50%, Duration: 3.00s
2025-06-03 23:45:17,696 - INFO - Epoch 64 EVAL  Summary: Avg Loss: 3.1816, Avg Acc: 29.12%, Duration: 0.52s
2025-06-03 23:45:17,845 - INFO - Epoch 64: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:17,846 - INFO - Epoch 64: 新的最佳准确率: 29.12% (已保存至 best_model.pth)
2025-06-03 23:45:18,414 - INFO - Epoch 65/300 | Batch 0/24 | Loss: 3.7132 | Acc: 17.58% | LR: 8.92e-04
2025-06-03 23:45:20,853 - INFO - Epoch 65 TRAIN Summary: Avg Loss: 3.6191, Avg Acc: 20.35%, Duration: 3.01s
2025-06-03 23:45:21,373 - INFO - Epoch 65 EVAL  Summary: Avg Loss: 3.2001, Avg Acc: 29.09%, Duration: 0.52s
2025-06-03 23:45:21,939 - INFO - Epoch 66/300 | Batch 0/24 | Loss: 3.5863 | Acc: 22.66% | LR: 8.89e-04
2025-06-03 23:45:24,480 - INFO - Epoch 66 TRAIN Summary: Avg Loss: 3.7219, Avg Acc: 18.53%, Duration: 3.11s
2025-06-03 23:45:24,985 - INFO - Epoch 66 EVAL  Summary: Avg Loss: 3.1647, Avg Acc: 29.82%, Duration: 0.50s
2025-06-03 23:45:25,154 - INFO - Epoch 66: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:25,154 - INFO - Epoch 66: 新的最佳准确率: 29.82% (已保存至 best_model.pth)
2025-06-03 23:45:25,700 - INFO - Epoch 67/300 | Batch 0/24 | Loss: 4.3444 | Acc: 8.37% | LR: 8.85e-04
2025-06-03 23:45:28,149 - INFO - Epoch 67 TRAIN Summary: Avg Loss: 3.6723, Avg Acc: 19.15%, Duration: 2.99s
2025-06-03 23:45:28,669 - INFO - Epoch 67 EVAL  Summary: Avg Loss: 3.1685, Avg Acc: 29.23%, Duration: 0.52s
2025-06-03 23:45:29,231 - INFO - Epoch 68/300 | Batch 0/24 | Loss: 3.6876 | Acc: 18.56% | LR: 8.82e-04
2025-06-03 23:45:31,712 - INFO - Epoch 68 TRAIN Summary: Avg Loss: 3.6227, Avg Acc: 20.29%, Duration: 3.04s
2025-06-03 23:45:32,207 - INFO - Epoch 68 EVAL  Summary: Avg Loss: 3.1505, Avg Acc: 30.04%, Duration: 0.49s
2025-06-03 23:45:32,360 - INFO - Epoch 68: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:32,361 - INFO - Epoch 68: 新的最佳准确率: 30.04% (已保存至 best_model.pth)
2025-06-03 23:45:32,944 - INFO - Epoch 69/300 | Batch 0/24 | Loss: 4.3538 | Acc: 7.84% | LR: 8.79e-04
2025-06-03 23:45:35,451 - INFO - Epoch 69 TRAIN Summary: Avg Loss: 3.6570, Avg Acc: 19.37%, Duration: 3.09s
2025-06-03 23:45:35,979 - INFO - Epoch 69 EVAL  Summary: Avg Loss: 3.1438, Avg Acc: 30.27%, Duration: 0.53s
2025-06-03 23:45:36,139 - INFO - Epoch 69: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:36,140 - INFO - Epoch 69: 新的最佳准确率: 30.27% (已保存至 best_model.pth)
2025-06-03 23:45:36,674 - INFO - Epoch 70/300 | Batch 0/24 | Loss: 3.5127 | Acc: 19.92% | LR: 8.75e-04
2025-06-03 23:45:39,095 - INFO - Epoch 70 TRAIN Summary: Avg Loss: 3.6847, Avg Acc: 19.18%, Duration: 2.95s
2025-06-03 23:45:39,603 - INFO - Epoch 70 EVAL  Summary: Avg Loss: 3.1453, Avg Acc: 29.99%, Duration: 0.51s
2025-06-03 23:45:40,175 - INFO - Epoch 71/300 | Batch 0/24 | Loss: 3.4700 | Acc: 20.70% | LR: 8.72e-04
2025-06-03 23:45:42,646 - INFO - Epoch 71 TRAIN Summary: Avg Loss: 3.6295, Avg Acc: 20.01%, Duration: 3.04s
2025-06-03 23:45:43,136 - INFO - Epoch 71 EVAL  Summary: Avg Loss: 3.1648, Avg Acc: 29.62%, Duration: 0.49s
2025-06-03 23:45:43,705 - INFO - Epoch 72/300 | Batch 0/24 | Loss: 3.4261 | Acc: 25.00% | LR: 8.68e-04
2025-06-03 23:45:46,136 - INFO - Epoch 72 TRAIN Summary: Avg Loss: 3.5653, Avg Acc: 21.27%, Duration: 3.00s
2025-06-03 23:45:46,650 - INFO - Epoch 72 EVAL  Summary: Avg Loss: 3.1534, Avg Acc: 29.88%, Duration: 0.51s
2025-06-03 23:45:47,215 - INFO - Epoch 73/300 | Batch 0/24 | Loss: 3.3841 | Acc: 21.88% | LR: 8.65e-04
2025-06-03 23:45:49,685 - INFO - Epoch 73 TRAIN Summary: Avg Loss: 3.6325, Avg Acc: 19.73%, Duration: 3.03s
2025-06-03 23:45:50,187 - INFO - Epoch 73 EVAL  Summary: Avg Loss: 3.1424, Avg Acc: 29.98%, Duration: 0.50s
2025-06-03 23:45:50,771 - INFO - Epoch 74/300 | Batch 0/24 | Loss: 3.4803 | Acc: 24.22% | LR: 8.61e-04
2025-06-03 23:45:53,186 - INFO - Epoch 74 TRAIN Summary: Avg Loss: 3.6513, Avg Acc: 18.95%, Duration: 3.00s
2025-06-03 23:45:53,689 - INFO - Epoch 74 EVAL  Summary: Avg Loss: 3.1357, Avg Acc: 30.69%, Duration: 0.50s
2025-06-03 23:45:53,900 - INFO - Epoch 74: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:53,901 - INFO - Epoch 74: 新的最佳准确率: 30.69% (已保存至 best_model.pth)
2025-06-03 23:45:54,465 - INFO - Epoch 75/300 | Batch 0/24 | Loss: 3.6803 | Acc: 19.14% | LR: 8.57e-04
2025-06-03 23:45:56,890 - INFO - Epoch 75 TRAIN Summary: Avg Loss: 3.6478, Avg Acc: 19.83%, Duration: 2.99s
2025-06-03 23:45:57,384 - INFO - Epoch 75 EVAL  Summary: Avg Loss: 3.1147, Avg Acc: 30.85%, Duration: 0.49s
2025-06-03 23:45:57,543 - INFO - Epoch 75: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:45:57,544 - INFO - Epoch 75: 新的最佳准确率: 30.85% (已保存至 best_model.pth)
2025-06-03 23:45:57,999 - INFO - Epoch 76/300 | Batch 0/24 | Loss: 3.5626 | Acc: 20.93% | LR: 8.54e-04
2025-06-03 23:46:00,482 - INFO - Epoch 76 TRAIN Summary: Avg Loss: 3.6180, Avg Acc: 20.18%, Duration: 2.94s
2025-06-03 23:46:00,988 - INFO - Epoch 76 EVAL  Summary: Avg Loss: 3.1088, Avg Acc: 31.30%, Duration: 0.50s
2025-06-03 23:46:01,156 - INFO - Epoch 76: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:01,156 - INFO - Epoch 76: 新的最佳准确率: 31.30% (已保存至 best_model.pth)
2025-06-03 23:46:01,726 - INFO - Epoch 77/300 | Batch 0/24 | Loss: 3.5578 | Acc: 22.66% | LR: 8.50e-04
2025-06-03 23:46:04,192 - INFO - Epoch 77 TRAIN Summary: Avg Loss: 3.6057, Avg Acc: 19.87%, Duration: 3.03s
2025-06-03 23:46:04,719 - INFO - Epoch 77 EVAL  Summary: Avg Loss: 3.1025, Avg Acc: 31.08%, Duration: 0.52s
2025-06-03 23:46:05,315 - INFO - Epoch 78/300 | Batch 0/24 | Loss: 3.9517 | Acc: 17.50% | LR: 8.46e-04
2025-06-03 23:46:07,773 - INFO - Epoch 78 TRAIN Summary: Avg Loss: 3.5971, Avg Acc: 20.57%, Duration: 3.05s
2025-06-03 23:46:08,294 - INFO - Epoch 78 EVAL  Summary: Avg Loss: 3.1173, Avg Acc: 30.61%, Duration: 0.52s
2025-06-03 23:46:08,872 - INFO - Epoch 79/300 | Batch 0/24 | Loss: 3.5114 | Acc: 21.09% | LR: 8.42e-04
2025-06-03 23:46:11,344 - INFO - Epoch 79 TRAIN Summary: Avg Loss: 3.6216, Avg Acc: 20.04%, Duration: 3.05s
2025-06-03 23:46:11,840 - INFO - Epoch 79 EVAL  Summary: Avg Loss: 3.1001, Avg Acc: 31.44%, Duration: 0.49s
2025-06-03 23:46:12,000 - INFO - Epoch 79: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:12,001 - INFO - Epoch 79: 新的最佳准确率: 31.44% (已保存至 best_model.pth)
2025-06-03 23:46:12,574 - INFO - Epoch 80/300 | Batch 0/24 | Loss: 3.5534 | Acc: 22.27% | LR: 8.39e-04
2025-06-03 23:46:15,012 - INFO - Epoch 80 TRAIN Summary: Avg Loss: 3.5771, Avg Acc: 20.59%, Duration: 3.01s
2025-06-03 23:46:15,521 - INFO - Epoch 80 EVAL  Summary: Avg Loss: 3.1066, Avg Acc: 31.23%, Duration: 0.51s
2025-06-03 23:46:15,662 - INFO - Epoch 80: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_80.pth
2025-06-03 23:46:16,231 - INFO - Epoch 81/300 | Batch 0/24 | Loss: 3.5841 | Acc: 21.62% | LR: 8.35e-04
2025-06-03 23:46:18,623 - INFO - Epoch 81 TRAIN Summary: Avg Loss: 3.5672, Avg Acc: 21.00%, Duration: 2.96s
2025-06-03 23:46:19,178 - INFO - Epoch 81 EVAL  Summary: Avg Loss: 3.0725, Avg Acc: 31.79%, Duration: 0.55s
2025-06-03 23:46:19,320 - INFO - Epoch 81: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:19,321 - INFO - Epoch 81: 新的最佳准确率: 31.79% (已保存至 best_model.pth)
2025-06-03 23:46:19,876 - INFO - Epoch 82/300 | Batch 0/24 | Loss: 3.4430 | Acc: 24.61% | LR: 8.31e-04
2025-06-03 23:46:22,543 - INFO - Epoch 82 TRAIN Summary: Avg Loss: 3.6486, Avg Acc: 20.28%, Duration: 3.22s
2025-06-03 23:46:23,028 - INFO - Epoch 82 EVAL  Summary: Avg Loss: 3.0854, Avg Acc: 31.76%, Duration: 0.48s
2025-06-03 23:46:23,580 - INFO - Epoch 83/300 | Batch 0/24 | Loss: 3.4459 | Acc: 23.05% | LR: 8.27e-04
2025-06-03 23:46:26,032 - INFO - Epoch 83 TRAIN Summary: Avg Loss: 3.6617, Avg Acc: 19.93%, Duration: 3.00s
2025-06-03 23:46:26,536 - INFO - Epoch 83 EVAL  Summary: Avg Loss: 3.0667, Avg Acc: 31.51%, Duration: 0.50s
2025-06-03 23:46:27,129 - INFO - Epoch 84/300 | Batch 0/24 | Loss: 3.5668 | Acc: 20.31% | LR: 8.23e-04
2025-06-03 23:46:29,578 - INFO - Epoch 84 TRAIN Summary: Avg Loss: 3.5288, Avg Acc: 22.52%, Duration: 3.04s
2025-06-03 23:46:30,076 - INFO - Epoch 84 EVAL  Summary: Avg Loss: 3.0753, Avg Acc: 31.89%, Duration: 0.49s
2025-06-03 23:46:30,240 - INFO - Epoch 84: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:30,241 - INFO - Epoch 84: 新的最佳准确率: 31.89% (已保存至 best_model.pth)
2025-06-03 23:46:30,803 - INFO - Epoch 85/300 | Batch 0/24 | Loss: 3.3513 | Acc: 21.88% | LR: 8.19e-04
2025-06-03 23:46:33,244 - INFO - Epoch 85 TRAIN Summary: Avg Loss: 3.5006, Avg Acc: 22.04%, Duration: 3.00s
2025-06-03 23:46:33,750 - INFO - Epoch 85 EVAL  Summary: Avg Loss: 3.0736, Avg Acc: 31.87%, Duration: 0.50s
2025-06-03 23:46:34,315 - INFO - Epoch 86/300 | Batch 0/24 | Loss: 4.1394 | Acc: 13.83% | LR: 8.15e-04
2025-06-03 23:46:36,744 - INFO - Epoch 86 TRAIN Summary: Avg Loss: 3.5446, Avg Acc: 21.72%, Duration: 2.99s
2025-06-03 23:46:37,232 - INFO - Epoch 86 EVAL  Summary: Avg Loss: 3.0551, Avg Acc: 32.62%, Duration: 0.48s
2025-06-03 23:46:37,398 - INFO - Epoch 86: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:37,398 - INFO - Epoch 86: 新的最佳准确率: 32.62% (已保存至 best_model.pth)
2025-06-03 23:46:37,907 - INFO - Epoch 87/300 | Batch 0/24 | Loss: 3.4299 | Acc: 23.05% | LR: 8.11e-04
2025-06-03 23:46:40,442 - INFO - Epoch 87 TRAIN Summary: Avg Loss: 3.6632, Avg Acc: 19.74%, Duration: 3.04s
2025-06-03 23:46:40,947 - INFO - Epoch 87 EVAL  Summary: Avg Loss: 3.0522, Avg Acc: 32.38%, Duration: 0.50s
2025-06-03 23:46:41,522 - INFO - Epoch 88/300 | Batch 0/24 | Loss: 3.5069 | Acc: 21.09% | LR: 8.07e-04
2025-06-03 23:46:44,054 - INFO - Epoch 88 TRAIN Summary: Avg Loss: 3.6034, Avg Acc: 21.01%, Duration: 3.10s
2025-06-03 23:46:44,531 - INFO - Epoch 88 EVAL  Summary: Avg Loss: 3.0415, Avg Acc: 32.48%, Duration: 0.47s
2025-06-03 23:46:45,120 - INFO - Epoch 89/300 | Batch 0/24 | Loss: 4.1767 | Acc: 10.76% | LR: 8.02e-04
2025-06-03 23:46:47,557 - INFO - Epoch 89 TRAIN Summary: Avg Loss: 3.6314, Avg Acc: 20.97%, Duration: 3.02s
2025-06-03 23:46:48,082 - INFO - Epoch 89 EVAL  Summary: Avg Loss: 3.0558, Avg Acc: 32.08%, Duration: 0.52s
2025-06-03 23:46:48,674 - INFO - Epoch 90/300 | Batch 0/24 | Loss: 3.5408 | Acc: 24.22% | LR: 7.98e-04
2025-06-03 23:46:51,127 - INFO - Epoch 90 TRAIN Summary: Avg Loss: 3.5233, Avg Acc: 22.19%, Duration: 3.04s
2025-06-03 23:46:51,637 - INFO - Epoch 90 EVAL  Summary: Avg Loss: 3.0457, Avg Acc: 32.77%, Duration: 0.51s
2025-06-03 23:46:51,851 - INFO - Epoch 90: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:51,853 - INFO - Epoch 90: 新的最佳准确率: 32.77% (已保存至 best_model.pth)
2025-06-03 23:46:52,402 - INFO - Epoch 91/300 | Batch 0/24 | Loss: 3.5182 | Acc: 20.31% | LR: 7.94e-04
2025-06-03 23:46:54,822 - INFO - Epoch 91 TRAIN Summary: Avg Loss: 3.5184, Avg Acc: 21.99%, Duration: 2.97s
2025-06-03 23:46:55,310 - INFO - Epoch 91 EVAL  Summary: Avg Loss: 3.0294, Avg Acc: 33.25%, Duration: 0.49s
2025-06-03 23:46:55,456 - INFO - Epoch 91: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:46:55,457 - INFO - Epoch 91: 新的最佳准确率: 33.25% (已保存至 best_model.pth)
2025-06-03 23:46:56,011 - INFO - Epoch 92/300 | Batch 0/24 | Loss: 4.1532 | Acc: 13.73% | LR: 7.90e-04
2025-06-03 23:46:58,435 - INFO - Epoch 92 TRAIN Summary: Avg Loss: 3.5045, Avg Acc: 23.04%, Duration: 2.98s
2025-06-03 23:46:58,907 - INFO - Epoch 92 EVAL  Summary: Avg Loss: 3.0272, Avg Acc: 32.99%, Duration: 0.47s
2025-06-03 23:46:59,491 - INFO - Epoch 93/300 | Batch 0/24 | Loss: 3.3119 | Acc: 30.86% | LR: 7.86e-04
2025-06-03 23:47:01,907 - INFO - Epoch 93 TRAIN Summary: Avg Loss: 3.4964, Avg Acc: 22.45%, Duration: 3.00s
2025-06-03 23:47:02,417 - INFO - Epoch 93 EVAL  Summary: Avg Loss: 3.0083, Avg Acc: 33.41%, Duration: 0.51s
2025-06-03 23:47:02,551 - INFO - Epoch 93: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:02,551 - INFO - Epoch 93: 新的最佳准确率: 33.41% (已保存至 best_model.pth)
2025-06-03 23:47:03,097 - INFO - Epoch 94/300 | Batch 0/24 | Loss: 4.1556 | Acc: 10.60% | LR: 7.81e-04
2025-06-03 23:47:05,575 - INFO - Epoch 94 TRAIN Summary: Avg Loss: 3.5087, Avg Acc: 23.08%, Duration: 3.02s
2025-06-03 23:47:06,108 - INFO - Epoch 94 EVAL  Summary: Avg Loss: 3.0250, Avg Acc: 33.13%, Duration: 0.53s
2025-06-03 23:47:06,670 - INFO - Epoch 95/300 | Batch 0/24 | Loss: 3.4459 | Acc: 24.61% | LR: 7.77e-04
2025-06-03 23:47:09,140 - INFO - Epoch 95 TRAIN Summary: Avg Loss: 3.4910, Avg Acc: 23.21%, Duration: 3.03s
2025-06-03 23:47:09,655 - INFO - Epoch 95 EVAL  Summary: Avg Loss: 3.0014, Avg Acc: 33.44%, Duration: 0.51s
2025-06-03 23:47:09,782 - INFO - Epoch 95: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:09,782 - INFO - Epoch 95: 新的最佳准确率: 33.44% (已保存至 best_model.pth)
2025-06-03 23:47:10,318 - INFO - Epoch 96/300 | Batch 0/24 | Loss: 3.5061 | Acc: 17.53% | LR: 7.73e-04
2025-06-03 23:47:12,787 - INFO - Epoch 96 TRAIN Summary: Avg Loss: 3.4878, Avg Acc: 22.55%, Duration: 3.00s
2025-06-03 23:47:13,305 - INFO - Epoch 96 EVAL  Summary: Avg Loss: 3.0034, Avg Acc: 33.71%, Duration: 0.52s
2025-06-03 23:47:13,438 - INFO - Epoch 96: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:13,438 - INFO - Epoch 96: 新的最佳准确率: 33.71% (已保存至 best_model.pth)
2025-06-03 23:47:13,951 - INFO - Epoch 97/300 | Batch 0/24 | Loss: 4.3157 | Acc: 10.02% | LR: 7.68e-04
2025-06-03 23:47:16,451 - INFO - Epoch 97 TRAIN Summary: Avg Loss: 3.4711, Avg Acc: 23.83%, Duration: 3.01s
2025-06-03 23:47:16,969 - INFO - Epoch 97 EVAL  Summary: Avg Loss: 2.9951, Avg Acc: 33.60%, Duration: 0.52s
2025-06-03 23:47:17,537 - INFO - Epoch 98/300 | Batch 0/24 | Loss: 3.4629 | Acc: 24.61% | LR: 7.64e-04
2025-06-03 23:47:20,775 - INFO - Epoch 98 TRAIN Summary: Avg Loss: 3.4951, Avg Acc: 22.76%, Duration: 3.80s
2025-06-03 23:47:21,422 - INFO - Epoch 98 EVAL  Summary: Avg Loss: 3.0048, Avg Acc: 33.95%, Duration: 0.64s
2025-06-03 23:47:21,578 - INFO - Epoch 98: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:21,578 - INFO - Epoch 98: 新的最佳准确率: 33.95% (已保存至 best_model.pth)
2025-06-03 23:47:22,380 - INFO - Epoch 99/300 | Batch 0/24 | Loss: 3.4096 | Acc: 23.05% | LR: 7.59e-04
2025-06-03 23:47:25,239 - INFO - Epoch 99 TRAIN Summary: Avg Loss: 3.4808, Avg Acc: 23.16%, Duration: 3.66s
2025-06-03 23:47:25,778 - INFO - Epoch 99 EVAL  Summary: Avg Loss: 2.9669, Avg Acc: 34.70%, Duration: 0.54s
2025-06-03 23:47:25,943 - INFO - Epoch 99: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:25,943 - INFO - Epoch 99: 新的最佳准确率: 34.70% (已保存至 best_model.pth)
2025-06-03 23:47:26,405 - INFO - Epoch 100/300 | Batch 0/24 | Loss: 3.3939 | Acc: 24.61% | LR: 7.55e-04
2025-06-03 23:47:29,047 - INFO - Epoch 100 TRAIN Summary: Avg Loss: 3.5797, Avg Acc: 21.06%, Duration: 3.10s
2025-06-03 23:47:29,558 - INFO - Epoch 100 EVAL  Summary: Avg Loss: 3.0004, Avg Acc: 33.58%, Duration: 0.51s
2025-06-03 23:47:29,718 - INFO - Epoch 100: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_100.pth
2025-06-03 23:47:30,271 - INFO - Epoch 101/300 | Batch 0/24 | Loss: 3.3956 | Acc: 23.05% | LR: 7.50e-04
2025-06-03 23:47:32,753 - INFO - Epoch 101 TRAIN Summary: Avg Loss: 3.4281, Avg Acc: 24.29%, Duration: 3.03s
2025-06-03 23:47:33,298 - INFO - Epoch 101 EVAL  Summary: Avg Loss: 2.9955, Avg Acc: 33.94%, Duration: 0.54s
2025-06-03 23:47:33,859 - INFO - Epoch 102/300 | Batch 0/24 | Loss: 3.4498 | Acc: 26.13% | LR: 7.46e-04
2025-06-03 23:47:36,367 - INFO - Epoch 102 TRAIN Summary: Avg Loss: 3.5056, Avg Acc: 23.97%, Duration: 3.07s
2025-06-03 23:47:36,888 - INFO - Epoch 102 EVAL  Summary: Avg Loss: 2.9727, Avg Acc: 34.55%, Duration: 0.52s
2025-06-03 23:47:37,444 - INFO - Epoch 103/300 | Batch 0/24 | Loss: 3.3478 | Acc: 23.83% | LR: 7.41e-04
2025-06-03 23:47:39,835 - INFO - Epoch 103 TRAIN Summary: Avg Loss: 3.5077, Avg Acc: 23.35%, Duration: 2.95s
2025-06-03 23:47:40,363 - INFO - Epoch 103 EVAL  Summary: Avg Loss: 2.9764, Avg Acc: 34.38%, Duration: 0.52s
2025-06-03 23:47:40,931 - INFO - Epoch 104/300 | Batch 0/24 | Loss: 4.1126 | Acc: 13.64% | LR: 7.37e-04
2025-06-03 23:47:43,427 - INFO - Epoch 104 TRAIN Summary: Avg Loss: 3.6040, Avg Acc: 20.98%, Duration: 3.06s
2025-06-03 23:47:43,926 - INFO - Epoch 104 EVAL  Summary: Avg Loss: 2.9548, Avg Acc: 35.33%, Duration: 0.50s
2025-06-03 23:47:44,143 - INFO - Epoch 104: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:47:44,143 - INFO - Epoch 104: 新的最佳准确率: 35.33% (已保存至 best_model.pth)
2025-06-03 23:47:44,698 - INFO - Epoch 105/300 | Batch 0/24 | Loss: 3.3569 | Acc: 28.52% | LR: 7.32e-04
2025-06-03 23:47:47,147 - INFO - Epoch 105 TRAIN Summary: Avg Loss: 3.4470, Avg Acc: 23.84%, Duration: 3.00s
2025-06-03 23:47:47,647 - INFO - Epoch 105 EVAL  Summary: Avg Loss: 2.9917, Avg Acc: 33.95%, Duration: 0.50s
2025-06-03 23:47:48,222 - INFO - Epoch 106/300 | Batch 0/24 | Loss: 3.3039 | Acc: 25.78% | LR: 7.27e-04
2025-06-03 23:47:50,702 - INFO - Epoch 106 TRAIN Summary: Avg Loss: 3.6228, Avg Acc: 20.78%, Duration: 3.05s
2025-06-03 23:47:51,225 - INFO - Epoch 106 EVAL  Summary: Avg Loss: 2.9649, Avg Acc: 34.82%, Duration: 0.52s
2025-06-03 23:47:51,798 - INFO - Epoch 107/300 | Batch 0/24 | Loss: 3.7889 | Acc: 18.65% | LR: 7.23e-04
2025-06-03 23:47:54,278 - INFO - Epoch 107 TRAIN Summary: Avg Loss: 3.4830, Avg Acc: 23.67%, Duration: 3.05s
2025-06-03 23:47:54,790 - INFO - Epoch 107 EVAL  Summary: Avg Loss: 2.9642, Avg Acc: 34.69%, Duration: 0.51s
2025-06-03 23:47:55,328 - INFO - Epoch 108/300 | Batch 0/24 | Loss: 3.3370 | Acc: 23.83% | LR: 7.18e-04
2025-06-03 23:47:57,797 - INFO - Epoch 108 TRAIN Summary: Avg Loss: 3.4876, Avg Acc: 24.21%, Duration: 3.01s
2025-06-03 23:47:58,279 - INFO - Epoch 108 EVAL  Summary: Avg Loss: 2.9459, Avg Acc: 35.17%, Duration: 0.48s
2025-06-03 23:47:58,891 - INFO - Epoch 109/300 | Batch 0/24 | Loss: 3.4344 | Acc: 25.00% | LR: 7.13e-04
2025-06-03 23:48:01,338 - INFO - Epoch 109 TRAIN Summary: Avg Loss: 3.6193, Avg Acc: 21.91%, Duration: 3.06s
2025-06-03 23:48:01,866 - INFO - Epoch 109 EVAL  Summary: Avg Loss: 2.9492, Avg Acc: 35.72%, Duration: 0.53s
2025-06-03 23:48:02,018 - INFO - Epoch 109: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:02,018 - INFO - Epoch 109: 新的最佳准确率: 35.72% (已保存至 best_model.pth)
2025-06-03 23:48:02,558 - INFO - Epoch 110/300 | Batch 0/24 | Loss: 3.3354 | Acc: 25.39% | LR: 7.08e-04
2025-06-03 23:48:05,038 - INFO - Epoch 110 TRAIN Summary: Avg Loss: 3.3846, Avg Acc: 25.59%, Duration: 3.02s
2025-06-03 23:48:05,555 - INFO - Epoch 110 EVAL  Summary: Avg Loss: 2.9401, Avg Acc: 35.21%, Duration: 0.52s
2025-06-03 23:48:06,139 - INFO - Epoch 111/300 | Batch 0/24 | Loss: 4.1789 | Acc: 11.31% | LR: 7.04e-04
2025-06-03 23:48:08,523 - INFO - Epoch 111 TRAIN Summary: Avg Loss: 3.5767, Avg Acc: 21.54%, Duration: 2.96s
2025-06-03 23:48:09,003 - INFO - Epoch 111 EVAL  Summary: Avg Loss: 2.9406, Avg Acc: 35.27%, Duration: 0.48s
2025-06-03 23:48:09,570 - INFO - Epoch 112/300 | Batch 0/24 | Loss: 3.2959 | Acc: 24.61% | LR: 6.99e-04
2025-06-03 23:48:12,042 - INFO - Epoch 112 TRAIN Summary: Avg Loss: 3.5086, Avg Acc: 22.52%, Duration: 3.04s
2025-06-03 23:48:12,540 - INFO - Epoch 112 EVAL  Summary: Avg Loss: 2.9318, Avg Acc: 35.90%, Duration: 0.50s
2025-06-03 23:48:12,682 - INFO - Epoch 112: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:12,683 - INFO - Epoch 112: 新的最佳准确率: 35.90% (已保存至 best_model.pth)
2025-06-03 23:48:13,246 - INFO - Epoch 113/300 | Batch 0/24 | Loss: 3.2199 | Acc: 28.52% | LR: 6.94e-04
2025-06-03 23:48:15,732 - INFO - Epoch 113 TRAIN Summary: Avg Loss: 3.4771, Avg Acc: 24.14%, Duration: 3.05s
2025-06-03 23:48:16,228 - INFO - Epoch 113 EVAL  Summary: Avg Loss: 2.9247, Avg Acc: 35.71%, Duration: 0.49s
2025-06-03 23:48:16,816 - INFO - Epoch 114/300 | Batch 0/24 | Loss: 3.2856 | Acc: 25.78% | LR: 6.89e-04
2025-06-03 23:48:19,303 - INFO - Epoch 114 TRAIN Summary: Avg Loss: 3.4305, Avg Acc: 24.74%, Duration: 3.07s
2025-06-03 23:48:19,822 - INFO - Epoch 114 EVAL  Summary: Avg Loss: 2.9237, Avg Acc: 35.68%, Duration: 0.51s
2025-06-03 23:48:20,395 - INFO - Epoch 115/300 | Batch 0/24 | Loss: 3.3773 | Acc: 26.17% | LR: 6.84e-04
2025-06-03 23:48:22,872 - INFO - Epoch 115 TRAIN Summary: Avg Loss: 3.4142, Avg Acc: 25.47%, Duration: 3.05s
2025-06-03 23:48:23,353 - INFO - Epoch 115 EVAL  Summary: Avg Loss: 2.9179, Avg Acc: 36.15%, Duration: 0.48s
2025-06-03 23:48:23,524 - INFO - Epoch 115: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:23,525 - INFO - Epoch 115: 新的最佳准确率: 36.15% (已保存至 best_model.pth)
2025-06-03 23:48:24,085 - INFO - Epoch 116/300 | Batch 0/24 | Loss: 3.4197 | Acc: 24.22% | LR: 6.80e-04
2025-06-03 23:48:26,442 - INFO - Epoch 116 TRAIN Summary: Avg Loss: 3.3893, Avg Acc: 25.17%, Duration: 2.92s
2025-06-03 23:48:26,926 - INFO - Epoch 116 EVAL  Summary: Avg Loss: 2.9063, Avg Acc: 36.24%, Duration: 0.48s
2025-06-03 23:48:27,059 - INFO - Epoch 116: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:27,060 - INFO - Epoch 116: 新的最佳准确率: 36.24% (已保存至 best_model.pth)
2025-06-03 23:48:27,594 - INFO - Epoch 117/300 | Batch 0/24 | Loss: 3.2247 | Acc: 30.22% | LR: 6.75e-04
2025-06-03 23:48:30,024 - INFO - Epoch 117 TRAIN Summary: Avg Loss: 3.4472, Avg Acc: 24.27%, Duration: 2.96s
2025-06-03 23:48:30,543 - INFO - Epoch 117 EVAL  Summary: Avg Loss: 2.9156, Avg Acc: 35.92%, Duration: 0.51s
2025-06-03 23:48:31,149 - INFO - Epoch 118/300 | Batch 0/24 | Loss: 3.3320 | Acc: 25.39% | LR: 6.70e-04
2025-06-03 23:48:33,825 - INFO - Epoch 118 TRAIN Summary: Avg Loss: 3.4674, Avg Acc: 23.70%, Duration: 3.28s
2025-06-03 23:48:34,365 - INFO - Epoch 118 EVAL  Summary: Avg Loss: 2.9049, Avg Acc: 36.48%, Duration: 0.54s
2025-06-03 23:48:34,527 - INFO - Epoch 118: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:34,527 - INFO - Epoch 118: 新的最佳准确率: 36.48% (已保存至 best_model.pth)
2025-06-03 23:48:35,050 - INFO - Epoch 119/300 | Batch 0/24 | Loss: 3.3659 | Acc: 25.00% | LR: 6.65e-04
2025-06-03 23:48:37,509 - INFO - Epoch 119 TRAIN Summary: Avg Loss: 3.4758, Avg Acc: 24.08%, Duration: 2.98s
2025-06-03 23:48:38,001 - INFO - Epoch 119 EVAL  Summary: Avg Loss: 2.8970, Avg Acc: 36.31%, Duration: 0.49s
2025-06-03 23:48:38,569 - INFO - Epoch 120/300 | Batch 0/24 | Loss: 4.4165 | Acc: 8.01% | LR: 6.60e-04
2025-06-03 23:48:41,086 - INFO - Epoch 120 TRAIN Summary: Avg Loss: 3.5009, Avg Acc: 23.30%, Duration: 3.08s
2025-06-03 23:48:41,603 - INFO - Epoch 120 EVAL  Summary: Avg Loss: 2.9043, Avg Acc: 35.89%, Duration: 0.51s
2025-06-03 23:48:41,726 - INFO - Epoch 120: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_120.pth
2025-06-03 23:48:42,294 - INFO - Epoch 121/300 | Batch 0/24 | Loss: 3.4304 | Acc: 25.58% | LR: 6.55e-04
2025-06-03 23:48:44,714 - INFO - Epoch 121 TRAIN Summary: Avg Loss: 3.4388, Avg Acc: 24.62%, Duration: 2.99s
2025-06-03 23:48:45,240 - INFO - Epoch 121 EVAL  Summary: Avg Loss: 2.9055, Avg Acc: 36.24%, Duration: 0.52s
2025-06-03 23:48:45,790 - INFO - Epoch 122/300 | Batch 0/24 | Loss: 3.4220 | Acc: 23.05% | LR: 6.50e-04
2025-06-03 23:48:48,290 - INFO - Epoch 122 TRAIN Summary: Avg Loss: 3.4410, Avg Acc: 24.73%, Duration: 3.05s
2025-06-03 23:48:48,796 - INFO - Epoch 122 EVAL  Summary: Avg Loss: 2.9062, Avg Acc: 36.23%, Duration: 0.50s
2025-06-03 23:48:49,410 - INFO - Epoch 123/300 | Batch 0/24 | Loss: 3.2228 | Acc: 25.78% | LR: 6.45e-04
2025-06-03 23:48:51,888 - INFO - Epoch 123 TRAIN Summary: Avg Loss: 3.3492, Avg Acc: 26.11%, Duration: 3.09s
2025-06-03 23:48:52,444 - INFO - Epoch 123 EVAL  Summary: Avg Loss: 2.8984, Avg Acc: 36.46%, Duration: 0.55s
2025-06-03 23:48:53,020 - INFO - Epoch 124/300 | Batch 0/24 | Loss: 3.4503 | Acc: 24.22% | LR: 6.40e-04
2025-06-03 23:48:55,518 - INFO - Epoch 124 TRAIN Summary: Avg Loss: 3.3465, Avg Acc: 26.22%, Duration: 3.07s
2025-06-03 23:48:56,022 - INFO - Epoch 124 EVAL  Summary: Avg Loss: 2.8763, Avg Acc: 37.16%, Duration: 0.50s
2025-06-03 23:48:56,149 - INFO - Epoch 124: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:48:56,150 - INFO - Epoch 124: 新的最佳准确率: 37.16% (已保存至 best_model.pth)
2025-06-03 23:48:56,692 - INFO - Epoch 125/300 | Batch 0/24 | Loss: 3.3312 | Acc: 28.12% | LR: 6.35e-04
2025-06-03 23:48:59,131 - INFO - Epoch 125 TRAIN Summary: Avg Loss: 3.2935, Avg Acc: 27.36%, Duration: 2.98s
2025-06-03 23:48:59,654 - INFO - Epoch 125 EVAL  Summary: Avg Loss: 2.8864, Avg Acc: 36.45%, Duration: 0.52s
2025-06-03 23:49:00,253 - INFO - Epoch 126/300 | Batch 0/24 | Loss: 3.3509 | Acc: 28.12% | LR: 6.30e-04
2025-06-03 23:49:02,762 - INFO - Epoch 126 TRAIN Summary: Avg Loss: 3.4383, Avg Acc: 24.74%, Duration: 3.11s
2025-06-03 23:49:03,258 - INFO - Epoch 126 EVAL  Summary: Avg Loss: 2.8847, Avg Acc: 36.81%, Duration: 0.49s
2025-06-03 23:49:03,858 - INFO - Epoch 127/300 | Batch 0/24 | Loss: 3.3227 | Acc: 32.42% | LR: 6.25e-04
2025-06-03 23:49:06,298 - INFO - Epoch 127 TRAIN Summary: Avg Loss: 3.3814, Avg Acc: 26.31%, Duration: 3.04s
2025-06-03 23:49:06,807 - INFO - Epoch 127 EVAL  Summary: Avg Loss: 2.8733, Avg Acc: 36.89%, Duration: 0.51s
2025-06-03 23:49:07,366 - INFO - Epoch 128/300 | Batch 0/24 | Loss: 3.3913 | Acc: 23.83% | LR: 6.20e-04
2025-06-03 23:49:09,843 - INFO - Epoch 128 TRAIN Summary: Avg Loss: 3.2819, Avg Acc: 26.75%, Duration: 3.03s
2025-06-03 23:49:10,334 - INFO - Epoch 128 EVAL  Summary: Avg Loss: 2.8625, Avg Acc: 37.38%, Duration: 0.49s
2025-06-03 23:49:10,569 - INFO - Epoch 128: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:10,569 - INFO - Epoch 128: 新的最佳准确率: 37.38% (已保存至 best_model.pth)
2025-06-03 23:49:11,146 - INFO - Epoch 129/300 | Batch 0/24 | Loss: 3.3444 | Acc: 27.73% | LR: 6.15e-04
2025-06-03 23:49:13,574 - INFO - Epoch 129 TRAIN Summary: Avg Loss: 3.3666, Avg Acc: 25.97%, Duration: 3.00s
2025-06-03 23:49:14,109 - INFO - Epoch 129 EVAL  Summary: Avg Loss: 2.8670, Avg Acc: 37.35%, Duration: 0.53s
2025-06-03 23:49:14,676 - INFO - Epoch 130/300 | Batch 0/24 | Loss: 3.2553 | Acc: 25.00% | LR: 6.09e-04
2025-06-03 23:49:17,078 - INFO - Epoch 130 TRAIN Summary: Avg Loss: 3.4182, Avg Acc: 24.81%, Duration: 2.97s
2025-06-03 23:49:17,576 - INFO - Epoch 130 EVAL  Summary: Avg Loss: 2.8668, Avg Acc: 37.20%, Duration: 0.50s
2025-06-03 23:49:18,153 - INFO - Epoch 131/300 | Batch 0/24 | Loss: 3.2475 | Acc: 31.65% | LR: 6.04e-04
2025-06-03 23:49:20,591 - INFO - Epoch 131 TRAIN Summary: Avg Loss: 3.3431, Avg Acc: 26.83%, Duration: 3.01s
2025-06-03 23:49:21,076 - INFO - Epoch 131 EVAL  Summary: Avg Loss: 2.8687, Avg Acc: 37.23%, Duration: 0.48s
2025-06-03 23:49:21,648 - INFO - Epoch 132/300 | Batch 0/24 | Loss: 3.3229 | Acc: 26.17% | LR: 5.99e-04
2025-06-03 23:49:24,118 - INFO - Epoch 132 TRAIN Summary: Avg Loss: 3.4335, Avg Acc: 25.11%, Duration: 3.04s
2025-06-03 23:49:24,598 - INFO - Epoch 132 EVAL  Summary: Avg Loss: 2.8534, Avg Acc: 37.86%, Duration: 0.48s
2025-06-03 23:49:24,725 - INFO - Epoch 132: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:24,725 - INFO - Epoch 132: 新的最佳准确率: 37.86% (已保存至 best_model.pth)
2025-06-03 23:49:25,224 - INFO - Epoch 133/300 | Batch 0/24 | Loss: 3.3674 | Acc: 28.90% | LR: 5.94e-04
2025-06-03 23:49:27,670 - INFO - Epoch 133 TRAIN Summary: Avg Loss: 3.4483, Avg Acc: 25.19%, Duration: 2.94s
2025-06-03 23:49:28,162 - INFO - Epoch 133 EVAL  Summary: Avg Loss: 2.8421, Avg Acc: 38.02%, Duration: 0.49s
2025-06-03 23:49:28,298 - INFO - Epoch 133: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:28,298 - INFO - Epoch 133: 新的最佳准确率: 38.02% (已保存至 best_model.pth)
2025-06-03 23:49:28,840 - INFO - Epoch 134/300 | Batch 0/24 | Loss: 3.3090 | Acc: 25.00% | LR: 5.89e-04
2025-06-03 23:49:31,308 - INFO - Epoch 134 TRAIN Summary: Avg Loss: 3.3014, Avg Acc: 27.19%, Duration: 3.01s
2025-06-03 23:49:31,836 - INFO - Epoch 134 EVAL  Summary: Avg Loss: 2.8479, Avg Acc: 37.89%, Duration: 0.53s
2025-06-03 23:49:32,412 - INFO - Epoch 135/300 | Batch 0/24 | Loss: 3.3885 | Acc: 28.50% | LR: 5.84e-04
2025-06-03 23:49:34,824 - INFO - Epoch 135 TRAIN Summary: Avg Loss: 3.3955, Avg Acc: 25.21%, Duration: 2.98s
2025-06-03 23:49:35,366 - INFO - Epoch 135 EVAL  Summary: Avg Loss: 2.8466, Avg Acc: 38.16%, Duration: 0.54s
2025-06-03 23:49:35,513 - INFO - Epoch 135: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:35,513 - INFO - Epoch 135: 新的最佳准确率: 38.16% (已保存至 best_model.pth)
2025-06-03 23:49:36,076 - INFO - Epoch 136/300 | Batch 0/24 | Loss: 4.2642 | Acc: 10.34% | LR: 5.79e-04
2025-06-03 23:49:38,499 - INFO - Epoch 136 TRAIN Summary: Avg Loss: 3.5136, Avg Acc: 23.49%, Duration: 2.99s
2025-06-03 23:49:39,022 - INFO - Epoch 136 EVAL  Summary: Avg Loss: 2.8482, Avg Acc: 38.19%, Duration: 0.52s
2025-06-03 23:49:39,160 - INFO - Epoch 136: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:39,161 - INFO - Epoch 136: 新的最佳准确率: 38.19% (已保存至 best_model.pth)
2025-06-03 23:49:39,757 - INFO - Epoch 137/300 | Batch 0/24 | Loss: 3.1903 | Acc: 27.35% | LR: 5.73e-04
2025-06-03 23:49:42,167 - INFO - Epoch 137 TRAIN Summary: Avg Loss: 3.3785, Avg Acc: 25.65%, Duration: 3.01s
2025-06-03 23:49:42,688 - INFO - Epoch 137 EVAL  Summary: Avg Loss: 2.8489, Avg Acc: 37.85%, Duration: 0.52s
2025-06-03 23:49:43,259 - INFO - Epoch 138/300 | Batch 0/24 | Loss: 3.1400 | Acc: 31.79% | LR: 5.68e-04
2025-06-03 23:49:45,713 - INFO - Epoch 138 TRAIN Summary: Avg Loss: 3.2606, Avg Acc: 28.72%, Duration: 3.02s
2025-06-03 23:49:46,231 - INFO - Epoch 138 EVAL  Summary: Avg Loss: 2.8322, Avg Acc: 38.32%, Duration: 0.51s
2025-06-03 23:49:46,376 - INFO - Epoch 138: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:46,376 - INFO - Epoch 138: 新的最佳准确率: 38.32% (已保存至 best_model.pth)
2025-06-03 23:49:46,907 - INFO - Epoch 139/300 | Batch 0/24 | Loss: 3.1703 | Acc: 29.30% | LR: 5.63e-04
2025-06-03 23:49:49,344 - INFO - Epoch 139 TRAIN Summary: Avg Loss: 3.3840, Avg Acc: 25.44%, Duration: 2.97s
2025-06-03 23:49:49,868 - INFO - Epoch 139 EVAL  Summary: Avg Loss: 2.8320, Avg Acc: 38.11%, Duration: 0.52s
2025-06-03 23:49:50,434 - INFO - Epoch 140/300 | Batch 0/24 | Loss: 3.5580 | Acc: 24.73% | LR: 5.58e-04
2025-06-03 23:49:52,895 - INFO - Epoch 140 TRAIN Summary: Avg Loss: 3.4816, Avg Acc: 24.62%, Duration: 3.03s
2025-06-03 23:49:53,381 - INFO - Epoch 140 EVAL  Summary: Avg Loss: 2.8363, Avg Acc: 38.37%, Duration: 0.48s
2025-06-03 23:49:53,534 - INFO - Epoch 140: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:53,535 - INFO - Epoch 140: 新的最佳准确率: 38.37% (已保存至 best_model.pth)
2025-06-03 23:49:53,761 - INFO - Epoch 140: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_140.pth
2025-06-03 23:49:54,259 - INFO - Epoch 141/300 | Batch 0/24 | Loss: 3.3531 | Acc: 26.56% | LR: 5.53e-04
2025-06-03 23:49:56,933 - INFO - Epoch 141 TRAIN Summary: Avg Loss: 3.3639, Avg Acc: 26.57%, Duration: 3.17s
2025-06-03 23:49:57,764 - INFO - Epoch 141 EVAL  Summary: Avg Loss: 2.8347, Avg Acc: 38.51%, Duration: 0.83s
2025-06-03 23:49:57,921 - INFO - Epoch 141: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:49:57,924 - INFO - Epoch 141: 新的最佳准确率: 38.51% (已保存至 best_model.pth)
2025-06-03 23:49:58,826 - INFO - Epoch 142/300 | Batch 0/24 | Loss: 3.3695 | Acc: 28.12% | LR: 5.48e-04
2025-06-03 23:50:02,179 - INFO - Epoch 142 TRAIN Summary: Avg Loss: 3.3943, Avg Acc: 26.05%, Duration: 4.25s
2025-06-03 23:50:02,672 - INFO - Epoch 142 EVAL  Summary: Avg Loss: 2.8327, Avg Acc: 38.09%, Duration: 0.49s
2025-06-03 23:50:03,229 - INFO - Epoch 143/300 | Batch 0/24 | Loss: 3.2805 | Acc: 27.34% | LR: 5.42e-04
2025-06-03 23:50:05,768 - INFO - Epoch 143 TRAIN Summary: Avg Loss: 3.3896, Avg Acc: 26.06%, Duration: 3.09s
2025-06-03 23:50:06,248 - INFO - Epoch 143 EVAL  Summary: Avg Loss: 2.8210, Avg Acc: 38.55%, Duration: 0.48s
2025-06-03 23:50:06,392 - INFO - Epoch 143: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:06,393 - INFO - Epoch 143: 新的最佳准确率: 38.55% (已保存至 best_model.pth)
2025-06-03 23:50:06,893 - INFO - Epoch 144/300 | Batch 0/24 | Loss: 3.2232 | Acc: 28.22% | LR: 5.37e-04
2025-06-03 23:50:09,398 - INFO - Epoch 144 TRAIN Summary: Avg Loss: 3.3084, Avg Acc: 27.60%, Duration: 3.00s
2025-06-03 23:50:09,874 - INFO - Epoch 144 EVAL  Summary: Avg Loss: 2.8247, Avg Acc: 38.60%, Duration: 0.47s
2025-06-03 23:50:10,102 - INFO - Epoch 144: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:10,102 - INFO - Epoch 144: 新的最佳准确率: 38.60% (已保存至 best_model.pth)
2025-06-03 23:50:10,661 - INFO - Epoch 145/300 | Batch 0/24 | Loss: 3.7019 | Acc: 22.68% | LR: 5.32e-04
2025-06-03 23:50:13,152 - INFO - Epoch 145 TRAIN Summary: Avg Loss: 3.3376, Avg Acc: 26.93%, Duration: 3.05s
2025-06-03 23:50:13,653 - INFO - Epoch 145 EVAL  Summary: Avg Loss: 2.8187, Avg Acc: 38.74%, Duration: 0.50s
2025-06-03 23:50:13,788 - INFO - Epoch 145: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:13,789 - INFO - Epoch 145: 新的最佳准确率: 38.74% (已保存至 best_model.pth)
2025-06-03 23:50:14,274 - INFO - Epoch 146/300 | Batch 0/24 | Loss: 3.1581 | Acc: 26.95% | LR: 5.27e-04
2025-06-03 23:50:16,755 - INFO - Epoch 146 TRAIN Summary: Avg Loss: 3.3694, Avg Acc: 25.83%, Duration: 2.96s
2025-06-03 23:50:17,226 - INFO - Epoch 146 EVAL  Summary: Avg Loss: 2.8166, Avg Acc: 38.28%, Duration: 0.47s
2025-06-03 23:50:17,790 - INFO - Epoch 147/300 | Batch 0/24 | Loss: 3.3055 | Acc: 25.78% | LR: 5.21e-04
2025-06-03 23:50:20,180 - INFO - Epoch 147 TRAIN Summary: Avg Loss: 3.3101, Avg Acc: 27.10%, Duration: 2.95s
2025-06-03 23:50:20,678 - INFO - Epoch 147 EVAL  Summary: Avg Loss: 2.8092, Avg Acc: 38.77%, Duration: 0.50s
2025-06-03 23:50:20,821 - INFO - Epoch 147: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:20,822 - INFO - Epoch 147: 新的最佳准确率: 38.77% (已保存至 best_model.pth)
2025-06-03 23:50:21,375 - INFO - Epoch 148/300 | Batch 0/24 | Loss: 3.3784 | Acc: 26.54% | LR: 5.16e-04
2025-06-03 23:50:23,836 - INFO - Epoch 148 TRAIN Summary: Avg Loss: 3.2982, Avg Acc: 27.80%, Duration: 3.01s
2025-06-03 23:50:24,352 - INFO - Epoch 148 EVAL  Summary: Avg Loss: 2.8073, Avg Acc: 39.17%, Duration: 0.51s
2025-06-03 23:50:24,502 - INFO - Epoch 148: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:24,503 - INFO - Epoch 148: 新的最佳准确率: 39.17% (已保存至 best_model.pth)
2025-06-03 23:50:25,051 - INFO - Epoch 149/300 | Batch 0/24 | Loss: 3.4474 | Acc: 26.31% | LR: 5.11e-04
2025-06-03 23:50:27,433 - INFO - Epoch 149 TRAIN Summary: Avg Loss: 3.4209, Avg Acc: 25.39%, Duration: 2.93s
2025-06-03 23:50:27,948 - INFO - Epoch 149 EVAL  Summary: Avg Loss: 2.8027, Avg Acc: 38.51%, Duration: 0.51s
2025-06-03 23:50:28,550 - INFO - Epoch 150/300 | Batch 0/24 | Loss: 3.2377 | Acc: 29.69% | LR: 5.06e-04
2025-06-03 23:50:30,882 - INFO - Epoch 150 TRAIN Summary: Avg Loss: 3.3676, Avg Acc: 26.27%, Duration: 2.93s
2025-06-03 23:50:31,397 - INFO - Epoch 150 EVAL  Summary: Avg Loss: 2.7980, Avg Acc: 39.04%, Duration: 0.51s
2025-06-03 23:50:31,940 - INFO - Epoch 151/300 | Batch 0/24 | Loss: 3.1899 | Acc: 32.42% | LR: 5.01e-04
2025-06-03 23:50:34,481 - INFO - Epoch 151 TRAIN Summary: Avg Loss: 3.3844, Avg Acc: 26.62%, Duration: 3.08s
2025-06-03 23:50:34,967 - INFO - Epoch 151 EVAL  Summary: Avg Loss: 2.8046, Avg Acc: 38.87%, Duration: 0.48s
2025-06-03 23:50:35,528 - INFO - Epoch 152/300 | Batch 0/24 | Loss: 4.0357 | Acc: 14.48% | LR: 4.95e-04
2025-06-03 23:50:38,018 - INFO - Epoch 152 TRAIN Summary: Avg Loss: 3.3635, Avg Acc: 26.67%, Duration: 3.05s
2025-06-03 23:50:38,475 - INFO - Epoch 152 EVAL  Summary: Avg Loss: 2.8033, Avg Acc: 39.00%, Duration: 0.46s
2025-06-03 23:50:39,044 - INFO - Epoch 153/300 | Batch 0/24 | Loss: 3.1898 | Acc: 28.52% | LR: 4.90e-04
2025-06-03 23:50:41,626 - INFO - Epoch 153 TRAIN Summary: Avg Loss: 3.3510, Avg Acc: 27.09%, Duration: 3.15s
2025-06-03 23:50:42,158 - INFO - Epoch 153 EVAL  Summary: Avg Loss: 2.7949, Avg Acc: 39.23%, Duration: 0.53s
2025-06-03 23:50:42,306 - INFO - Epoch 153: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:42,307 - INFO - Epoch 153: 新的最佳准确率: 39.23% (已保存至 best_model.pth)
2025-06-03 23:50:42,851 - INFO - Epoch 154/300 | Batch 0/24 | Loss: 3.1206 | Acc: 29.68% | LR: 4.85e-04
2025-06-03 23:50:45,306 - INFO - Epoch 154 TRAIN Summary: Avg Loss: 3.1908, Avg Acc: 30.37%, Duration: 3.00s
2025-06-03 23:50:45,827 - INFO - Epoch 154 EVAL  Summary: Avg Loss: 2.7959, Avg Acc: 39.09%, Duration: 0.52s
2025-06-03 23:50:46,376 - INFO - Epoch 155/300 | Batch 0/24 | Loss: 2.9795 | Acc: 32.03% | LR: 4.80e-04
2025-06-03 23:50:48,883 - INFO - Epoch 155 TRAIN Summary: Avg Loss: 3.3221, Avg Acc: 26.93%, Duration: 3.05s
2025-06-03 23:50:49,364 - INFO - Epoch 155 EVAL  Summary: Avg Loss: 2.7935, Avg Acc: 39.16%, Duration: 0.48s
2025-06-03 23:50:49,918 - INFO - Epoch 156/300 | Batch 0/24 | Loss: 3.2609 | Acc: 26.17% | LR: 4.74e-04
2025-06-03 23:50:52,413 - INFO - Epoch 156 TRAIN Summary: Avg Loss: 3.3613, Avg Acc: 26.84%, Duration: 3.05s
2025-06-03 23:50:52,908 - INFO - Epoch 156 EVAL  Summary: Avg Loss: 2.7926, Avg Acc: 39.25%, Duration: 0.49s
2025-06-03 23:50:53,052 - INFO - Epoch 156: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:53,052 - INFO - Epoch 156: 新的最佳准确率: 39.25% (已保存至 best_model.pth)
2025-06-03 23:50:53,510 - INFO - Epoch 157/300 | Batch 0/24 | Loss: 3.1769 | Acc: 30.08% | LR: 4.69e-04
2025-06-03 23:50:55,952 - INFO - Epoch 157 TRAIN Summary: Avg Loss: 3.4428, Avg Acc: 25.15%, Duration: 2.90s
2025-06-03 23:50:56,436 - INFO - Epoch 157 EVAL  Summary: Avg Loss: 2.7844, Avg Acc: 39.40%, Duration: 0.48s
2025-06-03 23:50:56,667 - INFO - Epoch 157: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:50:56,668 - INFO - Epoch 157: 新的最佳准确率: 39.40% (已保存至 best_model.pth)
2025-06-03 23:50:57,246 - INFO - Epoch 158/300 | Batch 0/24 | Loss: 3.1313 | Acc: 30.47% | LR: 4.64e-04
2025-06-03 23:50:59,680 - INFO - Epoch 158 TRAIN Summary: Avg Loss: 3.2810, Avg Acc: 28.71%, Duration: 3.01s
2025-06-03 23:51:00,231 - INFO - Epoch 158 EVAL  Summary: Avg Loss: 2.7805, Avg Acc: 40.04%, Duration: 0.55s
2025-06-03 23:51:00,451 - INFO - Epoch 158: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:51:00,452 - INFO - Epoch 158: 新的最佳准确率: 40.04% (已保存至 best_model.pth)
2025-06-03 23:51:00,983 - INFO - Epoch 159/300 | Batch 0/24 | Loss: 3.1999 | Acc: 29.69% | LR: 4.59e-04
2025-06-03 23:51:03,641 - INFO - Epoch 159 TRAIN Summary: Avg Loss: 3.3477, Avg Acc: 26.04%, Duration: 3.19s
2025-06-03 23:51:04,160 - INFO - Epoch 159 EVAL  Summary: Avg Loss: 2.7859, Avg Acc: 39.69%, Duration: 0.52s
2025-06-03 23:51:04,711 - INFO - Epoch 160/300 | Batch 0/24 | Loss: 3.2525 | Acc: 31.25% | LR: 4.53e-04
2025-06-03 23:51:07,130 - INFO - Epoch 160 TRAIN Summary: Avg Loss: 3.3536, Avg Acc: 26.61%, Duration: 2.97s
2025-06-03 23:51:07,626 - INFO - Epoch 160 EVAL  Summary: Avg Loss: 2.7826, Avg Acc: 39.55%, Duration: 0.49s
2025-06-03 23:51:07,806 - INFO - Epoch 160: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_160.pth
2025-06-03 23:51:08,372 - INFO - Epoch 161/300 | Batch 0/24 | Loss: 3.1343 | Acc: 30.86% | LR: 4.48e-04
2025-06-03 23:51:10,792 - INFO - Epoch 161 TRAIN Summary: Avg Loss: 3.2936, Avg Acc: 27.78%, Duration: 2.98s
2025-06-03 23:51:11,290 - INFO - Epoch 161 EVAL  Summary: Avg Loss: 2.7790, Avg Acc: 39.55%, Duration: 0.50s
2025-06-03 23:51:11,870 - INFO - Epoch 162/300 | Batch 0/24 | Loss: 3.1097 | Acc: 33.98% | LR: 4.43e-04
2025-06-03 23:51:14,300 - INFO - Epoch 162 TRAIN Summary: Avg Loss: 3.4031, Avg Acc: 25.47%, Duration: 3.01s
2025-06-03 23:51:14,837 - INFO - Epoch 162 EVAL  Summary: Avg Loss: 2.7847, Avg Acc: 39.63%, Duration: 0.53s
2025-06-03 23:51:15,429 - INFO - Epoch 163/300 | Batch 0/24 | Loss: 3.1138 | Acc: 33.20% | LR: 4.38e-04
2025-06-03 23:51:17,894 - INFO - Epoch 163 TRAIN Summary: Avg Loss: 3.3449, Avg Acc: 27.66%, Duration: 3.06s
2025-06-03 23:51:18,372 - INFO - Epoch 163 EVAL  Summary: Avg Loss: 2.7732, Avg Acc: 39.95%, Duration: 0.48s
2025-06-03 23:51:18,934 - INFO - Epoch 164/300 | Batch 0/24 | Loss: 3.1828 | Acc: 30.08% | LR: 4.33e-04
2025-06-03 23:51:21,405 - INFO - Epoch 164 TRAIN Summary: Avg Loss: 3.3109, Avg Acc: 28.27%, Duration: 3.03s
2025-06-03 23:51:21,922 - INFO - Epoch 164 EVAL  Summary: Avg Loss: 2.7704, Avg Acc: 39.92%, Duration: 0.51s
2025-06-03 23:51:22,446 - INFO - Epoch 165/300 | Batch 0/24 | Loss: 3.6767 | Acc: 21.39% | LR: 4.28e-04
2025-06-03 23:51:24,863 - INFO - Epoch 165 TRAIN Summary: Avg Loss: 3.2703, Avg Acc: 28.81%, Duration: 2.94s
2025-06-03 23:51:25,366 - INFO - Epoch 165 EVAL  Summary: Avg Loss: 2.7660, Avg Acc: 40.02%, Duration: 0.50s
2025-06-03 23:51:25,922 - INFO - Epoch 166/300 | Batch 0/24 | Loss: 3.0522 | Acc: 34.38% | LR: 4.22e-04
2025-06-03 23:51:28,415 - INFO - Epoch 166 TRAIN Summary: Avg Loss: 3.3583, Avg Acc: 26.95%, Duration: 3.05s
2025-06-03 23:51:28,922 - INFO - Epoch 166 EVAL  Summary: Avg Loss: 2.7602, Avg Acc: 40.19%, Duration: 0.50s
2025-06-03 23:51:29,098 - INFO - Epoch 166: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:51:29,098 - INFO - Epoch 166: 新的最佳准确率: 40.19% (已保存至 best_model.pth)
2025-06-03 23:51:29,636 - INFO - Epoch 167/300 | Batch 0/24 | Loss: 2.9208 | Acc: 34.77% | LR: 4.17e-04
2025-06-03 23:51:32,143 - INFO - Epoch 167 TRAIN Summary: Avg Loss: 3.2677, Avg Acc: 28.39%, Duration: 3.04s
2025-06-03 23:51:32,654 - INFO - Epoch 167 EVAL  Summary: Avg Loss: 2.7749, Avg Acc: 39.74%, Duration: 0.51s
2025-06-03 23:51:33,257 - INFO - Epoch 168/300 | Batch 0/24 | Loss: 3.2791 | Acc: 27.73% | LR: 4.12e-04
2025-06-03 23:51:35,720 - INFO - Epoch 168 TRAIN Summary: Avg Loss: 3.4290, Avg Acc: 25.62%, Duration: 3.07s
2025-06-03 23:51:36,206 - INFO - Epoch 168 EVAL  Summary: Avg Loss: 2.7576, Avg Acc: 40.28%, Duration: 0.48s
2025-06-03 23:51:36,344 - INFO - Epoch 168: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:51:36,344 - INFO - Epoch 168: 新的最佳准确率: 40.28% (已保存至 best_model.pth)
2025-06-03 23:51:36,894 - INFO - Epoch 169/300 | Batch 0/24 | Loss: 3.1819 | Acc: 32.42% | LR: 4.07e-04
2025-06-03 23:51:39,394 - INFO - Epoch 169 TRAIN Summary: Avg Loss: 3.2894, Avg Acc: 28.51%, Duration: 3.05s
2025-06-03 23:51:39,886 - INFO - Epoch 169 EVAL  Summary: Avg Loss: 2.7719, Avg Acc: 40.05%, Duration: 0.49s
2025-06-03 23:51:40,449 - INFO - Epoch 170/300 | Batch 0/24 | Loss: 3.2758 | Acc: 27.34% | LR: 4.02e-04
2025-06-03 23:51:42,881 - INFO - Epoch 170 TRAIN Summary: Avg Loss: 3.3108, Avg Acc: 27.73%, Duration: 2.99s
2025-06-03 23:51:43,404 - INFO - Epoch 170 EVAL  Summary: Avg Loss: 2.7648, Avg Acc: 39.76%, Duration: 0.52s
2025-06-03 23:51:43,994 - INFO - Epoch 171/300 | Batch 0/24 | Loss: 3.3258 | Acc: 34.10% | LR: 3.97e-04
2025-06-03 23:51:46,405 - INFO - Epoch 171 TRAIN Summary: Avg Loss: 3.2576, Avg Acc: 28.87%, Duration: 3.00s
2025-06-03 23:51:46,896 - INFO - Epoch 171 EVAL  Summary: Avg Loss: 2.7822, Avg Acc: 39.46%, Duration: 0.49s
2025-06-03 23:51:47,469 - INFO - Epoch 172/300 | Batch 0/24 | Loss: 3.2008 | Acc: 30.47% | LR: 3.92e-04
2025-06-03 23:51:49,914 - INFO - Epoch 172 TRAIN Summary: Avg Loss: 3.2326, Avg Acc: 29.08%, Duration: 3.02s
2025-06-03 23:51:50,447 - INFO - Epoch 172 EVAL  Summary: Avg Loss: 2.7565, Avg Acc: 40.33%, Duration: 0.53s
2025-06-03 23:51:50,609 - INFO - Epoch 172: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:51:50,609 - INFO - Epoch 172: 新的最佳准确率: 40.33% (已保存至 best_model.pth)
2025-06-03 23:51:51,096 - INFO - Epoch 173/300 | Batch 0/24 | Loss: 3.0975 | Acc: 33.59% | LR: 3.86e-04
2025-06-03 23:51:53,637 - INFO - Epoch 173 TRAIN Summary: Avg Loss: 3.3479, Avg Acc: 26.96%, Duration: 3.03s
2025-06-03 23:51:54,173 - INFO - Epoch 173 EVAL  Summary: Avg Loss: 2.7564, Avg Acc: 40.48%, Duration: 0.53s
2025-06-03 23:51:54,316 - INFO - Epoch 173: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:51:54,317 - INFO - Epoch 173: 新的最佳准确率: 40.48% (已保存至 best_model.pth)
2025-06-03 23:51:54,875 - INFO - Epoch 174/300 | Batch 0/24 | Loss: 3.0389 | Acc: 30.08% | LR: 3.81e-04
2025-06-03 23:51:57,273 - INFO - Epoch 174 TRAIN Summary: Avg Loss: 3.2318, Avg Acc: 28.82%, Duration: 2.96s
2025-06-03 23:51:57,771 - INFO - Epoch 174 EVAL  Summary: Avg Loss: 2.7619, Avg Acc: 40.14%, Duration: 0.50s
2025-06-03 23:51:58,347 - INFO - Epoch 175/300 | Batch 0/24 | Loss: 3.4222 | Acc: 29.96% | LR: 3.76e-04
2025-06-03 23:52:00,789 - INFO - Epoch 175 TRAIN Summary: Avg Loss: 3.2022, Avg Acc: 29.20%, Duration: 3.02s
2025-06-03 23:52:01,291 - INFO - Epoch 175 EVAL  Summary: Avg Loss: 2.7419, Avg Acc: 40.71%, Duration: 0.50s
2025-06-03 23:52:01,446 - INFO - Epoch 175: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:01,447 - INFO - Epoch 175: 新的最佳准确率: 40.71% (已保存至 best_model.pth)
2025-06-03 23:52:01,958 - INFO - Epoch 176/300 | Batch 0/24 | Loss: 3.3040 | Acc: 29.51% | LR: 3.71e-04
2025-06-03 23:52:04,393 - INFO - Epoch 176 TRAIN Summary: Avg Loss: 3.3177, Avg Acc: 27.58%, Duration: 2.95s
2025-06-03 23:52:04,900 - INFO - Epoch 176 EVAL  Summary: Avg Loss: 2.7433, Avg Acc: 40.86%, Duration: 0.51s
2025-06-03 23:52:05,041 - INFO - Epoch 176: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:05,041 - INFO - Epoch 176: 新的最佳准确率: 40.86% (已保存至 best_model.pth)
2025-06-03 23:52:05,517 - INFO - Epoch 177/300 | Batch 0/24 | Loss: 3.1020 | Acc: 32.81% | LR: 3.66e-04
2025-06-03 23:52:08,006 - INFO - Epoch 177 TRAIN Summary: Avg Loss: 3.2343, Avg Acc: 29.44%, Duration: 2.96s
2025-06-03 23:52:08,508 - INFO - Epoch 177 EVAL  Summary: Avg Loss: 2.7468, Avg Acc: 40.96%, Duration: 0.50s
2025-06-03 23:52:08,695 - INFO - Epoch 177: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:08,695 - INFO - Epoch 177: 新的最佳准确率: 40.96% (已保存至 best_model.pth)
2025-06-03 23:52:09,278 - INFO - Epoch 178/300 | Batch 0/24 | Loss: 3.0850 | Acc: 29.69% | LR: 3.61e-04
2025-06-03 23:52:11,709 - INFO - Epoch 178 TRAIN Summary: Avg Loss: 3.3019, Avg Acc: 27.82%, Duration: 3.01s
2025-06-03 23:52:12,214 - INFO - Epoch 178 EVAL  Summary: Avg Loss: 2.7375, Avg Acc: 40.72%, Duration: 0.50s
2025-06-03 23:52:12,791 - INFO - Epoch 179/300 | Batch 0/24 | Loss: 3.2286 | Acc: 30.71% | LR: 3.56e-04
2025-06-03 23:52:15,218 - INFO - Epoch 179 TRAIN Summary: Avg Loss: 3.3418, Avg Acc: 27.76%, Duration: 3.00s
2025-06-03 23:52:15,711 - INFO - Epoch 179 EVAL  Summary: Avg Loss: 2.7415, Avg Acc: 40.71%, Duration: 0.49s
2025-06-03 23:52:16,278 - INFO - Epoch 180/300 | Batch 0/24 | Loss: 4.2813 | Acc: 9.12% | LR: 3.51e-04
2025-06-03 23:52:18,717 - INFO - Epoch 180 TRAIN Summary: Avg Loss: 3.3346, Avg Acc: 28.05%, Duration: 3.00s
2025-06-03 23:52:19,218 - INFO - Epoch 180 EVAL  Summary: Avg Loss: 2.7471, Avg Acc: 40.46%, Duration: 0.50s
2025-06-03 23:52:19,321 - INFO - Epoch 180: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_180.pth
2025-06-03 23:52:19,827 - INFO - Epoch 181/300 | Batch 0/24 | Loss: 3.9908 | Acc: 17.37% | LR: 3.46e-04
2025-06-03 23:52:22,302 - INFO - Epoch 181 TRAIN Summary: Avg Loss: 3.3390, Avg Acc: 27.54%, Duration: 2.98s
2025-06-03 23:52:22,796 - INFO - Epoch 181 EVAL  Summary: Avg Loss: 2.7379, Avg Acc: 41.12%, Duration: 0.49s
2025-06-03 23:52:22,949 - INFO - Epoch 181: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:22,950 - INFO - Epoch 181: 新的最佳准确率: 41.12% (已保存至 best_model.pth)
2025-06-03 23:52:23,408 - INFO - Epoch 182/300 | Batch 0/24 | Loss: 3.2356 | Acc: 32.03% | LR: 3.41e-04
2025-06-03 23:52:25,881 - INFO - Epoch 182 TRAIN Summary: Avg Loss: 3.2856, Avg Acc: 28.88%, Duration: 2.93s
2025-06-03 23:52:26,418 - INFO - Epoch 182 EVAL  Summary: Avg Loss: 2.7483, Avg Acc: 40.73%, Duration: 0.53s
2025-06-03 23:52:26,984 - INFO - Epoch 183/300 | Batch 0/24 | Loss: 2.9608 | Acc: 37.44% | LR: 3.36e-04
2025-06-03 23:52:29,410 - INFO - Epoch 183 TRAIN Summary: Avg Loss: 3.1445, Avg Acc: 31.46%, Duration: 2.99s
2025-06-03 23:52:29,932 - INFO - Epoch 183 EVAL  Summary: Avg Loss: 2.7366, Avg Acc: 40.77%, Duration: 0.52s
2025-06-03 23:52:30,515 - INFO - Epoch 184/300 | Batch 0/24 | Loss: 3.0952 | Acc: 30.23% | LR: 3.31e-04
2025-06-03 23:52:33,670 - INFO - Epoch 184 TRAIN Summary: Avg Loss: 3.2300, Avg Acc: 29.47%, Duration: 3.73s
2025-06-03 23:52:34,189 - INFO - Epoch 184 EVAL  Summary: Avg Loss: 2.7435, Avg Acc: 40.61%, Duration: 0.52s
2025-06-03 23:52:34,780 - INFO - Epoch 185/300 | Batch 0/24 | Loss: 3.1094 | Acc: 31.19% | LR: 3.26e-04
2025-06-03 23:52:37,784 - INFO - Epoch 185 TRAIN Summary: Avg Loss: 3.2396, Avg Acc: 29.24%, Duration: 3.59s
2025-06-03 23:52:38,287 - INFO - Epoch 185 EVAL  Summary: Avg Loss: 2.7288, Avg Acc: 41.14%, Duration: 0.50s
2025-06-03 23:52:38,487 - INFO - Epoch 185: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:38,488 - INFO - Epoch 185: 新的最佳准确率: 41.14% (已保存至 best_model.pth)
2025-06-03 23:52:39,071 - INFO - Epoch 186/300 | Batch 0/24 | Loss: 3.1526 | Acc: 29.69% | LR: 3.21e-04
2025-06-03 23:52:41,545 - INFO - Epoch 186 TRAIN Summary: Avg Loss: 3.3629, Avg Acc: 26.99%, Duration: 3.06s
2025-06-03 23:52:42,043 - INFO - Epoch 186 EVAL  Summary: Avg Loss: 2.7418, Avg Acc: 40.72%, Duration: 0.49s
2025-06-03 23:52:42,614 - INFO - Epoch 187/300 | Batch 0/24 | Loss: 3.1171 | Acc: 30.96% | LR: 3.17e-04
2025-06-03 23:52:45,027 - INFO - Epoch 187 TRAIN Summary: Avg Loss: 3.3260, Avg Acc: 27.36%, Duration: 2.98s
2025-06-03 23:52:45,577 - INFO - Epoch 187 EVAL  Summary: Avg Loss: 2.7320, Avg Acc: 41.25%, Duration: 0.55s
2025-06-03 23:52:45,738 - INFO - Epoch 187: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:52:45,738 - INFO - Epoch 187: 新的最佳准确率: 41.25% (已保存至 best_model.pth)
2025-06-03 23:52:46,257 - INFO - Epoch 188/300 | Batch 0/24 | Loss: 3.3360 | Acc: 28.37% | LR: 3.12e-04
2025-06-03 23:52:48,665 - INFO - Epoch 188 TRAIN Summary: Avg Loss: 3.1923, Avg Acc: 30.13%, Duration: 2.93s
2025-06-03 23:52:49,165 - INFO - Epoch 188 EVAL  Summary: Avg Loss: 2.7337, Avg Acc: 41.02%, Duration: 0.50s
2025-06-03 23:52:49,737 - INFO - Epoch 189/300 | Batch 0/24 | Loss: 3.0709 | Acc: 34.38% | LR: 3.07e-04
2025-06-03 23:52:52,223 - INFO - Epoch 189 TRAIN Summary: Avg Loss: 3.2236, Avg Acc: 29.60%, Duration: 3.06s
2025-06-03 23:52:52,713 - INFO - Epoch 189 EVAL  Summary: Avg Loss: 2.7270, Avg Acc: 41.05%, Duration: 0.49s
2025-06-03 23:52:53,282 - INFO - Epoch 190/300 | Batch 0/24 | Loss: 3.1992 | Acc: 30.47% | LR: 3.02e-04
2025-06-03 23:52:55,732 - INFO - Epoch 190 TRAIN Summary: Avg Loss: 3.2477, Avg Acc: 28.66%, Duration: 3.02s
2025-06-03 23:52:56,219 - INFO - Epoch 190 EVAL  Summary: Avg Loss: 2.7281, Avg Acc: 40.99%, Duration: 0.48s
2025-06-03 23:52:56,780 - INFO - Epoch 191/300 | Batch 0/24 | Loss: 3.0075 | Acc: 33.20% | LR: 2.97e-04
2025-06-03 23:52:59,205 - INFO - Epoch 191 TRAIN Summary: Avg Loss: 3.1936, Avg Acc: 30.50%, Duration: 2.98s
2025-06-03 23:52:59,737 - INFO - Epoch 191 EVAL  Summary: Avg Loss: 2.7283, Avg Acc: 41.05%, Duration: 0.53s
2025-06-03 23:53:00,280 - INFO - Epoch 192/300 | Batch 0/24 | Loss: 4.1827 | Acc: 11.87% | LR: 2.93e-04
2025-06-03 23:53:02,714 - INFO - Epoch 192 TRAIN Summary: Avg Loss: 3.2551, Avg Acc: 28.51%, Duration: 2.98s
2025-06-03 23:53:03,185 - INFO - Epoch 192 EVAL  Summary: Avg Loss: 2.7253, Avg Acc: 41.22%, Duration: 0.47s
2025-06-03 23:53:03,736 - INFO - Epoch 193/300 | Batch 0/24 | Loss: 3.0432 | Acc: 31.64% | LR: 2.88e-04
2025-06-03 23:53:06,132 - INFO - Epoch 193 TRAIN Summary: Avg Loss: 3.2241, Avg Acc: 29.74%, Duration: 2.94s
2025-06-03 23:53:06,617 - INFO - Epoch 193 EVAL  Summary: Avg Loss: 2.7181, Avg Acc: 41.47%, Duration: 0.48s
2025-06-03 23:53:06,789 - INFO - Epoch 193: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:53:06,790 - INFO - Epoch 193: 新的最佳准确率: 41.47% (已保存至 best_model.pth)
2025-06-03 23:53:07,334 - INFO - Epoch 194/300 | Batch 0/24 | Loss: 3.5781 | Acc: 25.26% | LR: 2.83e-04
2025-06-03 23:53:09,718 - INFO - Epoch 194 TRAIN Summary: Avg Loss: 3.3370, Avg Acc: 26.83%, Duration: 2.93s
2025-06-03 23:53:10,215 - INFO - Epoch 194 EVAL  Summary: Avg Loss: 2.7318, Avg Acc: 41.18%, Duration: 0.49s
2025-06-03 23:53:10,796 - INFO - Epoch 195/300 | Batch 0/24 | Loss: 3.1366 | Acc: 33.42% | LR: 2.78e-04
2025-06-03 23:53:13,287 - INFO - Epoch 195 TRAIN Summary: Avg Loss: 3.2430, Avg Acc: 29.27%, Duration: 3.07s
2025-06-03 23:53:13,786 - INFO - Epoch 195 EVAL  Summary: Avg Loss: 2.7166, Avg Acc: 41.46%, Duration: 0.49s
2025-06-03 23:53:14,361 - INFO - Epoch 196/300 | Batch 0/24 | Loss: 3.0579 | Acc: 31.64% | LR: 2.74e-04
2025-06-03 23:53:16,855 - INFO - Epoch 196 TRAIN Summary: Avg Loss: 3.1858, Avg Acc: 31.17%, Duration: 3.07s
2025-06-03 23:53:17,373 - INFO - Epoch 196 EVAL  Summary: Avg Loss: 2.7152, Avg Acc: 41.67%, Duration: 0.51s
2025-06-03 23:53:17,503 - INFO - Epoch 196: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:53:17,504 - INFO - Epoch 196: 新的最佳准确率: 41.67% (已保存至 best_model.pth)
2025-06-03 23:53:17,974 - INFO - Epoch 197/300 | Batch 0/24 | Loss: 3.2074 | Acc: 29.71% | LR: 2.69e-04
2025-06-03 23:53:20,584 - INFO - Epoch 197 TRAIN Summary: Avg Loss: 3.3200, Avg Acc: 27.24%, Duration: 3.08s
2025-06-03 23:53:21,085 - INFO - Epoch 197 EVAL  Summary: Avg Loss: 2.7243, Avg Acc: 41.41%, Duration: 0.50s
2025-06-03 23:53:21,640 - INFO - Epoch 198/300 | Batch 0/24 | Loss: 3.2677 | Acc: 28.50% | LR: 2.64e-04
2025-06-03 23:53:24,065 - INFO - Epoch 198 TRAIN Summary: Avg Loss: 3.1982, Avg Acc: 29.62%, Duration: 2.98s
2025-06-03 23:53:24,608 - INFO - Epoch 198 EVAL  Summary: Avg Loss: 2.7236, Avg Acc: 41.18%, Duration: 0.54s
2025-06-03 23:53:25,168 - INFO - Epoch 199/300 | Batch 0/24 | Loss: 3.0384 | Acc: 32.21% | LR: 2.60e-04
2025-06-03 23:53:27,565 - INFO - Epoch 199 TRAIN Summary: Avg Loss: 3.2769, Avg Acc: 28.84%, Duration: 2.96s
2025-06-03 23:53:28,085 - INFO - Epoch 199 EVAL  Summary: Avg Loss: 2.7092, Avg Acc: 41.50%, Duration: 0.52s
2025-06-03 23:53:28,651 - INFO - Epoch 200/300 | Batch 0/24 | Loss: 3.1185 | Acc: 32.81% | LR: 2.55e-04
2025-06-03 23:53:31,163 - INFO - Epoch 200 TRAIN Summary: Avg Loss: 3.3434, Avg Acc: 28.04%, Duration: 3.07s
2025-06-03 23:53:31,663 - INFO - Epoch 200 EVAL  Summary: Avg Loss: 2.7104, Avg Acc: 41.30%, Duration: 0.50s
2025-06-03 23:53:31,815 - INFO - Epoch 200: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_200.pth
2025-06-03 23:53:32,399 - INFO - Epoch 201/300 | Batch 0/24 | Loss: 3.2772 | Acc: 29.69% | LR: 2.51e-04
2025-06-03 23:53:34,861 - INFO - Epoch 201 TRAIN Summary: Avg Loss: 3.3437, Avg Acc: 28.07%, Duration: 3.04s
2025-06-03 23:53:35,417 - INFO - Epoch 201 EVAL  Summary: Avg Loss: 2.7195, Avg Acc: 41.29%, Duration: 0.55s
2025-06-03 23:53:35,980 - INFO - Epoch 202/300 | Batch 0/24 | Loss: 3.1303 | Acc: 28.52% | LR: 2.46e-04
2025-06-03 23:53:38,426 - INFO - Epoch 202 TRAIN Summary: Avg Loss: 3.3028, Avg Acc: 28.17%, Duration: 3.01s
2025-06-03 23:53:38,969 - INFO - Epoch 202 EVAL  Summary: Avg Loss: 2.7093, Avg Acc: 41.63%, Duration: 0.54s
2025-06-03 23:53:39,508 - INFO - Epoch 203/300 | Batch 0/24 | Loss: 3.1115 | Acc: 29.30% | LR: 2.42e-04
2025-06-03 23:53:41,927 - INFO - Epoch 203 TRAIN Summary: Avg Loss: 3.2194, Avg Acc: 29.16%, Duration: 2.96s
2025-06-03 23:53:42,426 - INFO - Epoch 203 EVAL  Summary: Avg Loss: 2.7060, Avg Acc: 41.71%, Duration: 0.50s
2025-06-03 23:53:42,579 - INFO - Epoch 203: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:53:42,580 - INFO - Epoch 203: 新的最佳准确率: 41.71% (已保存至 best_model.pth)
2025-06-03 23:53:43,110 - INFO - Epoch 204/300 | Batch 0/24 | Loss: 3.1383 | Acc: 30.61% | LR: 2.37e-04
2025-06-03 23:53:45,574 - INFO - Epoch 204 TRAIN Summary: Avg Loss: 3.2570, Avg Acc: 29.43%, Duration: 2.99s
2025-06-03 23:53:46,084 - INFO - Epoch 204 EVAL  Summary: Avg Loss: 2.7057, Avg Acc: 41.82%, Duration: 0.51s
2025-06-03 23:53:46,250 - INFO - Epoch 204: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:53:46,250 - INFO - Epoch 204: 新的最佳准确率: 41.82% (已保存至 best_model.pth)
2025-06-03 23:53:46,784 - INFO - Epoch 205/300 | Batch 0/24 | Loss: 3.4249 | Acc: 30.23% | LR: 2.33e-04
2025-06-03 23:53:49,227 - INFO - Epoch 205 TRAIN Summary: Avg Loss: 3.2542, Avg Acc: 28.53%, Duration: 2.98s
2025-06-03 23:53:49,732 - INFO - Epoch 205 EVAL  Summary: Avg Loss: 2.7071, Avg Acc: 41.50%, Duration: 0.50s
2025-06-03 23:53:50,378 - INFO - Epoch 206/300 | Batch 0/24 | Loss: 2.9957 | Acc: 35.94% | LR: 2.28e-04
2025-06-03 23:53:52,854 - INFO - Epoch 206 TRAIN Summary: Avg Loss: 3.2508, Avg Acc: 29.55%, Duration: 3.12s
2025-06-03 23:53:53,381 - INFO - Epoch 206 EVAL  Summary: Avg Loss: 2.7002, Avg Acc: 41.78%, Duration: 0.52s
2025-06-03 23:53:53,927 - INFO - Epoch 207/300 | Batch 0/24 | Loss: 3.0850 | Acc: 31.64% | LR: 2.24e-04
2025-06-03 23:53:56,368 - INFO - Epoch 207 TRAIN Summary: Avg Loss: 3.1345, Avg Acc: 31.63%, Duration: 2.98s
2025-06-03 23:53:56,844 - INFO - Epoch 207 EVAL  Summary: Avg Loss: 2.7084, Avg Acc: 41.91%, Duration: 0.47s
2025-06-03 23:53:57,102 - INFO - Epoch 207: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:53:57,104 - INFO - Epoch 207: 新的最佳准确率: 41.91% (已保存至 best_model.pth)
2025-06-03 23:53:57,693 - INFO - Epoch 208/300 | Batch 0/24 | Loss: 2.9500 | Acc: 34.77% | LR: 2.20e-04
2025-06-03 23:54:00,104 - INFO - Epoch 208 TRAIN Summary: Avg Loss: 3.3095, Avg Acc: 28.19%, Duration: 3.00s
2025-06-03 23:54:00,621 - INFO - Epoch 208 EVAL  Summary: Avg Loss: 2.7082, Avg Acc: 41.84%, Duration: 0.51s
2025-06-03 23:54:01,186 - INFO - Epoch 209/300 | Batch 0/24 | Loss: 3.2379 | Acc: 30.51% | LR: 2.15e-04
2025-06-03 23:54:03,622 - INFO - Epoch 209 TRAIN Summary: Avg Loss: 3.2547, Avg Acc: 28.97%, Duration: 3.00s
2025-06-03 23:54:04,118 - INFO - Epoch 209 EVAL  Summary: Avg Loss: 2.7099, Avg Acc: 41.58%, Duration: 0.49s
2025-06-03 23:54:04,683 - INFO - Epoch 210/300 | Batch 0/24 | Loss: 3.1698 | Acc: 32.03% | LR: 2.11e-04
2025-06-03 23:54:07,183 - INFO - Epoch 210 TRAIN Summary: Avg Loss: 3.3554, Avg Acc: 27.26%, Duration: 3.06s
2025-06-03 23:54:07,698 - INFO - Epoch 210 EVAL  Summary: Avg Loss: 2.6991, Avg Acc: 41.92%, Duration: 0.51s
2025-06-03 23:54:07,841 - INFO - Epoch 210: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:07,841 - INFO - Epoch 210: 新的最佳准确率: 41.92% (已保存至 best_model.pth)
2025-06-03 23:54:08,409 - INFO - Epoch 211/300 | Batch 0/24 | Loss: 3.0954 | Acc: 34.18% | LR: 2.07e-04
2025-06-03 23:54:11,103 - INFO - Epoch 211 TRAIN Summary: Avg Loss: 3.3581, Avg Acc: 27.84%, Duration: 3.26s
2025-06-03 23:54:11,623 - INFO - Epoch 211 EVAL  Summary: Avg Loss: 2.7137, Avg Acc: 41.34%, Duration: 0.52s
2025-06-03 23:54:12,189 - INFO - Epoch 212/300 | Batch 0/24 | Loss: 3.0671 | Acc: 32.03% | LR: 2.03e-04
2025-06-03 23:54:14,623 - INFO - Epoch 212 TRAIN Summary: Avg Loss: 3.2808, Avg Acc: 28.60%, Duration: 3.00s
2025-06-03 23:54:15,106 - INFO - Epoch 212 EVAL  Summary: Avg Loss: 2.7034, Avg Acc: 41.93%, Duration: 0.48s
2025-06-03 23:54:15,234 - INFO - Epoch 212: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:15,234 - INFO - Epoch 212: 新的最佳准确率: 41.93% (已保存至 best_model.pth)
2025-06-03 23:54:15,803 - INFO - Epoch 213/300 | Batch 0/24 | Loss: 3.8632 | Acc: 18.34% | LR: 1.99e-04
2025-06-03 23:54:18,221 - INFO - Epoch 213 TRAIN Summary: Avg Loss: 3.2920, Avg Acc: 28.19%, Duration: 2.99s
2025-06-03 23:54:18,720 - INFO - Epoch 213 EVAL  Summary: Avg Loss: 2.7014, Avg Acc: 41.89%, Duration: 0.50s
2025-06-03 23:54:19,285 - INFO - Epoch 214/300 | Batch 0/24 | Loss: 3.0899 | Acc: 31.66% | LR: 1.94e-04
2025-06-03 23:54:21,804 - INFO - Epoch 214 TRAIN Summary: Avg Loss: 3.1338, Avg Acc: 30.72%, Duration: 3.08s
2025-06-03 23:54:22,319 - INFO - Epoch 214 EVAL  Summary: Avg Loss: 2.7052, Avg Acc: 41.84%, Duration: 0.51s
2025-06-03 23:54:22,885 - INFO - Epoch 215/300 | Batch 0/24 | Loss: 3.1788 | Acc: 27.73% | LR: 1.90e-04
2025-06-03 23:54:25,290 - INFO - Epoch 215 TRAIN Summary: Avg Loss: 3.1278, Avg Acc: 31.33%, Duration: 2.97s
2025-06-03 23:54:25,809 - INFO - Epoch 215 EVAL  Summary: Avg Loss: 2.6946, Avg Acc: 42.14%, Duration: 0.52s
2025-06-03 23:54:25,976 - INFO - Epoch 215: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:25,977 - INFO - Epoch 215: 新的最佳准确率: 42.14% (已保存至 best_model.pth)
2025-06-03 23:54:26,535 - INFO - Epoch 216/300 | Batch 0/24 | Loss: 3.1001 | Acc: 32.42% | LR: 1.86e-04
2025-06-03 23:54:28,934 - INFO - Epoch 216 TRAIN Summary: Avg Loss: 3.1721, Avg Acc: 30.35%, Duration: 2.96s
2025-06-03 23:54:29,448 - INFO - Epoch 216 EVAL  Summary: Avg Loss: 2.7021, Avg Acc: 41.82%, Duration: 0.51s
2025-06-03 23:54:30,013 - INFO - Epoch 217/300 | Batch 0/24 | Loss: 3.1438 | Acc: 30.86% | LR: 1.82e-04
2025-06-03 23:54:32,470 - INFO - Epoch 217 TRAIN Summary: Avg Loss: 3.2592, Avg Acc: 29.06%, Duration: 3.02s
2025-06-03 23:54:32,991 - INFO - Epoch 217 EVAL  Summary: Avg Loss: 2.6954, Avg Acc: 42.02%, Duration: 0.52s
2025-06-03 23:54:33,563 - INFO - Epoch 218/300 | Batch 0/24 | Loss: 3.1242 | Acc: 29.69% | LR: 1.78e-04
2025-06-03 23:54:36,076 - INFO - Epoch 218 TRAIN Summary: Avg Loss: 3.2250, Avg Acc: 29.22%, Duration: 3.08s
2025-06-03 23:54:36,595 - INFO - Epoch 218 EVAL  Summary: Avg Loss: 2.6998, Avg Acc: 42.15%, Duration: 0.52s
2025-06-03 23:54:36,747 - INFO - Epoch 218: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:36,747 - INFO - Epoch 218: 新的最佳准确率: 42.15% (已保存至 best_model.pth)
2025-06-03 23:54:37,268 - INFO - Epoch 219/300 | Batch 0/24 | Loss: 3.1953 | Acc: 30.47% | LR: 1.74e-04
2025-06-03 23:54:39,687 - INFO - Epoch 219 TRAIN Summary: Avg Loss: 3.2700, Avg Acc: 29.18%, Duration: 2.94s
2025-06-03 23:54:40,184 - INFO - Epoch 219 EVAL  Summary: Avg Loss: 2.6940, Avg Acc: 42.04%, Duration: 0.49s
2025-06-03 23:54:40,764 - INFO - Epoch 220/300 | Batch 0/24 | Loss: 3.0268 | Acc: 32.81% | LR: 1.70e-04
2025-06-03 23:54:43,178 - INFO - Epoch 220 TRAIN Summary: Avg Loss: 3.2118, Avg Acc: 30.59%, Duration: 2.99s
2025-06-03 23:54:43,673 - INFO - Epoch 220 EVAL  Summary: Avg Loss: 2.6904, Avg Acc: 42.21%, Duration: 0.49s
2025-06-03 23:54:43,805 - INFO - Epoch 220: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:43,806 - INFO - Epoch 220: 新的最佳准确率: 42.21% (已保存至 best_model.pth)
2025-06-03 23:54:43,914 - INFO - Epoch 220: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_220.pth
2025-06-03 23:54:44,454 - INFO - Epoch 221/300 | Batch 0/24 | Loss: 3.3039 | Acc: 27.15% | LR: 1.66e-04
2025-06-03 23:54:46,928 - INFO - Epoch 221 TRAIN Summary: Avg Loss: 3.2455, Avg Acc: 29.49%, Duration: 3.01s
2025-06-03 23:54:47,447 - INFO - Epoch 221 EVAL  Summary: Avg Loss: 2.6949, Avg Acc: 42.08%, Duration: 0.52s
2025-06-03 23:54:48,038 - INFO - Epoch 222/300 | Batch 0/24 | Loss: 3.0324 | Acc: 32.81% | LR: 1.62e-04
2025-06-03 23:54:50,500 - INFO - Epoch 222 TRAIN Summary: Avg Loss: 3.2471, Avg Acc: 29.22%, Duration: 3.05s
2025-06-03 23:54:50,987 - INFO - Epoch 222 EVAL  Summary: Avg Loss: 2.6871, Avg Acc: 42.13%, Duration: 0.48s
2025-06-03 23:54:51,584 - INFO - Epoch 223/300 | Batch 0/24 | Loss: 3.1065 | Acc: 32.81% | LR: 1.59e-04
2025-06-03 23:54:54,101 - INFO - Epoch 223 TRAIN Summary: Avg Loss: 3.2768, Avg Acc: 29.48%, Duration: 3.11s
2025-06-03 23:54:54,602 - INFO - Epoch 223 EVAL  Summary: Avg Loss: 2.6917, Avg Acc: 42.32%, Duration: 0.50s
2025-06-03 23:54:54,753 - INFO - Epoch 223: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:54,753 - INFO - Epoch 223: 新的最佳准确率: 42.32% (已保存至 best_model.pth)
2025-06-03 23:54:55,295 - INFO - Epoch 224/300 | Batch 0/24 | Loss: 4.0395 | Acc: 16.28% | LR: 1.55e-04
2025-06-03 23:54:57,817 - INFO - Epoch 224 TRAIN Summary: Avg Loss: 3.3704, Avg Acc: 26.82%, Duration: 3.06s
2025-06-03 23:54:58,307 - INFO - Epoch 224 EVAL  Summary: Avg Loss: 2.6879, Avg Acc: 42.39%, Duration: 0.49s
2025-06-03 23:54:58,525 - INFO - Epoch 224: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:54:58,527 - INFO - Epoch 224: 新的最佳准确率: 42.39% (已保存至 best_model.pth)
2025-06-03 23:54:59,069 - INFO - Epoch 225/300 | Batch 0/24 | Loss: 3.0213 | Acc: 36.72% | LR: 1.51e-04
2025-06-03 23:55:01,472 - INFO - Epoch 225 TRAIN Summary: Avg Loss: 3.2970, Avg Acc: 29.09%, Duration: 2.94s
2025-06-03 23:55:01,975 - INFO - Epoch 225 EVAL  Summary: Avg Loss: 2.6954, Avg Acc: 42.16%, Duration: 0.50s
2025-06-03 23:55:02,593 - INFO - Epoch 226/300 | Batch 0/24 | Loss: 3.0766 | Acc: 33.98% | LR: 1.47e-04
2025-06-03 23:55:05,098 - INFO - Epoch 226 TRAIN Summary: Avg Loss: 3.1848, Avg Acc: 30.65%, Duration: 3.12s
2025-06-03 23:55:05,799 - INFO - Epoch 226 EVAL  Summary: Avg Loss: 2.6960, Avg Acc: 42.16%, Duration: 0.70s
2025-06-03 23:55:06,836 - INFO - Epoch 227/300 | Batch 0/24 | Loss: 3.1677 | Acc: 28.52% | LR: 1.44e-04
2025-06-03 23:55:09,684 - INFO - Epoch 227 TRAIN Summary: Avg Loss: 3.1657, Avg Acc: 30.89%, Duration: 3.88s
2025-06-03 23:55:10,193 - INFO - Epoch 227 EVAL  Summary: Avg Loss: 2.6925, Avg Acc: 42.12%, Duration: 0.51s
2025-06-03 23:55:10,762 - INFO - Epoch 228/300 | Batch 0/24 | Loss: 3.5217 | Acc: 24.66% | LR: 1.40e-04
2025-06-03 23:55:13,402 - INFO - Epoch 228 TRAIN Summary: Avg Loss: 3.1461, Avg Acc: 31.77%, Duration: 3.21s
2025-06-03 23:55:13,896 - INFO - Epoch 228 EVAL  Summary: Avg Loss: 2.6844, Avg Acc: 42.08%, Duration: 0.49s
2025-06-03 23:55:14,456 - INFO - Epoch 229/300 | Batch 0/24 | Loss: 3.2403 | Acc: 24.61% | LR: 1.36e-04
2025-06-03 23:55:17,279 - INFO - Epoch 229 TRAIN Summary: Avg Loss: 3.2016, Avg Acc: 30.54%, Duration: 3.38s
2025-06-03 23:55:17,768 - INFO - Epoch 229 EVAL  Summary: Avg Loss: 2.6891, Avg Acc: 42.16%, Duration: 0.49s
2025-06-03 23:55:18,344 - INFO - Epoch 230/300 | Batch 0/24 | Loss: 3.1042 | Acc: 30.84% | LR: 1.33e-04
2025-06-03 23:55:21,079 - INFO - Epoch 230 TRAIN Summary: Avg Loss: 3.3638, Avg Acc: 27.18%, Duration: 3.31s
2025-06-03 23:55:21,624 - INFO - Epoch 230 EVAL  Summary: Avg Loss: 2.6891, Avg Acc: 41.89%, Duration: 0.54s
2025-06-03 23:55:22,209 - INFO - Epoch 231/300 | Batch 0/24 | Loss: 3.2510 | Acc: 29.13% | LR: 1.29e-04
2025-06-03 23:55:24,734 - INFO - Epoch 231 TRAIN Summary: Avg Loss: 3.1754, Avg Acc: 31.37%, Duration: 3.11s
2025-06-03 23:55:25,233 - INFO - Epoch 231 EVAL  Summary: Avg Loss: 2.6875, Avg Acc: 42.23%, Duration: 0.50s
2025-06-03 23:55:25,800 - INFO - Epoch 232/300 | Batch 0/24 | Loss: 3.4037 | Acc: 26.66% | LR: 1.26e-04
2025-06-03 23:55:28,235 - INFO - Epoch 232 TRAIN Summary: Avg Loss: 3.1915, Avg Acc: 31.44%, Duration: 3.00s
2025-06-03 23:55:28,762 - INFO - Epoch 232 EVAL  Summary: Avg Loss: 2.6893, Avg Acc: 41.82%, Duration: 0.52s
2025-06-03 23:55:29,336 - INFO - Epoch 233/300 | Batch 0/24 | Loss: 3.0588 | Acc: 32.42% | LR: 1.22e-04
2025-06-03 23:55:31,770 - INFO - Epoch 233 TRAIN Summary: Avg Loss: 3.1843, Avg Acc: 30.58%, Duration: 3.01s
2025-06-03 23:55:32,276 - INFO - Epoch 233 EVAL  Summary: Avg Loss: 2.6852, Avg Acc: 42.13%, Duration: 0.50s
2025-06-03 23:55:32,856 - INFO - Epoch 234/300 | Batch 0/24 | Loss: 3.2736 | Acc: 29.20% | LR: 1.19e-04
2025-06-03 23:55:35,547 - INFO - Epoch 234 TRAIN Summary: Avg Loss: 3.2140, Avg Acc: 30.19%, Duration: 3.27s
2025-06-03 23:55:36,032 - INFO - Epoch 234 EVAL  Summary: Avg Loss: 2.6866, Avg Acc: 42.27%, Duration: 0.48s
2025-06-03 23:55:36,612 - INFO - Epoch 235/300 | Batch 0/24 | Loss: 3.1158 | Acc: 32.03% | LR: 1.16e-04
2025-06-03 23:55:39,094 - INFO - Epoch 235 TRAIN Summary: Avg Loss: 3.2037, Avg Acc: 30.09%, Duration: 3.06s
2025-06-03 23:55:39,637 - INFO - Epoch 235 EVAL  Summary: Avg Loss: 2.6827, Avg Acc: 42.07%, Duration: 0.54s
2025-06-03 23:55:40,205 - INFO - Epoch 236/300 | Batch 0/24 | Loss: 3.1970 | Acc: 28.91% | LR: 1.12e-04
2025-06-03 23:55:42,594 - INFO - Epoch 236 TRAIN Summary: Avg Loss: 3.2561, Avg Acc: 29.86%, Duration: 2.96s
2025-06-03 23:55:43,134 - INFO - Epoch 236 EVAL  Summary: Avg Loss: 2.6870, Avg Acc: 42.05%, Duration: 0.54s
2025-06-03 23:55:43,691 - INFO - Epoch 237/300 | Batch 0/24 | Loss: 3.0945 | Acc: 36.92% | LR: 1.09e-04
2025-06-03 23:55:46,095 - INFO - Epoch 237 TRAIN Summary: Avg Loss: 3.2383, Avg Acc: 29.74%, Duration: 2.96s
2025-06-03 23:55:46,623 - INFO - Epoch 237 EVAL  Summary: Avg Loss: 2.6812, Avg Acc: 42.27%, Duration: 0.52s
2025-06-03 23:55:47,180 - INFO - Epoch 238/300 | Batch 0/24 | Loss: 3.0716 | Acc: 31.64% | LR: 1.06e-04
2025-06-03 23:55:49,657 - INFO - Epoch 238 TRAIN Summary: Avg Loss: 3.3256, Avg Acc: 27.71%, Duration: 3.03s
2025-06-03 23:55:50,150 - INFO - Epoch 238 EVAL  Summary: Avg Loss: 2.6852, Avg Acc: 41.94%, Duration: 0.49s
2025-06-03 23:55:50,713 - INFO - Epoch 239/300 | Batch 0/24 | Loss: 3.2491 | Acc: 30.77% | LR: 1.03e-04
2025-06-03 23:55:53,146 - INFO - Epoch 239 TRAIN Summary: Avg Loss: 3.2238, Avg Acc: 30.36%, Duration: 2.99s
2025-06-03 23:55:53,639 - INFO - Epoch 239 EVAL  Summary: Avg Loss: 2.6807, Avg Acc: 42.55%, Duration: 0.49s
2025-06-03 23:55:53,780 - INFO - Epoch 239: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:55:53,781 - INFO - Epoch 239: 新的最佳准确率: 42.55% (已保存至 best_model.pth)
2025-06-03 23:55:54,316 - INFO - Epoch 240/300 | Batch 0/24 | Loss: 3.0680 | Acc: 38.05% | LR: 9.95e-05
2025-06-03 23:55:56,758 - INFO - Epoch 240 TRAIN Summary: Avg Loss: 3.1906, Avg Acc: 31.37%, Duration: 2.98s
2025-06-03 23:55:57,319 - INFO - Epoch 240 EVAL  Summary: Avg Loss: 2.6772, Avg Acc: 42.37%, Duration: 0.56s
2025-06-03 23:55:57,463 - INFO - Epoch 240: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_240.pth
2025-06-03 23:55:58,024 - INFO - Epoch 241/300 | Batch 0/24 | Loss: 3.0111 | Acc: 32.42% | LR: 9.64e-05
2025-06-03 23:56:00,429 - INFO - Epoch 241 TRAIN Summary: Avg Loss: 3.1518, Avg Acc: 31.45%, Duration: 2.96s
2025-06-03 23:56:00,912 - INFO - Epoch 241 EVAL  Summary: Avg Loss: 2.6774, Avg Acc: 42.11%, Duration: 0.48s
2025-06-03 23:56:01,487 - INFO - Epoch 242/300 | Batch 0/24 | Loss: 3.1184 | Acc: 31.91% | LR: 9.33e-05
2025-06-03 23:56:03,906 - INFO - Epoch 242 TRAIN Summary: Avg Loss: 3.3130, Avg Acc: 28.14%, Duration: 2.99s
2025-06-03 23:56:04,433 - INFO - Epoch 242 EVAL  Summary: Avg Loss: 2.6782, Avg Acc: 42.27%, Duration: 0.52s
2025-06-03 23:56:04,995 - INFO - Epoch 243/300 | Batch 0/24 | Loss: 3.1937 | Acc: 30.27% | LR: 9.03e-05
2025-06-03 23:56:07,449 - INFO - Epoch 243 TRAIN Summary: Avg Loss: 3.2429, Avg Acc: 29.44%, Duration: 3.01s
2025-06-03 23:56:07,968 - INFO - Epoch 243 EVAL  Summary: Avg Loss: 2.6769, Avg Acc: 42.41%, Duration: 0.52s
2025-06-03 23:56:08,533 - INFO - Epoch 244/300 | Batch 0/24 | Loss: 3.1782 | Acc: 29.69% | LR: 8.74e-05
2025-06-03 23:56:11,018 - INFO - Epoch 244 TRAIN Summary: Avg Loss: 3.2840, Avg Acc: 28.95%, Duration: 3.05s
2025-06-03 23:56:11,563 - INFO - Epoch 244 EVAL  Summary: Avg Loss: 2.6708, Avg Acc: 42.53%, Duration: 0.54s
2025-06-03 23:56:12,124 - INFO - Epoch 245/300 | Batch 0/24 | Loss: 3.6163 | Acc: 27.34% | LR: 8.45e-05
2025-06-03 23:56:14,529 - INFO - Epoch 245 TRAIN Summary: Avg Loss: 3.2033, Avg Acc: 30.95%, Duration: 2.96s
2025-06-03 23:56:15,035 - INFO - Epoch 245 EVAL  Summary: Avg Loss: 2.6796, Avg Acc: 42.15%, Duration: 0.50s
2025-06-03 23:56:15,606 - INFO - Epoch 246/300 | Batch 0/24 | Loss: 3.0159 | Acc: 35.16% | LR: 8.16e-05
2025-06-03 23:56:17,981 - INFO - Epoch 246 TRAIN Summary: Avg Loss: 3.1245, Avg Acc: 31.15%, Duration: 2.94s
2025-06-03 23:56:18,498 - INFO - Epoch 246 EVAL  Summary: Avg Loss: 2.6757, Avg Acc: 42.38%, Duration: 0.52s
2025-06-03 23:56:19,072 - INFO - Epoch 247/300 | Batch 0/24 | Loss: 3.8041 | Acc: 19.85% | LR: 7.88e-05
2025-06-03 23:56:21,467 - INFO - Epoch 247 TRAIN Summary: Avg Loss: 3.2984, Avg Acc: 28.78%, Duration: 2.97s
2025-06-03 23:56:21,980 - INFO - Epoch 247 EVAL  Summary: Avg Loss: 2.6783, Avg Acc: 42.39%, Duration: 0.51s
2025-06-03 23:56:22,553 - INFO - Epoch 248/300 | Batch 0/24 | Loss: 3.1573 | Acc: 33.59% | LR: 7.60e-05
2025-06-03 23:56:24,923 - INFO - Epoch 248 TRAIN Summary: Avg Loss: 3.2307, Avg Acc: 30.38%, Duration: 2.94s
2025-06-03 23:56:25,457 - INFO - Epoch 248 EVAL  Summary: Avg Loss: 2.6777, Avg Acc: 42.37%, Duration: 0.53s
2025-06-03 23:56:26,032 - INFO - Epoch 249/300 | Batch 0/24 | Loss: 3.0420 | Acc: 35.94% | LR: 7.32e-05
2025-06-03 23:56:28,452 - INFO - Epoch 249 TRAIN Summary: Avg Loss: 3.1089, Avg Acc: 32.62%, Duration: 2.99s
2025-06-03 23:56:28,966 - INFO - Epoch 249 EVAL  Summary: Avg Loss: 2.6764, Avg Acc: 42.49%, Duration: 0.51s
2025-06-03 23:56:29,538 - INFO - Epoch 250/300 | Batch 0/24 | Loss: 3.1282 | Acc: 33.20% | LR: 7.06e-05
2025-06-03 23:56:32,022 - INFO - Epoch 250 TRAIN Summary: Avg Loss: 3.1118, Avg Acc: 32.27%, Duration: 3.05s
2025-06-03 23:56:32,542 - INFO - Epoch 250 EVAL  Summary: Avg Loss: 2.6725, Avg Acc: 42.52%, Duration: 0.52s
2025-06-03 23:56:33,115 - INFO - Epoch 251/300 | Batch 0/24 | Loss: 2.9492 | Acc: 34.77% | LR: 6.79e-05
2025-06-03 23:56:35,548 - INFO - Epoch 251 TRAIN Summary: Avg Loss: 3.0687, Avg Acc: 31.74%, Duration: 3.01s
2025-06-03 23:56:36,058 - INFO - Epoch 251 EVAL  Summary: Avg Loss: 2.6753, Avg Acc: 42.40%, Duration: 0.51s
2025-06-03 23:56:36,644 - INFO - Epoch 252/300 | Batch 0/24 | Loss: 4.0451 | Acc: 14.70% | LR: 6.53e-05
2025-06-03 23:56:39,143 - INFO - Epoch 252 TRAIN Summary: Avg Loss: 3.2399, Avg Acc: 29.39%, Duration: 3.08s
2025-06-03 23:56:39,663 - INFO - Epoch 252 EVAL  Summary: Avg Loss: 2.6746, Avg Acc: 42.24%, Duration: 0.52s
2025-06-03 23:56:40,237 - INFO - Epoch 253/300 | Batch 0/24 | Loss: 3.2101 | Acc: 30.81% | LR: 6.28e-05
2025-06-03 23:56:42,734 - INFO - Epoch 253 TRAIN Summary: Avg Loss: 3.1714, Avg Acc: 31.20%, Duration: 3.07s
2025-06-03 23:56:43,250 - INFO - Epoch 253 EVAL  Summary: Avg Loss: 2.6730, Avg Acc: 42.57%, Duration: 0.51s
2025-06-03 23:56:43,427 - INFO - Epoch 253: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:56:43,428 - INFO - Epoch 253: 新的最佳准确率: 42.57% (已保存至 best_model.pth)
2025-06-03 23:56:43,962 - INFO - Epoch 254/300 | Batch 0/24 | Loss: 3.0322 | Acc: 33.59% | LR: 6.03e-05
2025-06-03 23:56:46,386 - INFO - Epoch 254 TRAIN Summary: Avg Loss: 3.2554, Avg Acc: 30.28%, Duration: 2.96s
2025-06-03 23:56:46,926 - INFO - Epoch 254 EVAL  Summary: Avg Loss: 2.6771, Avg Acc: 42.48%, Duration: 0.54s
2025-06-03 23:56:47,541 - INFO - Epoch 255/300 | Batch 0/24 | Loss: 3.0391 | Acc: 33.20% | LR: 5.78e-05
2025-06-03 23:56:49,922 - INFO - Epoch 255 TRAIN Summary: Avg Loss: 3.1599, Avg Acc: 31.43%, Duration: 2.99s
2025-06-03 23:56:50,449 - INFO - Epoch 255 EVAL  Summary: Avg Loss: 2.6733, Avg Acc: 42.54%, Duration: 0.52s
2025-06-03 23:56:51,022 - INFO - Epoch 256/300 | Batch 0/24 | Loss: 3.1426 | Acc: 30.07% | LR: 5.54e-05
2025-06-03 23:56:53,476 - INFO - Epoch 256 TRAIN Summary: Avg Loss: 3.2109, Avg Acc: 30.34%, Duration: 3.02s
2025-06-03 23:56:54,002 - INFO - Epoch 256 EVAL  Summary: Avg Loss: 2.6728, Avg Acc: 42.51%, Duration: 0.52s
2025-06-03 23:56:54,577 - INFO - Epoch 257/300 | Batch 0/24 | Loss: 4.2231 | Acc: 9.68% | LR: 5.31e-05
2025-06-03 23:56:56,997 - INFO - Epoch 257 TRAIN Summary: Avg Loss: 3.1184, Avg Acc: 32.08%, Duration: 2.99s
2025-06-03 23:56:57,510 - INFO - Epoch 257 EVAL  Summary: Avg Loss: 2.6719, Avg Acc: 42.29%, Duration: 0.51s
2025-06-03 23:56:58,083 - INFO - Epoch 258/300 | Batch 0/24 | Loss: 3.0404 | Acc: 34.77% | LR: 5.08e-05
2025-06-03 23:57:00,512 - INFO - Epoch 258 TRAIN Summary: Avg Loss: 3.2671, Avg Acc: 29.59%, Duration: 3.00s
2025-06-03 23:57:01,031 - INFO - Epoch 258 EVAL  Summary: Avg Loss: 2.6720, Avg Acc: 42.38%, Duration: 0.52s
2025-06-03 23:57:01,609 - INFO - Epoch 259/300 | Batch 0/24 | Loss: 2.9958 | Acc: 34.38% | LR: 4.85e-05
2025-06-03 23:57:04,061 - INFO - Epoch 259 TRAIN Summary: Avg Loss: 3.2969, Avg Acc: 29.06%, Duration: 3.03s
2025-06-03 23:57:04,566 - INFO - Epoch 259 EVAL  Summary: Avg Loss: 2.6716, Avg Acc: 42.49%, Duration: 0.50s
2025-06-03 23:57:05,123 - INFO - Epoch 260/300 | Batch 0/24 | Loss: 3.1058 | Acc: 32.03% | LR: 4.63e-05
2025-06-03 23:57:07,556 - INFO - Epoch 260 TRAIN Summary: Avg Loss: 3.1838, Avg Acc: 31.19%, Duration: 2.99s
2025-06-03 23:57:08,074 - INFO - Epoch 260 EVAL  Summary: Avg Loss: 2.6705, Avg Acc: 42.65%, Duration: 0.52s
2025-06-03 23:57:08,209 - INFO - Epoch 260: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:57:08,209 - INFO - Epoch 260: 新的最佳准确率: 42.65% (已保存至 best_model.pth)
2025-06-03 23:57:08,308 - INFO - Epoch 260: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_260.pth
2025-06-03 23:57:08,783 - INFO - Epoch 261/300 | Batch 0/24 | Loss: 3.3996 | Acc: 26.62% | LR: 4.42e-05
2025-06-03 23:57:11,232 - INFO - Epoch 261 TRAIN Summary: Avg Loss: 3.2036, Avg Acc: 31.45%, Duration: 2.92s
2025-06-03 23:57:11,757 - INFO - Epoch 261 EVAL  Summary: Avg Loss: 2.6704, Avg Acc: 42.45%, Duration: 0.52s
2025-06-03 23:57:12,330 - INFO - Epoch 262/300 | Batch 0/24 | Loss: 3.0035 | Acc: 33.20% | LR: 4.21e-05
2025-06-03 23:57:14,761 - INFO - Epoch 262 TRAIN Summary: Avg Loss: 3.2347, Avg Acc: 30.12%, Duration: 3.00s
2025-06-03 23:57:15,313 - INFO - Epoch 262 EVAL  Summary: Avg Loss: 2.6691, Avg Acc: 42.44%, Duration: 0.55s
2025-06-03 23:57:15,897 - INFO - Epoch 263/300 | Batch 0/24 | Loss: 3.1881 | Acc: 27.05% | LR: 4.00e-05
2025-06-03 23:57:18,303 - INFO - Epoch 263 TRAIN Summary: Avg Loss: 3.1628, Avg Acc: 30.20%, Duration: 2.99s
2025-06-03 23:57:18,868 - INFO - Epoch 263 EVAL  Summary: Avg Loss: 2.6707, Avg Acc: 42.44%, Duration: 0.56s
2025-06-03 23:57:19,446 - INFO - Epoch 264/300 | Batch 0/24 | Loss: 3.1825 | Acc: 31.64% | LR: 3.80e-05
2025-06-03 23:57:21,867 - INFO - Epoch 264 TRAIN Summary: Avg Loss: 3.1287, Avg Acc: 32.09%, Duration: 3.00s
2025-06-03 23:57:22,390 - INFO - Epoch 264 EVAL  Summary: Avg Loss: 2.6686, Avg Acc: 42.47%, Duration: 0.52s
2025-06-03 23:57:22,983 - INFO - Epoch 265/300 | Batch 0/24 | Loss: 2.9558 | Acc: 34.77% | LR: 3.61e-05
2025-06-03 23:57:25,371 - INFO - Epoch 265 TRAIN Summary: Avg Loss: 3.2528, Avg Acc: 29.52%, Duration: 2.98s
2025-06-03 23:57:25,879 - INFO - Epoch 265 EVAL  Summary: Avg Loss: 2.6682, Avg Acc: 42.68%, Duration: 0.50s
2025-06-03 23:57:26,021 - INFO - Epoch 265: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:57:26,021 - INFO - Epoch 265: 新的最佳准确率: 42.68% (已保存至 best_model.pth)
2025-06-03 23:57:26,610 - INFO - Epoch 266/300 | Batch 0/24 | Loss: 3.0957 | Acc: 32.97% | LR: 3.42e-05
2025-06-03 23:57:29,096 - INFO - Epoch 266 TRAIN Summary: Avg Loss: 3.2061, Avg Acc: 29.49%, Duration: 3.07s
2025-06-03 23:57:29,623 - INFO - Epoch 266 EVAL  Summary: Avg Loss: 2.6679, Avg Acc: 42.59%, Duration: 0.52s
2025-06-03 23:57:30,204 - INFO - Epoch 267/300 | Batch 0/24 | Loss: 2.9134 | Acc: 36.31% | LR: 3.23e-05
2025-06-03 23:57:32,682 - INFO - Epoch 267 TRAIN Summary: Avg Loss: 3.2393, Avg Acc: 29.56%, Duration: 3.06s
2025-06-03 23:57:33,196 - INFO - Epoch 267 EVAL  Summary: Avg Loss: 2.6707, Avg Acc: 42.60%, Duration: 0.51s
2025-06-03 23:57:33,765 - INFO - Epoch 268/300 | Batch 0/24 | Loss: 3.0946 | Acc: 34.38% | LR: 3.05e-05
2025-06-03 23:57:36,168 - INFO - Epoch 268 TRAIN Summary: Avg Loss: 3.3138, Avg Acc: 27.70%, Duration: 2.97s
2025-06-03 23:57:36,673 - INFO - Epoch 268 EVAL  Summary: Avg Loss: 2.6720, Avg Acc: 42.60%, Duration: 0.50s
2025-06-03 23:57:37,247 - INFO - Epoch 269/300 | Batch 0/24 | Loss: 3.0528 | Acc: 33.98% | LR: 2.88e-05
2025-06-03 23:57:39,962 - INFO - Epoch 269 TRAIN Summary: Avg Loss: 3.1217, Avg Acc: 32.04%, Duration: 3.29s
2025-06-03 23:57:40,467 - INFO - Epoch 269 EVAL  Summary: Avg Loss: 2.6711, Avg Acc: 42.64%, Duration: 0.50s
2025-06-03 23:57:41,032 - INFO - Epoch 270/300 | Batch 0/24 | Loss: 3.0371 | Acc: 35.16% | LR: 2.71e-05
2025-06-03 23:57:43,887 - INFO - Epoch 270 TRAIN Summary: Avg Loss: 3.3342, Avg Acc: 28.51%, Duration: 3.42s
2025-06-03 23:57:44,406 - INFO - Epoch 270 EVAL  Summary: Avg Loss: 2.6701, Avg Acc: 42.56%, Duration: 0.52s
2025-06-03 23:57:44,970 - INFO - Epoch 271/300 | Batch 0/24 | Loss: 3.0075 | Acc: 33.59% | LR: 2.54e-05
2025-06-03 23:57:47,966 - INFO - Epoch 271 TRAIN Summary: Avg Loss: 3.2050, Avg Acc: 30.28%, Duration: 3.56s
2025-06-03 23:57:48,492 - INFO - Epoch 271 EVAL  Summary: Avg Loss: 2.6675, Avg Acc: 42.46%, Duration: 0.52s
2025-06-03 23:57:49,075 - INFO - Epoch 272/300 | Batch 0/24 | Loss: 3.0037 | Acc: 34.38% | LR: 2.39e-05
2025-06-03 23:57:51,744 - INFO - Epoch 272 TRAIN Summary: Avg Loss: 3.1529, Avg Acc: 31.18%, Duration: 3.25s
2025-06-03 23:57:52,276 - INFO - Epoch 272 EVAL  Summary: Avg Loss: 2.6682, Avg Acc: 42.48%, Duration: 0.53s
2025-06-03 23:57:52,857 - INFO - Epoch 273/300 | Batch 0/24 | Loss: 3.0745 | Acc: 34.84% | LR: 2.23e-05
2025-06-03 23:57:55,286 - INFO - Epoch 273 TRAIN Summary: Avg Loss: 3.2420, Avg Acc: 29.88%, Duration: 3.01s
2025-06-03 23:57:55,782 - INFO - Epoch 273 EVAL  Summary: Avg Loss: 2.6673, Avg Acc: 42.67%, Duration: 0.49s
2025-06-03 23:57:56,389 - INFO - Epoch 274/300 | Batch 0/24 | Loss: 3.1343 | Acc: 29.69% | LR: 2.08e-05
2025-06-03 23:57:58,839 - INFO - Epoch 274 TRAIN Summary: Avg Loss: 3.2423, Avg Acc: 29.39%, Duration: 3.06s
2025-06-03 23:57:59,339 - INFO - Epoch 274 EVAL  Summary: Avg Loss: 2.6693, Avg Acc: 42.60%, Duration: 0.50s
2025-06-03 23:57:59,901 - INFO - Epoch 275/300 | Batch 0/24 | Loss: 4.1800 | Acc: 12.69% | LR: 1.94e-05
2025-06-03 23:58:02,573 - INFO - Epoch 275 TRAIN Summary: Avg Loss: 3.3395, Avg Acc: 28.23%, Duration: 3.23s
2025-06-03 23:58:03,091 - INFO - Epoch 275 EVAL  Summary: Avg Loss: 2.6678, Avg Acc: 42.82%, Duration: 0.51s
2025-06-03 23:58:03,239 - INFO - Epoch 275: 最佳模型已保存至 ./logs/mlp_mixer_tiny/20250603-234122/best_model.pth
2025-06-03 23:58:03,239 - INFO - Epoch 275: 新的最佳准确率: 42.82% (已保存至 best_model.pth)
2025-06-03 23:58:03,773 - INFO - Epoch 276/300 | Batch 0/24 | Loss: 3.2098 | Acc: 28.15% | LR: 1.80e-05
2025-06-03 23:58:06,190 - INFO - Epoch 276 TRAIN Summary: Avg Loss: 3.2367, Avg Acc: 29.79%, Duration: 2.95s
2025-06-03 23:58:06,697 - INFO - Epoch 276 EVAL  Summary: Avg Loss: 2.6684, Avg Acc: 42.66%, Duration: 0.50s
2025-06-03 23:58:07,283 - INFO - Epoch 277/300 | Batch 0/24 | Loss: 3.1114 | Acc: 30.08% | LR: 1.67e-05
2025-06-03 23:58:09,770 - INFO - Epoch 277 TRAIN Summary: Avg Loss: 3.1939, Avg Acc: 30.32%, Duration: 3.07s
2025-06-03 23:58:10,306 - INFO - Epoch 277 EVAL  Summary: Avg Loss: 2.6672, Avg Acc: 42.58%, Duration: 0.53s
2025-06-03 23:58:10,868 - INFO - Epoch 278/300 | Batch 0/24 | Loss: 3.0863 | Acc: 31.64% | LR: 1.54e-05
2025-06-03 23:58:13,331 - INFO - Epoch 278 TRAIN Summary: Avg Loss: 3.0923, Avg Acc: 33.32%, Duration: 3.02s
2025-06-03 23:58:13,829 - INFO - Epoch 278 EVAL  Summary: Avg Loss: 2.6678, Avg Acc: 42.64%, Duration: 0.50s
2025-06-03 23:58:14,396 - INFO - Epoch 279/300 | Batch 0/24 | Loss: 3.0929 | Acc: 33.20% | LR: 1.42e-05
2025-06-03 23:58:16,770 - INFO - Epoch 279 TRAIN Summary: Avg Loss: 3.1655, Avg Acc: 31.37%, Duration: 2.94s
2025-06-03 23:58:17,258 - INFO - Epoch 279 EVAL  Summary: Avg Loss: 2.6661, Avg Acc: 42.57%, Duration: 0.49s
2025-06-03 23:58:17,818 - INFO - Epoch 280/300 | Batch 0/24 | Loss: 3.1404 | Acc: 28.12% | LR: 1.30e-05
2025-06-03 23:58:20,314 - INFO - Epoch 280 TRAIN Summary: Avg Loss: 3.1986, Avg Acc: 30.16%, Duration: 3.05s
2025-06-03 23:58:20,840 - INFO - Epoch 280 EVAL  Summary: Avg Loss: 2.6676, Avg Acc: 42.78%, Duration: 0.52s
2025-06-03 23:58:20,970 - INFO - Epoch 280: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_280.pth
2025-06-03 23:58:21,489 - INFO - Epoch 281/300 | Batch 0/24 | Loss: 3.0775 | Acc: 37.91% | LR: 1.19e-05
2025-06-03 23:58:23,922 - INFO - Epoch 281 TRAIN Summary: Avg Loss: 3.2301, Avg Acc: 30.32%, Duration: 2.95s
2025-06-03 23:58:24,434 - INFO - Epoch 281 EVAL  Summary: Avg Loss: 2.6662, Avg Acc: 42.62%, Duration: 0.51s
2025-06-03 23:58:25,008 - INFO - Epoch 282/300 | Batch 0/24 | Loss: 3.0007 | Acc: 35.94% | LR: 1.09e-05
2025-06-03 23:58:27,405 - INFO - Epoch 282 TRAIN Summary: Avg Loss: 3.0893, Avg Acc: 32.51%, Duration: 2.97s
2025-06-03 23:58:27,920 - INFO - Epoch 282 EVAL  Summary: Avg Loss: 2.6665, Avg Acc: 42.72%, Duration: 0.51s
2025-06-03 23:58:28,516 - INFO - Epoch 283/300 | Batch 0/24 | Loss: 3.1986 | Acc: 31.64% | LR: 9.85e-06
2025-06-03 23:58:30,985 - INFO - Epoch 283 TRAIN Summary: Avg Loss: 3.2632, Avg Acc: 29.36%, Duration: 3.06s
2025-06-03 23:58:31,459 - INFO - Epoch 283 EVAL  Summary: Avg Loss: 2.6664, Avg Acc: 42.66%, Duration: 0.47s
2025-06-03 23:58:32,080 - INFO - Epoch 284/300 | Batch 0/24 | Loss: 3.0957 | Acc: 30.86% | LR: 8.89e-06
2025-06-03 23:58:34,546 - INFO - Epoch 284 TRAIN Summary: Avg Loss: 3.1740, Avg Acc: 30.82%, Duration: 3.09s
2025-06-03 23:58:35,076 - INFO - Epoch 284 EVAL  Summary: Avg Loss: 2.6656, Avg Acc: 42.77%, Duration: 0.53s
2025-06-03 23:58:35,608 - INFO - Epoch 285/300 | Batch 0/24 | Loss: 4.3126 | Acc: 11.60% | LR: 7.99e-06
2025-06-03 23:58:38,039 - INFO - Epoch 285 TRAIN Summary: Avg Loss: 3.2345, Avg Acc: 30.12%, Duration: 2.96s
2025-06-03 23:58:38,529 - INFO - Epoch 285 EVAL  Summary: Avg Loss: 2.6659, Avg Acc: 42.76%, Duration: 0.49s
2025-06-03 23:58:39,101 - INFO - Epoch 286/300 | Batch 0/24 | Loss: 3.0677 | Acc: 32.81% | LR: 7.15e-06
2025-06-03 23:58:41,554 - INFO - Epoch 286 TRAIN Summary: Avg Loss: 3.1923, Avg Acc: 30.82%, Duration: 3.02s
2025-06-03 23:58:42,059 - INFO - Epoch 286 EVAL  Summary: Avg Loss: 2.6663, Avg Acc: 42.71%, Duration: 0.50s
2025-06-03 23:58:42,639 - INFO - Epoch 287/300 | Batch 0/24 | Loss: 3.4907 | Acc: 31.26% | LR: 6.36e-06
2025-06-03 23:58:45,113 - INFO - Epoch 287 TRAIN Summary: Avg Loss: 3.2787, Avg Acc: 29.71%, Duration: 3.05s
2025-06-03 23:58:45,632 - INFO - Epoch 287 EVAL  Summary: Avg Loss: 2.6663, Avg Acc: 42.68%, Duration: 0.52s
2025-06-03 23:58:46,158 - INFO - Epoch 288/300 | Batch 0/24 | Loss: 3.0738 | Acc: 37.11% | LR: 5.62e-06
2025-06-03 23:58:48,564 - INFO - Epoch 288 TRAIN Summary: Avg Loss: 3.1049, Avg Acc: 32.71%, Duration: 2.93s
2025-06-03 23:58:49,093 - INFO - Epoch 288 EVAL  Summary: Avg Loss: 2.6661, Avg Acc: 42.61%, Duration: 0.52s
2025-06-03 23:58:49,655 - INFO - Epoch 289/300 | Batch 0/24 | Loss: 3.0335 | Acc: 31.98% | LR: 4.94e-06
2025-06-03 23:58:52,061 - INFO - Epoch 289 TRAIN Summary: Avg Loss: 3.2242, Avg Acc: 29.58%, Duration: 2.97s
2025-06-03 23:58:52,608 - INFO - Epoch 289 EVAL  Summary: Avg Loss: 2.6667, Avg Acc: 42.58%, Duration: 0.54s
2025-06-03 23:58:53,191 - INFO - Epoch 290/300 | Batch 0/24 | Loss: 2.9910 | Acc: 33.59% | LR: 4.31e-06
2025-06-03 23:58:55,697 - INFO - Epoch 290 TRAIN Summary: Avg Loss: 3.1268, Avg Acc: 31.70%, Duration: 3.09s
2025-06-03 23:58:56,190 - INFO - Epoch 290 EVAL  Summary: Avg Loss: 2.6664, Avg Acc: 42.66%, Duration: 0.49s
2025-06-03 23:58:56,763 - INFO - Epoch 291/300 | Batch 0/24 | Loss: 3.1046 | Acc: 29.69% | LR: 3.74e-06
2025-06-03 23:58:59,189 - INFO - Epoch 291 TRAIN Summary: Avg Loss: 3.2358, Avg Acc: 29.83%, Duration: 3.00s
2025-06-03 23:58:59,704 - INFO - Epoch 291 EVAL  Summary: Avg Loss: 2.6657, Avg Acc: 42.68%, Duration: 0.51s
2025-06-03 23:59:00,287 - INFO - Epoch 292/300 | Batch 0/24 | Loss: 3.0883 | Acc: 33.59% | LR: 3.22e-06
2025-06-03 23:59:02,699 - INFO - Epoch 292 TRAIN Summary: Avg Loss: 3.1968, Avg Acc: 30.57%, Duration: 2.99s
2025-06-03 23:59:03,215 - INFO - Epoch 292 EVAL  Summary: Avg Loss: 2.6659, Avg Acc: 42.67%, Duration: 0.51s
2025-06-03 23:59:03,787 - INFO - Epoch 293/300 | Batch 0/24 | Loss: 3.0547 | Acc: 30.86% | LR: 2.75e-06
2025-06-03 23:59:06,327 - INFO - Epoch 293 TRAIN Summary: Avg Loss: 3.1908, Avg Acc: 30.72%, Duration: 3.11s
2025-06-03 23:59:06,832 - INFO - Epoch 293 EVAL  Summary: Avg Loss: 2.6660, Avg Acc: 42.69%, Duration: 0.50s
2025-06-03 23:59:07,403 - INFO - Epoch 294/300 | Batch 0/24 | Loss: 3.0504 | Acc: 32.81% | LR: 2.34e-06
2025-06-03 23:59:09,860 - INFO - Epoch 294 TRAIN Summary: Avg Loss: 3.2983, Avg Acc: 28.77%, Duration: 3.03s
2025-06-03 23:59:10,395 - INFO - Epoch 294 EVAL  Summary: Avg Loss: 2.6658, Avg Acc: 42.70%, Duration: 0.53s
2025-06-03 23:59:10,948 - INFO - Epoch 295/300 | Batch 0/24 | Loss: 2.9990 | Acc: 37.50% | LR: 1.99e-06
2025-06-03 23:59:13,350 - INFO - Epoch 295 TRAIN Summary: Avg Loss: 3.1707, Avg Acc: 31.41%, Duration: 2.95s
2025-06-03 23:59:13,884 - INFO - Epoch 295 EVAL  Summary: Avg Loss: 2.6662, Avg Acc: 42.71%, Duration: 0.53s
2025-06-03 23:59:14,451 - INFO - Epoch 296/300 | Batch 0/24 | Loss: 3.9355 | Acc: 16.11% | LR: 1.68e-06
2025-06-03 23:59:16,826 - INFO - Epoch 296 TRAIN Summary: Avg Loss: 3.2173, Avg Acc: 29.85%, Duration: 2.94s
2025-06-03 23:59:17,345 - INFO - Epoch 296 EVAL  Summary: Avg Loss: 2.6662, Avg Acc: 42.62%, Duration: 0.51s
2025-06-03 23:59:17,978 - INFO - Epoch 297/300 | Batch 0/24 | Loss: 3.0800 | Acc: 33.59% | LR: 1.44e-06
2025-06-03 23:59:20,467 - INFO - Epoch 297 TRAIN Summary: Avg Loss: 3.2605, Avg Acc: 29.44%, Duration: 3.12s
2025-06-03 23:59:20,964 - INFO - Epoch 297 EVAL  Summary: Avg Loss: 2.6660, Avg Acc: 42.63%, Duration: 0.49s
2025-06-03 23:59:21,536 - INFO - Epoch 298/300 | Batch 0/24 | Loss: 3.0355 | Acc: 32.81% | LR: 1.25e-06
2025-06-03 23:59:23,981 - INFO - Epoch 298 TRAIN Summary: Avg Loss: 3.0965, Avg Acc: 32.88%, Duration: 3.01s
2025-06-03 23:59:24,491 - INFO - Epoch 298 EVAL  Summary: Avg Loss: 2.6661, Avg Acc: 42.74%, Duration: 0.51s
2025-06-03 23:59:25,049 - INFO - Epoch 299/300 | Batch 0/24 | Loss: 3.0325 | Acc: 36.72% | LR: 1.11e-06
2025-06-03 23:59:27,473 - INFO - Epoch 299 TRAIN Summary: Avg Loss: 3.0567, Avg Acc: 33.46%, Duration: 2.98s
2025-06-03 23:59:27,974 - INFO - Epoch 299 EVAL  Summary: Avg Loss: 2.6662, Avg Acc: 42.69%, Duration: 0.50s
2025-06-03 23:59:28,568 - INFO - Epoch 300/300 | Batch 0/24 | Loss: 3.1762 | Acc: 28.91% | LR: 1.03e-06
2025-06-03 23:59:31,033 - INFO - Epoch 300 TRAIN Summary: Avg Loss: 3.2670, Avg Acc: 28.97%, Duration: 3.06s
2025-06-03 23:59:31,560 - INFO - Epoch 300 EVAL  Summary: Avg Loss: 2.6660, Avg Acc: 42.69%, Duration: 0.52s
2025-06-03 23:59:31,676 - INFO - Epoch 300: 检查点已保存至 ./logs/mlp_mixer_tiny/20250603-234122/checkpoint_epoch_300.pth
2025-06-03 23:59:31,677 - INFO - 训练完成! 总用时: 0.30 小时。最佳测试准确率: 42.82%
