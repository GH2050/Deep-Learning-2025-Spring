# DL-2025

## ğŸ“ é¡¹ç›®æ ¸å¿ƒè¦æ±‚

ä½¿ç”¨ PyTorch å®ç° CIFAR-100 åˆ†ç±»ã€‚
åœ¨ç²¾ç®€ç‰ˆçš„ ResNet ä½œä¸ºåŸºç¡€ç½‘ç»œä¹‹ä¸Šï¼Œæ¢ç´¢ã€å®ç°å¹¶å¯¹æ¯”å¤šç§å…ˆè¿›çš„æ·±åº¦å­¦ä¹ ç½‘ç»œæ¶æ„æˆ–æ³¨æ„åŠ›æœºåˆ¶ã€‚


**æŠ€æœ¯æ ˆè¦æ±‚**ï¼š

- **PyTorch**ï¼šä¸»è¦æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ¨¡å‹æ„å»ºå’Œè®­ç»ƒ
- **datasets**ï¼šç”¨äºæ•°æ®é›†åŠ è½½ã€é¢„å¤„ç†å’Œç®¡ç†
- **accelerate**ï¼šç”¨äºè®­ç»ƒåŠ é€Ÿã€åˆ†å¸ƒå¼è®­ç»ƒå’Œæ€§èƒ½ä¼˜åŒ–    
- **huggingface_hub**ï¼šç”¨äºæ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œèµ„æºå…±äº«
- **transformers**ï¼šä»…ä½¿ç”¨åŸºç¡€æ„ä»¶ï¼ˆä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ã€å·¥å…·å‡½æ•°ç­‰ï¼‰ï¼Œä¸ä¾èµ–é¢„è®­ç»ƒæ¨¡å‹

---

## ğŸ› ï¸ å®ç°è¿‡ç¨‹è¦æ±‚

1.  **åŸºç¡€æ¨¡å‹**: é‡‡ç”¨ç²¾ç®€ç‰ˆ ResNetã€‚
2.  **æŠ€æœ¯é€‰å‹ä¸å‚è€ƒè®ºæ–‡**:
    å®ç°ä»¥ä¸‹åˆ—è¡¨ä¸­å…¨éƒ¨10ç§ä¸åŒçš„æ–¹æ³•ï¼ˆå¯ä»¥ä¸€ç§æˆ–å¤šç§è¿›è¡Œç»„åˆï¼‰ã€‚ä»¥ä¸‹æ˜¯è¿™äº›æ–¹æ³•çš„å…·ä½“åç§°å’Œå¯¹åº”çš„å‚è€ƒè®ºæ–‡ï¼š

        1.  **ConvNeXt**: A ConvNet for the 2020s
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf`
        2.  **SegNeXt**: Rethinking convolutional attention design for semantic segmentation
            * è®ºæ–‡: `https://proceedings.neurips.cc/paper_files/paper/2022/file/005f5f40f4416f1ecfc3080e60b38f1a-Paper-Conference.pdf`
        3.  **LSKNet**: Large selective kernel network for remote sensing object detection
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf`
        4.  **CoatNet**: Marrying convolution and attention for all data sizes
            * è®ºæ–‡: `https://proceedings.neurips.cc/paper/2021/file/20598b92d6e43456acb242c1f9-Paper.pdf`
        5.  **ECA-Net**: Efficient channel attention for deep convolutional neural networks
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/CVPR2020/papers/Wang_ECA-Net_Efficient_Channel_Attention_for_Deep_Convolutional_Neural_Networks_CVPR_2020_paper.pdf`
        6.  **CSPNet**: A new backbone that can enhance learning capability of CNN
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/CVPRW/2020/papers/w28/Wang_CSPNet_A_New_Backbone_That_Can_Enhance_Learning_Capability_of_CVPRW_2020_paper.pdf`
        7.  **GhostNet**: More features from cheap operations
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/CVPR_2020/papers/Han_GhostNet_More_Features_From_Cheap_Operations_CVPR_2020_paper.pdf`
        8.  **HorNet**: Efficient high-order spatial interactions with recursive gated convolutions
            * è®ºæ–‡: `https://proceedings.neurips.cc/paper_files/paper/2022/file/436d42b3dd81214023ae43b96b146-Paper-Conference.pdf`
        9.  **ResNeSt**: Split-attention networks
            * è®ºæ–‡: `https://openaccess.thecvf.com/content/CVPR2022W/ECV/papers/Zhang_ResNeSt_Split-Attention_Networks_CVPRW_2022_paper.pdf`
        10. **Pay Attention to MLPs** (MLP-Mixer)
            * è®ºæ–‡: `https://proceedings.neurips.cc/paper/2021/file/4ccb653b2c3537e5d1e917d413c686ff-Paper.pdf`

ä½ éœ€è¦è€ƒè™‘æ¨èçš„ä¸‰ç§æˆ–å¤šç§é€‰æ‹©ã€‚

3.  **å›¢é˜Ÿåˆä½œ**: ä»¥ **5 äºº**ä¸ºä¸€ç»„è¿›è¡Œã€‚

---

## ğŸ“Š å®éªŒä¸å¯¹æ¯”è¦æ±‚

* ä»‹ç»æ‰€ä½¿ç”¨çš„åŸºç¡€æ–¹æ³• (ResNet)ã€‚
* è¯¦ç»†è¯´æ˜å¦‚ä½•å¯¹åŸºç¡€æ–¹æ³•è¿›è¡Œæ”¹è¿›ï¼ˆå³å¦‚ä½•å®ç°å’Œé›†æˆæ‰€é€‰çš„ 3+ ç§æ–¹æ³•ï¼‰ã€‚
* æä¾›è¯¦ç»†çš„**å®éªŒå¯¹æ¯”ç»“æœ**ã€‚
* è¿›è¡Œå¿…è¦çš„**æ¶ˆèæ€§å®éªŒ** (Ablation Studies) æ¥éªŒè¯å„ä¸ªæ¨¡å—æˆ–æ”¹è¿›ç‚¹çš„æœ‰æ•ˆæ€§ã€‚

---

## ğŸ¤ æˆæœå±•ç¤ºè¦æ±‚

* **å½¢å¼**: é‡‡ç”¨ PPT æ–¹å¼è¿›è¡Œå±•ç¤ºã€‚
* **æ—¶é•¿**: æ¯ç»„å±•ç¤ºæ—¶é—´**çº¦ä¸º 8-10 åˆ†é’Ÿ**ã€‚
* **å†…å®¹**:
    * åŸºç¡€æ–¹æ³•ä»‹ç»ã€‚
    * æ”¹è¿›æ–¹æ¡ˆè¯¦è¿°ã€‚
    * å®éªŒå¯¹æ¯”ä¸æ¶ˆèç»“æœåˆ†æã€‚
    * å¯¹æœªæ¥å·¥ä½œçš„è®¾æƒ³å’Œå±•æœ›ã€‚

---

## ğŸ“– å®éªŒæŠ¥å‘Šè¦æ±‚

* æäº¤ä¸€ä»½è¯¦ç»†çš„å®éªŒæŠ¥å‘Šã€‚
* æŠ¥å‘Šä¸­å¿…é¡»**è¯¦ç»†é˜è¿°å›¢é˜Ÿä¸­æ¯ä¸ªæˆå‘˜çš„å…·ä½“è´¡çŒ®**ï¼ˆä¾‹å¦‚ï¼šæ–‡æ¡£æ’°å†™ã€å®éªŒè®¾è®¡ä¸æ‰§è¡Œã€Idea æå‡ºç­‰ï¼‰ã€‚

---

## âœ¨ åŠ åˆ†é¡¹ (æœ€å¤š 5 åˆ†)

* åœ¨ä¼˜ç§€å®ŒæˆåŸºç¡€è¦æ±‚ä¹‹ä¸Šï¼Œ**æå‡ºåˆ›æ–°æ€§çš„æ–¹æ³•**ã€‚
* é€šè¿‡**å®éªŒ**å¯¹æå‡ºçš„åˆ›æ–°æ–¹æ³•è¿›è¡Œ**éªŒè¯å’Œè®ºè¯**ã€‚