import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import pandas as pd

# æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

def load_results():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒç»“æœ"""
    results_dir = Path('logs/results')
    all_results = {}
    
    # åŠ è½½æ±‡æ€»æ–‡ä»¶
    summary_file = results_dir / 'all_models_summary.json'
    if summary_file.exists():
        with open(summary_file, 'r', encoding='utf-8') as f:
            all_results = json.load(f)
    
    # åŠ è½½å•ç‹¬çš„ç»“æœæ–‡ä»¶
    for result_file in results_dir.glob('*_results.json'):
        if 'summary' not in result_file.name:
            with open(result_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
                model_name = result['model_name']
                all_results[model_name] = result
    
    return all_results

def create_summary_table(results):
    """åˆ›å»ºç»“æœæ±‡æ€»è¡¨"""
    data = []
    
    for model_name, result in results.items():
        if 'error' not in result and 'best_acc' in result:
            data.append({
                'æ¨¡å‹åç§°': model_name,
                'æœ€ä½³å‡†ç¡®ç‡(%)': result['best_acc'],
                'Top5å‡†ç¡®ç‡(%)': result.get('best_acc_top5', 0),
                'å‚æ•°é‡(M)': result['parameters'],
                'è®­ç»ƒæ—¶é—´(s)': result['total_time'],
                'å‚æ•°æ•ˆç‡': result['best_acc'] / result['parameters'] if result['parameters'] > 0 else 0
            })
    
    df = pd.DataFrame(data)
    df = df.sort_values('æœ€ä½³å‡†ç¡®ç‡(%)', ascending=False)
    return df

def plot_accuracy_comparison(results):
    """ç»˜åˆ¶å‡†ç¡®ç‡å¯¹æ¯”å›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # æå–æ•°æ®
    model_names = []
    top1_accs = []
    top5_accs = []
    
    for model_name, result in results.items():
        if 'error' not in result and 'best_acc' in result:
            model_names.append(model_name.replace('_', '\n'))
            top1_accs.append(result['best_acc'])
            top5_accs.append(result.get('best_acc_top5', 0))
    
    # æŒ‰Top1å‡†ç¡®ç‡æ’åº
    sorted_data = sorted(zip(model_names, top1_accs, top5_accs), key=lambda x: x[1], reverse=True)
    model_names, top1_accs, top5_accs = zip(*sorted_data)
    
    # Top1å‡†ç¡®ç‡æŸ±çŠ¶å›¾
    bars1 = ax1.bar(range(len(model_names)), top1_accs, color='skyblue', alpha=0.7)
    ax1.set_title('Top-1 å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax1.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)
    ax1.set_xticks(range(len(model_names)))
    ax1.set_xticklabels(model_names, rotation=45, ha='right')
    ax1.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars1, top1_accs):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{acc:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # Top5å‡†ç¡®ç‡æŸ±çŠ¶å›¾
    bars2 = ax2.bar(range(len(model_names)), top5_accs, color='lightcoral', alpha=0.7)
    ax2.set_title('Top-5 å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax2.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)
    ax2.set_xticks(range(len(model_names)))
    ax2.set_xticklabels(model_names, rotation=45, ha='right')
    ax2.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars2, top5_accs):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                f'{acc:.1f}%', ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    plt.savefig('assets/accuracy_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_efficiency_analysis(results):
    """ç»˜åˆ¶æ•ˆç‡åˆ†æå›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # æå–æ•°æ®
    model_names = []
    accuracies = []
    parameters = []
    train_times = []
    
    for model_name, result in results.items():
        if 'error' not in result and 'best_acc' in result:
            model_names.append(model_name)
            accuracies.append(result['best_acc'])
            parameters.append(result['parameters'])
            train_times.append(result['total_time'])
    
    # å‡†ç¡®ç‡ vs å‚æ•°é‡æ•£ç‚¹å›¾
    scatter1 = ax1.scatter(parameters, accuracies, s=100, alpha=0.7, c='blue')
    ax1.set_xlabel('å‚æ•°é‡ (M)', fontsize=12)
    ax1.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)
    ax1.set_title('å‡†ç¡®ç‡ vs å‚æ•°é‡', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ æ¨¡å‹åç§°æ ‡ç­¾
    for i, name in enumerate(model_names):
        ax1.annotate(name.replace('_', '\n'), (parameters[i], accuracies[i]),
                    xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.8)
    
    # å‡†ç¡®ç‡ vs è®­ç»ƒæ—¶é—´æ•£ç‚¹å›¾
    scatter2 = ax2.scatter(train_times, accuracies, s=100, alpha=0.7, c='red')
    ax2.set_xlabel('è®­ç»ƒæ—¶é—´ (s)', fontsize=12)
    ax2.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)
    ax2.set_title('å‡†ç¡®ç‡ vs è®­ç»ƒæ—¶é—´', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # æ·»åŠ æ¨¡å‹åç§°æ ‡ç­¾
    for i, name in enumerate(model_names):
        ax2.annotate(name.replace('_', '\n'), (train_times[i], accuracies[i]),
                    xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.8)
    
    plt.tight_layout()
    plt.savefig('assets/efficiency_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_training_curves(results, model_names=None):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    if model_names is None:
        # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ¨¡å‹
        model_names = ['resnet_20', 'eca_resnet_20', 'ghost_resnet_20', 'convnext_tiny_timm']
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    axes = [ax1, ax2, ax3, ax4]
    
    for i, model_name in enumerate(model_names[:4]):
        if model_name in results and 'epochs' in results[model_name]:
            result = results[model_name]
            epochs = result['epochs']
            train_acc = result['train_acc']
            test_acc = result['test_acc']
            
            ax = axes[i]
            ax.plot(epochs, train_acc, 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
            ax.plot(epochs, test_acc, 'r-', label='æµ‹è¯•å‡†ç¡®ç‡', linewidth=2)
            ax.set_title(f'{model_name} è®­ç»ƒæ›²çº¿', fontsize=12, fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('å‡†ç¡®ç‡ (%)')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # æ ‡æ³¨æœ€ä½³å‡†ç¡®ç‡
            best_epoch = epochs[test_acc.index(max(test_acc))]
            best_acc = max(test_acc)
            ax.annotate(f'æœ€ä½³: {best_acc:.1f}%', 
                       xy=(best_epoch, best_acc), xytext=(10, 10),
                       textcoords='offset points', ha='left',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                       arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    plt.tight_layout()
    plt.savefig('assets/training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_comprehensive_report(results):
    """åˆ›å»ºç»¼åˆæŠ¥å‘Š"""
    print("=" * 80)
    print("CIFAR-100 åˆ†ç±»ä»»åŠ¡ - åç§å…ˆè¿›æ¶æ„å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # åŸºæœ¬ç»Ÿè®¡
    valid_results = {k: v for k, v in results.items() if 'error' not in v and 'best_acc' in v}
    print(f"\næ€»æ¨¡å‹æ•°é‡: {len(results)}")
    print(f"æˆåŠŸè®­ç»ƒ: {len(valid_results)}")
    print(f"å¤±è´¥æ¨¡å‹: {len(results) - len(valid_results)}")
    
    if not valid_results:
        print("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒç»“æœ!")
        return
    
    # æ€§èƒ½æ’å
    print(f"\nğŸ† æ€§èƒ½æ’å (Top-1å‡†ç¡®ç‡):")
    print("-" * 60)
    sorted_models = sorted(valid_results.items(), key=lambda x: x[1]['best_acc'], reverse=True)
    
    for i, (model_name, result) in enumerate(sorted_models[:10], 1):
        print(f"{i:2d}. {model_name:<20} {result['best_acc']:6.2f}% "
              f"(Top5: {result.get('best_acc_top5', 0):5.1f}%, "
              f"å‚æ•°: {result['parameters']:5.2f}M)")
    
    # æ•ˆç‡åˆ†æ
    print(f"\nâš¡ æ•ˆç‡åˆ†æ:")
    print("-" * 60)
    
    # å‚æ•°æ•ˆç‡æ’å
    param_efficiency = [(name, res['best_acc'] / res['parameters'] if res['parameters'] > 0 else 0) 
                       for name, res in valid_results.items()]
    param_efficiency.sort(key=lambda x: x[1], reverse=True)
    
    print("å‚æ•°æ•ˆç‡æ’å (å‡†ç¡®ç‡/å‚æ•°é‡):")
    for i, (name, eff) in enumerate(param_efficiency[:5], 1):
        acc = valid_results[name]['best_acc']
        params = valid_results[name]['parameters']
        print(f"  {i}. {name:<20} {eff:6.2f} ({acc:.1f}% / {params:.2f}M)")
    
    # é€Ÿåº¦åˆ†æ
    speed_ranking = sorted(valid_results.items(), key=lambda x: x[1]['total_time'])
    print(f"\nè®­ç»ƒé€Ÿåº¦æ’å:")
    for i, (name, res) in enumerate(speed_ranking[:5], 1):
        print(f"  {i}. {name:<20} {res['total_time']:6.1f}s "
              f"(å‡†ç¡®ç‡: {res['best_acc']:.1f}%)")
    
    # æŠ€æœ¯ç‰¹ç‚¹åˆ†æ
    print(f"\nğŸ”¬ æŠ€æœ¯ç‰¹ç‚¹åˆ†æ:")
    print("-" * 60)
    
    categories = {
        'åŸºç¡€ç½‘ç»œ': ['resnet_20', 'resnet_32', 'resnet_56'],
        'æ³¨æ„åŠ›æœºåˆ¶': ['eca_resnet_20', 'eca_resnet_32'],
        'è½»é‡åŒ–è®¾è®¡': ['ghost_resnet_20', 'ghost_resnet_32', 'ghostnet_100'],
        'ç°ä»£åŒ–æ¶æ„': ['convnext_tiny', 'convnext_tiny_timm'],
        'å¤šå°ºåº¦æ„ŸçŸ¥': ['segnext_mscan_tiny'],
        'æ··åˆæ¶æ„': ['coatnet_0'],
        'è·¨é˜¶æ®µç½‘ç»œ': ['cspresnet50'],
        'åˆ†è£‚æ³¨æ„åŠ›': ['resnest50d'],
        'MLPæ¶æ„': ['mlp_mixer_tiny', 'mlp_mixer_b16'],
        'æ›¿ä»£æ¶æ„': ['hornet_tiny']
    }
    
    for category, models in categories.items():
        category_results = [(name, valid_results[name]) for name in models if name in valid_results]
        if category_results:
            avg_acc = np.mean([res['best_acc'] for _, res in category_results])
            avg_params = np.mean([res['parameters'] for _, res in category_results])
            print(f"{category:<12}: å¹³å‡å‡†ç¡®ç‡ {avg_acc:5.1f}%, å¹³å‡å‚æ•°é‡ {avg_params:5.2f}M")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path('assets').mkdir(exist_ok=True)
    
    # åŠ è½½ç»“æœ
    print("åŠ è½½è®­ç»ƒç»“æœ...")
    results = load_results()
    
    if not results:
        print("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒç»“æœæ–‡ä»¶!")
        return
    
    # åˆ›å»ºæ±‡æ€»è¡¨
    print("åˆ›å»ºç»“æœæ±‡æ€»è¡¨...")
    summary_df = create_summary_table(results)
    summary_df.to_csv('assets/model_comparison_summary.csv', index=False, encoding='utf-8')
    print(f"æ±‡æ€»è¡¨å·²ä¿å­˜åˆ°: assets/model_comparison_summary.csv")
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    plot_accuracy_comparison(results)
    plot_efficiency_analysis(results)
    plot_training_curves(results)
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    create_comprehensive_report(results)
    
    print(f"\nğŸ“Š åˆ†æå®Œæˆ! å›¾è¡¨å·²ä¿å­˜åˆ° assets/ ç›®å½•")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - accuracy_comparison.png: å‡†ç¡®ç‡å¯¹æ¯”å›¾")
    print("  - efficiency_analysis.png: æ•ˆç‡åˆ†æå›¾") 
    print("  - training_curves.png: è®­ç»ƒæ›²çº¿å›¾")
    print("  - model_comparison_summary.csv: ç»“æœæ±‡æ€»è¡¨")

if __name__ == "__main__":
    main() 