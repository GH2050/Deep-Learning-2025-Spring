import torch
import argparse
from pathlib import Path
import sys
import os
from tqdm import tqdm
import time
import logging
import json
from datetime import datetime
import io
from contextlib import redirect_stdout, redirect_stderr

# å°è¯•å¯¼å…¥æ¨¡å‹æ¶æ„æ‰“å°å·¥å…·
try:
    from torchinfo import summary as torchinfo_summary
    HAS_TORCHINFO = True
except ImportError:
    HAS_TORCHINFO = False

try:
    from torchsummary import summary as torchsummary_summary
    HAS_TORCHSUMMARY = True
except ImportError:
    HAS_TORCHSUMMARY = False

from models import (
    resnet20,
    resnet32,
    resnet56,
    resnet20_slim,
    resnet32_slim,
    improved_resnet20_v2,
    convnext_micro,
    convnext_nano,
    convnext_tiny_cifar,
    convnext_small_cifar,
    convnext_tiny,  # åŸç‰ˆ(ä¸æ¨è)
    count_parameters,
    get_training_config,
)
from dataset import get_dataloaders
from trainer import Trainer


class ModelLogger:
    """ç‹¬ç«‹çš„æ¨¡å‹æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, save_dir, model_name):
        self.save_dir = save_dir
        self.model_name = model_name
        self.log_dir = save_dir / "logs"
        self.log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.log_dir / f"{model_name}_{timestamp}.log"
        
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(f"{model_name}_{timestamp}")
        self.logger.setLevel(logging.INFO)
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        
        # æ§åˆ¶å°è¾“å‡ºç¼“å†²
        self.console_buffer = []
    
    def info(self, message):
        """è®°å½•ä¿¡æ¯ï¼Œå¤„ç†Unicodeå­—ç¬¦"""
        # æ›¿æ¢é—®é¢˜å­—ç¬¦
        safe_message = self._safe_unicode(message)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        self.logger.info(safe_message)
        
        # æ·»åŠ åˆ°æ§åˆ¶å°ç¼“å†²
        self.console_buffer.append(safe_message)
    
    def error(self, message):
        """è®°å½•é”™è¯¯"""
        safe_message = self._safe_unicode(message)
        self.logger.error(safe_message)
        self.console_buffer.append(f"ERROR: {safe_message}")
    
    def _safe_unicode(self, message):
        """å¤„ç†Unicodeå­—ç¬¦"""
        replacements = {
            'âœ“': '[OK]',
            'âœ—': '[FAIL]', 
            'ğŸ‰': '[BEST]',
            'â”œ': '|-',
            'â””': '`-',
            'â†’': '->',
            'Ã—': 'x'
        }
        
        for old, new in replacements.items():
            message = message.replace(old, new)
        
        return message
    
    def flush_console(self):
        """åˆ·æ–°æ§åˆ¶å°è¾“å‡º"""
        if self.console_buffer:
            # æ¸…å±å¹¶æ˜¾ç¤ºå½“å‰æ¨¡å‹çš„æ—¥å¿—
            os.system('cls' if os.name == 'nt' else 'clear')
            print(f"{'='*80}")
            print(f"Training Model: {self.model_name}")
            print(f"{'='*80}")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—
            for line in self.console_buffer[-50:]:  # åªæ˜¾ç¤ºæœ€è¿‘50è¡Œ
                print(line)
            
            print(f"{'='*80}")
    
    def clear_buffer(self):
        """æ¸…ç©ºæ§åˆ¶å°ç¼“å†²"""
        self.console_buffer = []


def get_model_architecture(model, model_name, input_size=(1, 3, 32, 32)):
    """è·å–æ¨¡å‹æ¶æ„ä¿¡æ¯"""
    arch_info = []
    
    # åŸºæœ¬ä¿¡æ¯
    total_params = count_parameters(model)
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    arch_info.extend([
        f"Model: {model_name}",
        f"Total Parameters: {total_params:.2f}M",
        f"Trainable Parameters: {trainable_params/1e6:.2f}M",
        f"Model Size (approx): {total_params * 4:.2f} MB",
        ""
    ])
    
    # å°è¯•ä½¿ç”¨ torchinfo - ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹å®ä¾‹
    if HAS_TORCHINFO:
        try:
            arch_info.append("Model Architecture (torchinfo):")
            arch_info.append("-" * 60)
            
            # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Šè¿›è¡Œsummaryï¼ˆé¿å…è®¾å¤‡é—®é¢˜ï¼‰
            model_for_summary = model.cpu()
            model_for_summary.eval()
            
            # ä½¿ç”¨ torchinfo è·å–è¯¦ç»†ä¿¡æ¯
            summary_str = str(torchinfo_summary(
                model_for_summary, 
                input_size=input_size,
                verbose=0,
                col_names=["input_size", "output_size", "num_params", "kernel_size"],
                row_settings=["var_names"],
                device='cpu'
            ))
            
            # åˆ†è¡Œæ·»åŠ 
            for line in summary_str.split('\n'):
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    arch_info.append(line)
            
            arch_info.append("-" * 60)
            
        except Exception as e:
            arch_info.extend([
                f"torchinfo failed: {str(e)}",
                "Falling back to torchsummary or basic info..."
            ])
    
    # å¦‚æœ torchinfo å¤±è´¥ï¼Œå°è¯• torchsummary
    if (not HAS_TORCHINFO or "failed" in arch_info[-2]) and HAS_TORCHSUMMARY:
        try:
            arch_info.append("Model Architecture (torchsummary):")
            arch_info.append("-" * 60)
            
            # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Š
            model_for_summary = model.cpu()
            model_for_summary.eval()
            
            # åˆ›å»ºå­—ç¬¦ä¸²ç¼“å†²åŒº
            old_stdout = sys.stdout
            sys.stdout = buffer = io.StringIO()
            
            # è°ƒç”¨ torchsummary
            torchsummary_summary(model_for_summary, input_size[1:])  # ä¸åŒ…æ‹¬batchç»´åº¦
            
            # æ¢å¤stdoutå¹¶è·å–è¾“å‡º
            sys.stdout = old_stdout
            summary_output = buffer.getvalue()
            
            # æ·»åŠ è¾“å‡ºåˆ°æ¶æ„ä¿¡æ¯
            for line in summary_output.split('\n'):
                if line.strip():
                    arch_info.append(line)
            
            arch_info.append("-" * 60)
            
        except Exception as e:
            arch_info.extend([
                f"torchsummary failed: {str(e)}",
                "Using basic architecture info..."
            ])
        finally:
            sys.stdout = old_stdout
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œæˆ–è€…éƒ½æ²¡æœ‰ï¼Œä½¿ç”¨åŸºæœ¬çš„æ¨¡å‹å­—ç¬¦ä¸²è¡¨ç¤º
    if (not HAS_TORCHINFO and not HAS_TORCHSUMMARY) or "failed" in str(arch_info):
        arch_info.extend([
            "",
            "Model Architecture (basic representation):",
            "-" * 60
        ])
        
        # è·å–æ¨¡å‹çš„å­—ç¬¦ä¸²è¡¨ç¤º
        model_str = str(model)
        lines = model_str.split('\n')
        
        # æ˜¾ç¤ºæ¨¡å‹ç»“æ„ï¼Œä½†é™åˆ¶è¡Œæ•°
        for i, line in enumerate(lines):
            if i > 30:  # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°
                arch_info.append(f"... (truncated, {len(lines) - i} more lines)")
                break
            arch_info.append(line)
        
        arch_info.extend([
            "",
            "For detailed architecture info, install:",
            "  pip install torchinfo  (recommended)",
            "  pip install torchsummary",
            "-" * 60
        ])
    
    return arch_info


def get_simple_model_info(model, model_name):
    """è·å–ç®€åŒ–çš„æ¨¡å‹ä¿¡æ¯ï¼ˆç”¨äºå¿«é€Ÿæ˜¾ç¤ºï¼‰"""
    total_params = count_parameters(model)
    
    # æ ¹æ®æ¨¡å‹ç±»å‹æä¾›ç®€è¦æè¿°
    if "resnet" in model_name and "improved" not in model_name:
        if "20" in model_name:
            desc = "ResNet-20: 3 layers x 3 blocks each"
        elif "32" in model_name:
            desc = "ResNet-32: 3 layers x 5 blocks each"
        elif "56" in model_name:
            desc = "ResNet-56: 3 layers x 9 blocks each"
        else:
            desc = "ResNet variant"
            
        if "slim" in model_name:
            desc += " (0.5x channels)"
    
    elif "improved" in model_name:
        if "v2" in model_name:
            desc = "Enhanced ResNet-20 v2: Depthwise conv + Inverted bottleneck"
        else:
            desc = "Enhanced ResNet-20: Advanced improvements"
    
    elif "convnext" in model_name:
        if "micro" in model_name:
            desc = "ConvNeXt-Micro: [2,2,4,2] blocks, [32,64,128,256] dims (CIFAR optimized)"
        elif "nano" in model_name:
            desc = "ConvNeXt-Nano: [2,2,6,2] blocks, [40,80,160,320] dims (CIFAR optimized)"
        elif "tiny_cifar" in model_name:
            desc = "ConvNeXt-Tiny: [2,2,6,2] blocks, [48,96,192,384] dims (CIFAR optimized)"
        elif "small_cifar" in model_name:
            desc = "ConvNeXt-Small: [2,2,18,2] blocks, [48,96,192,384] dims (CIFAR optimized)"
        elif "tiny" in model_name:
            desc = "ConvNeXt-Tiny: [2,2,6,2] blocks, [48,96,192,384] dims (Original - may overfit)"
        else:
            desc = "ConvNeXt variant: Modern CNN architecture"
    else:
        desc = "Custom model architecture"
    
    return [
        f"Model: {model_name}",
        f"Description: {desc}",
        f"Parameters: {total_params:.2f}M ({total_params*1e6:,.0f} total)",
        f"Model size: ~{total_params * 4:.1f} MB (FP32)",
        f"Input: 32x32x3 RGB -> Output: 100 classes (CIFAR-100)"
    ]


def print_layer_summary(model, model_name):
    """æ‰‹åŠ¨æ‰“å°æ¨¡å‹å±‚çš„ç®€è¦æ€»ç»“"""
    summary_lines = [
        "",
        f"Layer Summary for {model_name}:",
        "-" * 50
    ]
    
    total_params = 0
    layer_count = 0
    
    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # å¶å­èŠ‚ç‚¹
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                layer_count += 1
                total_params += params
                
                # è·å–å±‚ç±»å‹
                layer_type = type(module).__name__
                
                # è·å–å±‚çš„åŸºæœ¬ä¿¡æ¯
                if hasattr(module, 'in_features') and hasattr(module, 'out_features'):
                    info = f"{module.in_features} -> {module.out_features}"
                elif hasattr(module, 'in_channels') and hasattr(module, 'out_channels'):
                    kernel = getattr(module, 'kernel_size', 'N/A')
                    stride = getattr(module, 'stride', 'N/A')
                    info = f"{module.in_channels} -> {module.out_channels}, kernel={kernel}, stride={stride}"
                elif hasattr(module, 'num_features'):
                    info = f"features={module.num_features}"
                else:
                    info = "N/A"
                
                summary_lines.append(f"{layer_count:2d}. {name:<25} {layer_type:<15} {info:<25} {params:>8,} params")
    
    summary_lines.extend([
        "-" * 50,
        f"Total: {layer_count} layers, {total_params:,} parameters",
        ""
    ])
    
    return summary_lines


def save_experiment_config(save_dir, args, model_params, model_name):
    """ä¿å­˜å®éªŒé…ç½®"""
    config = {
        "model": model_name,
        "epochs": args.epochs,
        "batch_size": args.batch_size,
        "lr": args.lr,
        "optimizer": args.optimizer,
        "weight_decay": args.weight_decay,
        "data_augmentation": not args.no_augment,
        "model_parameters": model_params,
        "timestamp": datetime.now().isoformat()
    }
    
    config_file = save_dir / "experiment_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    return config_file


def test_model_forward(model, device, batch_size=2, logger=None):
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    logger.info("Testing model forward pass...")

    model = model.to(device)
    model.eval()
    test_input = torch.randn(batch_size, 3, 32, 32).to(device)

    try:
        start_time = time.time()
        with torch.no_grad():
            output = model(test_input)
        forward_time = time.time() - start_time

        logger.info(f"[OK] Forward pass successful")
        logger.info(f"|- Input shape: {list(test_input.shape)}")
        logger.info(f"|- Output shape: {list(output.shape)}")
        logger.info(f"|- Forward time: {forward_time*1000:.2f}ms")
        logger.info(f"`- Device: {next(model.parameters()).device}")
        
        return True
    except Exception as e:
        logger.error(f"[FAIL] Forward pass failed: {e}")
        logger.error(f"Model device: {next(model.parameters()).device}")
        logger.error(f"Input device: {test_input.device}")
        return False


def train_single_model(model_name, args):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹ä¸“ç”¨æ—¥å¿—è®°å½•å™¨
    save_dir = Path(args.save_dir) / model_name
    save_dir.mkdir(parents=True, exist_ok=True)
    
    logger = ModelLogger(Path(args.save_dir), model_name)
    
    logger.info("="*80)
    logger.info(f"Starting training for model: {model_name}")
    logger.info("="*80)
    
    # æ›´æ–°çš„æ¨¡å‹å­—å…¸
    model_dict = {
        # åŸºç¡€ ResNet
        "resnet20": resnet20,
        "resnet32": resnet32,
        "resnet56": resnet56,
        "resnet20_slim": resnet20_slim,
        "resnet32_slim": resnet32_slim,
        
        # æ”¹è¿› ResNet
        "improved_resnet20_v2": improved_resnet20_v2,
        
        # CIFAR-100 ä¼˜åŒ–çš„ ConvNeXt
        "convnext_micro": convnext_micro,
        "convnext_nano": convnext_nano,
        "convnext_tiny_cifar": convnext_tiny_cifar,
        "convnext_small_cifar": convnext_small_cifar,
        
        # åŸç‰ˆ ConvNeXt (ä¸æ¨è)
        "convnext_tiny": convnext_tiny,
    }

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    if model_name not in model_dict:
        logger.error(f"Unknown model: {model_name}")
        logger.error(f"Available models: {list(model_dict.keys())}")
        return None
    
    logger.info(f"Creating model: {model_name}")
    model = model_dict[model_name]()
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸æ¨èçš„æ¨¡å‹
    if model_name == "convnext_tiny":
        logger.info("WARNING: convnext_tiny may overfit on CIFAR-100")
        logger.info("Consider using convnext_micro or convnext_nano instead")
    
    # é¦–å…ˆæ˜¾ç¤ºç®€è¦ä¿¡æ¯
    simple_info = get_simple_model_info(model, model_name)
    for line in simple_info:
        logger.info(line)
    
    # æ‰‹åŠ¨æ‰“å°å±‚æ€»ç»“
    layer_summary = print_layer_summary(model, model_name)
    for line in layer_summary:
        logger.info(line)
    
    # å°è¯•è·å–è¯¦ç»†çš„æ¨¡å‹æ¶æ„ä¿¡æ¯
    if HAS_TORCHINFO or HAS_TORCHSUMMARY:
        logger.info("Getting detailed architecture...")
        try:
            arch_info = get_model_architecture(model, model_name)
            for line in arch_info:
                logger.info(line)
        except Exception as e:
            logger.error(f"Failed to get detailed architecture: {e}")
            logger.info("Continuing with basic model info...")
    
    # è·å–æ¨èçš„è®­ç»ƒé…ç½®
    training_config = get_training_config(model_name)
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–æ¨èé…ç½®
    lr = args.lr if args.lr is not None else training_config['lr']
    optimizer_type = args.optimizer if args.optimizer is not None else training_config['optimizer']
    weight_decay = args.weight_decay if args.weight_decay != 5e-4 else training_config['weight_decay']
    epochs = args.epochs if args.epochs != 200 else training_config['epochs']
    
    logger.info("")
    logger.info(f"Training Configuration:")
    logger.info(f"|- Learning Rate: {lr} (recommended: {training_config['lr']})")
    logger.info(f"|- Optimizer: {optimizer_type} (recommended: {training_config['optimizer']})")
    logger.info(f"|- Weight Decay: {weight_decay} (recommended: {training_config['weight_decay']})")
    logger.info(f"|- Batch Size: {args.batch_size}")
    logger.info(f"|- Epochs: {epochs} (recommended: {training_config['epochs']})")
    logger.info(f"|- Warmup Epochs: {training_config.get('warmup_epochs', 0)}")
    logger.info(f"|- Label Smoothing: {training_config.get('label_smoothing', 0.0)}")

    # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    if not test_model_forward(model, device, args.batch_size, logger):
        logger.error("Model forward pass test failed. Skipping...")
        return None

    # æ•°æ®åŠ è½½
    logger.info("Loading CIFAR-100 dataset...")
    train_loader, test_loader = get_dataloaders(
        data_dir=args.data_dir, batch_size=args.batch_size, augment=not args.no_augment
    )

    # ä¿å­˜å®éªŒé…ç½®ï¼ˆåŒ…å«æ¨èé…ç½®ï¼‰
    config_file = save_experiment_config(save_dir, args, count_parameters(model), model_name)
    
    # åŒæ—¶ä¿å­˜æ¨èé…ç½®
    recommended_config_file = save_dir / "recommended_config.json"
    with open(recommended_config_file, 'w', encoding='utf-8') as f:
        json.dump(training_config, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Experiment config saved to: {config_file}")
    logger.info(f"Recommended config saved to: {recommended_config_file}")

    # åˆ·æ–°æ§åˆ¶å°æ˜¾ç¤º
    logger.flush_console()

    # å¼€å§‹è®­ç»ƒ
    logger.info(f"Starting training for {epochs} epochs...")
    trainer = Trainer(model, device, save_dir, verbose=args.verbose)
    
    try:
        history = trainer.fit(
            train_loader,
            test_loader,
            epochs=epochs,
            lr=lr,
            optimizer_type=optimizer_type,
            weight_decay=weight_decay,
        )
        
        # è®­ç»ƒå®Œæˆåçš„å¤„ç†
        logger.info("Training completed successfully!")
        logger.info(f"Best test accuracy: {trainer.best_acc:.2f}%")
        
        # ç”Ÿæˆè®­ç»ƒæ›²çº¿
        trainer.plot_curves(save_dir / "training_curves.png")
        
        # å¯¼å‡ºæ¨¡å‹
        onnx_path = trainer.export_model(model_name=model_name, input_size=(1, 3, 32, 32))
        script_path = trainer.export_torchscript(model_name=model_name, input_size=(1, 3, 32, 32))
        summary_path = trainer.save_model_summary(model_name=model_name)
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results = {
            "model": model_name,
            "best_accuracy": trainer.best_acc,
            "final_train_accuracy": history['train_acc'][-1],
            "final_test_accuracy": history['test_acc'][-1],
            "total_epochs": epochs,
            "actual_lr": lr,
            "actual_optimizer": optimizer_type,
            "actual_weight_decay": weight_decay,
            "recommended_config": training_config,
            "parameters": count_parameters(model),
            "training_time": time.time() - trainer.start_time if hasattr(trainer, 'start_time') else None
        }
        
        results_file = save_dir / "training_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Training results saved to: {results_file}")
        
        # æœ€ç»ˆåˆ·æ–°æ˜¾ç¤º
        logger.flush_console()
        
        return results
        
    except Exception as e:
        logger.error(f"Training failed for {model_name}: {str(e)}")
        return None


def main():
    parser = argparse.ArgumentParser(
        description="Deep Learning Training Framework for CIFAR-100"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="resnet20",
        help="Model architecture to train (or 'all' for batch training)",
    )
    parser.add_argument(
        "--models",
        nargs="+",
        help="Multiple models to train (alternative to --model)",
    )
    parser.add_argument(
        "--epochs", type=int, default=200, help="Number of training epochs"
    )
    parser.add_argument(
        "--batch_size", type=int, default=128, help="Batch size for training"
    )
    parser.add_argument(
        "--lr",
        type=float,
        default=None,
        help="Initial learning rate (auto-selected if not specified)",
    )
    parser.add_argument(
        "--optimizer",
        type=str,
        default=None,
        choices=["sgd", "adamw"],
        help="Optimizer type (auto-selected if not specified)",
    )
    parser.add_argument(
        "--weight_decay", type=float, default=5e-4, help="Weight decay coefficient"
    )
    parser.add_argument(
        "--data_dir", type=str, default="./data", help="Directory for dataset"
    )
    parser.add_argument(
        "--save_dir",
        type=str,
        default="./checkpoints",
        help="Directory to save checkpoints",
    )
    parser.add_argument(
        "--no_augment", action="store_true", help="Disable data augmentation"
    )
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")

    args = parser.parse_args()

    # æ£€æŸ¥ä¾èµ–
    if not HAS_TORCHINFO and not HAS_TORCHSUMMARY:
        print("Warning: Neither torchinfo nor torchsummary is installed.")
        print("Install one for better model architecture display:")
        print("  pip install torchinfo  (recommended)")
        print("  pip install torchsummary")
        print()

    # æ›´æ–°çš„æ¨¡å‹åˆ—è¡¨
    all_models = [
        # åŸºç¡€æ¨¡å‹
        "resnet20", "resnet32", "resnet56", "resnet20_slim", "resnet32_slim",
        # æ”¹è¿›æ¨¡å‹
        "improved_resnet20_v2",
        # CIFARä¼˜åŒ–ConvNeXt
        "convnext_micro", "convnext_nano", "convnext_tiny_cifar", "convnext_small_cifar",
        # åŸç‰ˆConvNeXt
        "convnext_tiny",
    ]
    
    # é¢„å®šä¹‰çš„æ¨¡å‹ç»„åˆ
    model_groups = {
        "all": ["resnet20", "improved_resnet20_v2", "convnext_micro", "convnext_nano"],
        "resnet_all": ["resnet20", "resnet32", "resnet56", "resnet20_slim", "resnet32_slim"],
        "improved_all": ["improved_resnet20_v2"],
        "convnext_all": ["convnext_micro", "convnext_nano", "convnext_tiny_cifar", "convnext_small_cifar"],
        "convnext_recommended": ["convnext_micro", "convnext_nano"],
        "best_models": ["resnet20", "improved_resnet20_v2", "convnext_micro", "convnext_nano"],
    }
    
    if args.models:
        models_to_train = args.models
    elif args.model in model_groups:
        models_to_train = model_groups[args.model]
    else:
        models_to_train = [args.model]

    # éªŒè¯æ¨¡å‹åç§°
    available_options = list(set(all_models + list(model_groups.keys())))
    invalid_models = [m for m in models_to_train if m not in all_models]
    if invalid_models:
        print(f"Error: Invalid model names: {invalid_models}")
        print(f"Available models: {all_models}")
        print(f"Available groups: {list(model_groups.keys())}")
        return

    # åˆ›å»ºä¸»æ—¥å¿—ç›®å½•
    main_save_dir = Path(args.save_dir)
    main_save_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"{'='*80}")
    print(f"{'CIFAR-100 Training Framework':^80}")
    print(f"{'='*80}")
    print(f"Models to train: {models_to_train}")
    print(f"Total models: {len(models_to_train)}")
    print(f"Architecture tool: {'torchinfo' if HAS_TORCHINFO else 'torchsummary' if HAS_TORCHSUMMARY else 'basic'}")
    
    # æ˜¾ç¤ºæ¨¡å‹æ¨èä¿¡æ¯
    print(f"\nModel Recommendations:")
    recommendations = {
        'convnext_micro': 'Best choice - balanced performance and stability',
        'convnext_nano': 'Excellent performance with moderate complexity',
        'improved_resnet20_v2': 'Good ResNet improvement',
        'resnet20': 'Baseline for comparison',
        'convnext_tiny': 'WARNING: May overfit on CIFAR-100',
    }
    
    for model_name in models_to_train:
        rec = recommendations.get(model_name, 'Standard model')
        print(f"  - {model_name}: {rec}")
    
    # æ‰¹é‡è®­ç»ƒ
    all_results = []
    successful_trains = 0
    
    for i, model_name in enumerate(models_to_train, 1):
        print(f"\n{'='*80}")
        print(f"Training {i}/{len(models_to_train)}: {model_name}")
        print(f"{'='*80}")
        
        result = train_single_model(model_name, args)
        
        if result:
            all_results.append(result)
            successful_trains += 1
            print(f"[OK] {model_name} training completed successfully!")
        else:
            print(f"[FAIL] {model_name} training failed!")
    
    # ä¿å­˜æ‰¹é‡è®­ç»ƒæ€»ç»“
    summary = {
        "total_models": len(models_to_train),
        "successful_trains": successful_trains,
        "failed_trains": len(models_to_train) - successful_trains,
        "models_trained": models_to_train,
        "results": all_results,
        "timestamp": datetime.now().isoformat(),
        "framework_version": "CIFAR-100 Optimized v1.0"
    }
    
    summary_file = main_save_dir / "batch_training_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # æ¸…å±å¹¶æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"{'='*80}")
    print(f"{'Training Summary':^80}")
    print(f"{'='*80}")
    print(f"Total models: {len(models_to_train)}")
    print(f"Successful: {successful_trains}")
    print(f"Failed: {len(models_to_train) - successful_trains}")
    
    if all_results:
        print(f"\nResults Summary (sorted by accuracy):")
        sorted_results = sorted(all_results, key=lambda x: x['best_accuracy'], reverse=True)
        for i, result in enumerate(sorted_results, 1):
            params = result['parameters']
            acc = result['best_accuracy']
            print(f"{i:2d}. {result['model']:<25} {acc:6.2f}% ({params:5.2f}M params)")
    
    print(f"\nFiles saved:")
    print(f"|- Summary: {summary_file}")
    print(f"|- Individual logs: {main_save_dir / 'logs'}")
    print(f"|- Model checkpoints: {main_save_dir / '[model_name]'}")
    
    if not HAS_TORCHINFO:
        print(f"\nTip: Install torchinfo for better model display:")
        print(f"  pip install torchinfo")
    
    print(f"\nModel Groups Available:")
    for group, models in model_groups.items():
        print(f"  --model {group}: {models}")
    
    print(f"{'='*80}")


if __name__ == "__main__":
    main()