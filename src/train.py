import torch
import argparse
from pathlib import Path
import sys
import os
from tqdm import tqdm
import time
import logging
import json
from datetime import datetime
import io
from contextlib import redirect_stdout, redirect_stderr

# å°è¯•å¯¼å…¥æ¨¡å‹æ¶æ„æ‰“å°å·¥å…·
try:
    from torchinfo import summary as torchinfo_summary
    HAS_TORCHINFO = True
except ImportError:
    HAS_TORCHINFO = False

try:
    from torchsummary import summary as torchsummary_summary
    HAS_TORCHSUMMARY = True
except ImportError:
    HAS_TORCHSUMMARY = False

from models import (
    resnet20,
    resnet32,
    resnet56,
    resnet20_slim,
    resnet32_slim,
    improved_resnet20_v1,
    improved_resnet20_v2,
    improved_resnet20_v3,
    improved_resnet20_v4,
    convnext_tiny,
    convnext_small,
    convnext_base,
    convnext_large,
    count_parameters,
)
from dataset import get_dataloaders
from trainer import Trainer


class ModelLogger:
    """ç‹¬ç«‹çš„æ¨¡å‹æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, save_dir, model_name):
        self.save_dir = save_dir
        self.model_name = model_name
        self.log_dir = save_dir / "logs"
        self.log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.log_dir / f"{model_name}_{timestamp}.log"
        
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(f"{model_name}_{timestamp}")
        self.logger.setLevel(logging.INFO)
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        
        # æ§åˆ¶å°è¾“å‡ºç¼“å†²
        self.console_buffer = []
    
    def info(self, message):
        """è®°å½•ä¿¡æ¯ï¼Œå¤„ç†Unicodeå­—ç¬¦"""
        # æ›¿æ¢é—®é¢˜å­—ç¬¦
        safe_message = self._safe_unicode(message)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        self.logger.info(safe_message)
        
        # æ·»åŠ åˆ°æ§åˆ¶å°ç¼“å†²
        self.console_buffer.append(safe_message)
    
    def error(self, message):
        """è®°å½•é”™è¯¯"""
        safe_message = self._safe_unicode(message)
        self.logger.error(safe_message)
        self.console_buffer.append(f"ERROR: {safe_message}")
    
    def _safe_unicode(self, message):
        """å¤„ç†Unicodeå­—ç¬¦"""
        replacements = {
            'âœ“': '[OK]',
            'âœ—': '[FAIL]', 
            'ğŸ‰': '[BEST]',
            'â”œ': '|-',
            'â””': '`-',
            'â†’': '->',
            'Ã—': 'x'
        }
        
        for old, new in replacements.items():
            message = message.replace(old, new)
        
        return message
    
    def flush_console(self):
        """åˆ·æ–°æ§åˆ¶å°è¾“å‡º"""
        if self.console_buffer:
            # æ¸…å±å¹¶æ˜¾ç¤ºå½“å‰æ¨¡å‹çš„æ—¥å¿—
            os.system('cls' if os.name == 'nt' else 'clear')
            print(f"{'='*80}")
            print(f"Training Model: {self.model_name}")
            print(f"{'='*80}")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—
            for line in self.console_buffer[-50:]:  # åªæ˜¾ç¤ºæœ€è¿‘50è¡Œ
                print(line)
            
            print(f"{'='*80}")
    
    def clear_buffer(self):
        """æ¸…ç©ºæ§åˆ¶å°ç¼“å†²"""
        self.console_buffer = []


def get_model_architecture(model, model_name, input_size=(1, 3, 32, 32)):
    """è·å–æ¨¡å‹æ¶æ„ä¿¡æ¯"""
    arch_info = []
    
    # åŸºæœ¬ä¿¡æ¯
    total_params = count_parameters(model)
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    arch_info.extend([
        f"Model: {model_name}",
        f"Total Parameters: {total_params:.2f}M",
        f"Trainable Parameters: {trainable_params/1e6:.2f}M",
        f"Model Size (approx): {total_params * 4:.2f} MB",
        ""
    ])
    
    # å°è¯•ä½¿ç”¨ torchinfo - ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹å®ä¾‹
    if HAS_TORCHINFO:
        try:
            arch_info.append("Model Architecture (torchinfo):")
            arch_info.append("-" * 60)
            
            # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Šè¿›è¡Œsummaryï¼ˆé¿å…è®¾å¤‡é—®é¢˜ï¼‰
            model_for_summary = model.cpu()
            model_for_summary.eval()
            
            # ä½¿ç”¨ torchinfo è·å–è¯¦ç»†ä¿¡æ¯
            summary_str = str(torchinfo_summary(
                model_for_summary, 
                input_size=input_size,
                verbose=0,
                col_names=["input_size", "output_size", "num_params", "kernel_size"],
                row_settings=["var_names"],
                device='cpu'
            ))
            
            # åˆ†è¡Œæ·»åŠ 
            for line in summary_str.split('\n'):
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    arch_info.append(line)
            
            arch_info.append("-" * 60)
            
        except Exception as e:
            arch_info.extend([
                f"torchinfo failed: {str(e)}",
                "Falling back to torchsummary or basic info..."
            ])
    
    # å¦‚æœ torchinfo å¤±è´¥ï¼Œå°è¯• torchsummary
    if (not HAS_TORCHINFO or "failed" in arch_info[-2]) and HAS_TORCHSUMMARY:
        try:
            arch_info.append("Model Architecture (torchsummary):")
            arch_info.append("-" * 60)
            
            # ç¡®ä¿æ¨¡å‹åœ¨CPUä¸Š
            model_for_summary = model.cpu()
            model_for_summary.eval()
            
            # åˆ›å»ºå­—ç¬¦ä¸²ç¼“å†²åŒº
            old_stdout = sys.stdout
            sys.stdout = buffer = io.StringIO()
            
            # è°ƒç”¨ torchsummary
            torchsummary_summary(model_for_summary, input_size[1:])  # ä¸åŒ…æ‹¬batchç»´åº¦
            
            # æ¢å¤stdoutå¹¶è·å–è¾“å‡º
            sys.stdout = old_stdout
            summary_output = buffer.getvalue()
            
            # æ·»åŠ è¾“å‡ºåˆ°æ¶æ„ä¿¡æ¯
            for line in summary_output.split('\n'):
                if line.strip():
                    arch_info.append(line)
            
            arch_info.append("-" * 60)
            
        except Exception as e:
            arch_info.extend([
                f"torchsummary failed: {str(e)}",
                "Using basic architecture info..."
            ])
        finally:
            sys.stdout = old_stdout
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œæˆ–è€…éƒ½æ²¡æœ‰ï¼Œä½¿ç”¨åŸºæœ¬çš„æ¨¡å‹å­—ç¬¦ä¸²è¡¨ç¤º
    if (not HAS_TORCHINFO and not HAS_TORCHSUMMARY) or "failed" in str(arch_info):
        arch_info.extend([
            "",
            "Model Architecture (basic representation):",
            "-" * 60
        ])
        
        # è·å–æ¨¡å‹çš„å­—ç¬¦ä¸²è¡¨ç¤º
        model_str = str(model)
        lines = model_str.split('\n')
        
        # æ˜¾ç¤ºæ¨¡å‹ç»“æ„ï¼Œä½†é™åˆ¶è¡Œæ•°
        for i, line in enumerate(lines):
            if i > 30:  # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°
                arch_info.append(f"... (truncated, {len(lines) - i} more lines)")
                break
            arch_info.append(line)
        
        arch_info.extend([
            "",
            "For detailed architecture info, install:",
            "  pip install torchinfo  (recommended)",
            "  pip install torchsummary",
            "-" * 60
        ])
    
    return arch_info


def get_simple_model_info(model, model_name):
    """è·å–ç®€åŒ–çš„æ¨¡å‹ä¿¡æ¯ï¼ˆç”¨äºå¿«é€Ÿæ˜¾ç¤ºï¼‰"""
    total_params = count_parameters(model)
    
    # æ ¹æ®æ¨¡å‹ç±»å‹æä¾›ç®€è¦æè¿°
    if "resnet" in model_name and "improved" not in model_name:
        if "20" in model_name:
            desc = "ResNet-20: 3 layers x 3 blocks each"
        elif "32" in model_name:
            desc = "ResNet-32: 3 layers x 5 blocks each"
        elif "56" in model_name:
            desc = "ResNet-56: 3 layers x 9 blocks each"
        else:
            desc = "ResNet variant"
            
        if "slim" in model_name:
            desc += " (0.5x channels)"
    
    elif "improved" in model_name:
        base_desc = "Enhanced ResNet-20"
        if "v1" in model_name:
            desc = f"{base_desc} v1: 7x7 kernels for larger receptive field"
        elif "v2" in model_name:
            desc = f"{base_desc} v2: Depthwise conv + Inverted bottleneck"
        elif "v3" in model_name:
            desc = f"{base_desc} v3: LayerNorm + GELU + Layer Scale + Drop Path"
        elif "v4" in model_name:
            desc = f"{base_desc} v4: ConvNeXt-inspired design"
        else:
            desc = f"{base_desc}: Advanced improvements"
    
    elif "convnext" in model_name:
        if "tiny" in model_name:
            desc = "ConvNeXt-Tiny: [2,2,6,2] blocks, [48,96,192,384] dims"
        elif "small" in model_name:
            desc = "ConvNeXt-Small: [2,2,18,2] blocks, [48,96,192,384] dims"
        elif "base" in model_name:
            desc = "ConvNeXt-Base: [2,2,18,2] blocks, [64,128,256,512] dims"
        elif "large" in model_name:
            desc = "ConvNeXt-Large: [2,2,18,2] blocks, [96,192,384,768] dims"
        else:
            desc = "ConvNeXt variant: Modern CNN architecture"
    else:
        desc = "Custom model architecture"
    
    return [
        f"Model: {model_name}",
        f"Description: {desc}",
        f"Parameters: {total_params:.2f}M ({total_params*1e6:,.0f} total)",
        f"Model size: ~{total_params * 4:.1f} MB (FP32)",
        f"Input: 32x32x3 RGB -> Output: 100 classes (CIFAR-100)"
    ]


def print_layer_summary(model, model_name):
    """æ‰‹åŠ¨æ‰“å°æ¨¡å‹å±‚çš„ç®€è¦æ€»ç»“"""
    summary_lines = [
        "",
        f"Layer Summary for {model_name}:",
        "-" * 50
    ]
    
    total_params = 0
    layer_count = 0
    
    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # å¶å­èŠ‚ç‚¹
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                layer_count += 1
                total_params += params
                
                # è·å–å±‚ç±»å‹
                layer_type = type(module).__name__
                
                # è·å–å±‚çš„åŸºæœ¬ä¿¡æ¯
                if hasattr(module, 'in_features') and hasattr(module, 'out_features'):
                    info = f"{module.in_features} -> {module.out_features}"
                elif hasattr(module, 'in_channels') and hasattr(module, 'out_channels'):
                    kernel = getattr(module, 'kernel_size', 'N/A')
                    stride = getattr(module, 'stride', 'N/A')
                    info = f"{module.in_channels} -> {module.out_channels}, kernel={kernel}, stride={stride}"
                elif hasattr(module, 'num_features'):
                    info = f"features={module.num_features}"
                else:
                    info = "N/A"
                
                summary_lines.append(f"{layer_count:2d}. {name:<25} {layer_type:<15} {info:<25} {params:>8,} params")
    
    summary_lines.extend([
        "-" * 50,
        f"Total: {layer_count} layers, {total_params:,} parameters",
        ""
    ])
    
    return summary_lines


def get_default_lr_and_optimizer(model_name):
    """æ ¹æ®æ¨¡å‹ç±»å‹è¿”å›é»˜è®¤å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨è®¾ç½®"""
    if "convnext" in model_name:
        return 0.004, "adamw"
    elif "improved" in model_name and ("v3" in model_name or "v4" in model_name):
        return 0.001, "adamw"
    else:
        return 0.1, "sgd"


def save_experiment_config(save_dir, args, model_params, model_name):
    """ä¿å­˜å®éªŒé…ç½®"""
    config = {
        "model": model_name,
        "epochs": args.epochs,
        "batch_size": args.batch_size,
        "lr": args.lr,
        "optimizer": args.optimizer,
        "weight_decay": args.weight_decay,
        "data_augmentation": not args.no_augment,
        "model_parameters": model_params,
        "timestamp": datetime.now().isoformat()
    }
    
    config_file = save_dir / "experiment_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    return config_file


def test_model_forward(model, device, batch_size=2, logger=None):
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    logger.info("Testing model forward pass...")

    model = model.to(device)
    model.eval()
    test_input = torch.randn(batch_size, 3, 32, 32).to(device)

    try:
        start_time = time.time()
        with torch.no_grad():
            output = model(test_input)
        forward_time = time.time() - start_time

        logger.info(f"[OK] Forward pass successful")
        logger.info(f"|- Input shape: {list(test_input.shape)}")
        logger.info(f"|- Output shape: {list(output.shape)}")
        logger.info(f"|- Forward time: {forward_time*1000:.2f}ms")
        logger.info(f"`- Device: {next(model.parameters()).device}")
        
        return True
    except Exception as e:
        logger.error(f"[FAIL] Forward pass failed: {e}")
        logger.error(f"Model device: {next(model.parameters()).device}")
        logger.error(f"Input device: {test_input.device}")
        return False


def train_single_model(model_name, args):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹ä¸“ç”¨æ—¥å¿—è®°å½•å™¨
    save_dir = Path(args.save_dir) / model_name
    save_dir.mkdir(parents=True, exist_ok=True)
    
    logger = ModelLogger(Path(args.save_dir), model_name)
    
    logger.info("="*80)
    logger.info(f"Starting training for model: {model_name}")
    logger.info("="*80)
    
    # æ¨¡å‹åˆ›å»º
    model_dict = {
        "resnet20": resnet20,
        "resnet32": resnet32,
        "resnet56": resnet56,
        "resnet20_slim": resnet20_slim,
        "resnet32_slim": resnet32_slim,
        "improved_resnet20_v1": improved_resnet20_v1,
        "improved_resnet20_v2": improved_resnet20_v2,
        "improved_resnet20_v3": improved_resnet20_v3,
        "improved_resnet20_v4": improved_resnet20_v4,
        "convnext_tiny": convnext_tiny,
        "convnext_small": convnext_small,
        "convnext_base": convnext_base,
        "convnext_large": convnext_large,
    }

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    logger.info(f"Creating model: {model_name}")
    model = model_dict[model_name]()
    
    # é¦–å…ˆæ˜¾ç¤ºç®€è¦ä¿¡æ¯
    simple_info = get_simple_model_info(model, model_name)
    for line in simple_info:
        logger.info(line)
    
    # æ‰‹åŠ¨æ‰“å°å±‚æ€»ç»“
    layer_summary = print_layer_summary(model, model_name)
    for line in layer_summary:
        logger.info(line)
    
    # å°è¯•è·å–è¯¦ç»†çš„æ¨¡å‹æ¶æ„ä¿¡æ¯
    if HAS_TORCHINFO or HAS_TORCHSUMMARY:
        logger.info("Getting detailed architecture...")
        try:
            arch_info = get_model_architecture(model, model_name)
            for line in arch_info:
                logger.info(line)
        except Exception as e:
            logger.error(f"Failed to get detailed architecture: {e}")
            logger.info("Continuing with basic model info...")
    
    # è·å–ä¼˜åŒ–å™¨è®¾ç½®
    if args.lr is None or args.optimizer is None:
        default_lr, default_optimizer = get_default_lr_and_optimizer(model_name)
        lr = args.lr if args.lr is not None else default_lr
        optimizer_type = args.optimizer if args.optimizer is not None else default_optimizer
    else:
        lr = args.lr
        optimizer_type = args.optimizer
    
    logger.info("")
    logger.info(f"Training Configuration:")
    logger.info(f"|- Learning Rate: {lr}")
    logger.info(f"|- Optimizer: {optimizer_type}")
    logger.info(f"|- Weight Decay: {args.weight_decay}")
    logger.info(f"|- Batch Size: {args.batch_size}")
    logger.info(f"|- Epochs: {args.epochs}")

    # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    if not test_model_forward(model, device, args.batch_size, logger):
        logger.error("Model forward pass test failed. Skipping...")
        return None

    # æ•°æ®åŠ è½½
    logger.info("Loading CIFAR-100 dataset...")
    train_loader, test_loader = get_dataloaders(
        data_dir=args.data_dir, batch_size=args.batch_size, augment=not args.no_augment
    )

    # ä¿å­˜å®éªŒé…ç½®
    config_file = save_experiment_config(save_dir, args, count_parameters(model), model_name)
    logger.info(f"Experiment config saved to: {config_file}")

    # åˆ·æ–°æ§åˆ¶å°æ˜¾ç¤º
    logger.flush_console()

    # å¼€å§‹è®­ç»ƒ
    logger.info(f"Starting training for {args.epochs} epochs...")
    trainer = Trainer(model, device, save_dir, verbose=args.verbose)
    
    try:
        history = trainer.fit(
            train_loader,
            test_loader,
            epochs=args.epochs,
            lr=lr,
            optimizer_type=optimizer_type,
            weight_decay=args.weight_decay,
        )
        
        # è®­ç»ƒå®Œæˆåçš„å¤„ç†
        logger.info("Training completed successfully!")
        logger.info(f"Best test accuracy: {trainer.best_acc:.2f}%")
        
        # ç”Ÿæˆè®­ç»ƒæ›²çº¿
        trainer.plot_curves(save_dir / "training_curves.png")
        
        # å¯¼å‡ºæ¨¡å‹
        onnx_path = trainer.export_model(model_name=model_name, input_size=(1, 3, 32, 32))
        script_path = trainer.export_torchscript(model_name=model_name, input_size=(1, 3, 32, 32))
        summary_path = trainer.save_model_summary(model_name=model_name)
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results = {
            "model": model_name,
            "best_accuracy": trainer.best_acc,
            "final_train_accuracy": history['train_acc'][-1],
            "final_test_accuracy": history['test_acc'][-1],
            "total_epochs": args.epochs,
            "parameters": count_parameters(model),
            "training_time": time.time() - trainer.start_time if hasattr(trainer, 'start_time') else None
        }
        
        results_file = save_dir / "training_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Training results saved to: {results_file}")
        
        # æœ€ç»ˆåˆ·æ–°æ˜¾ç¤º
        logger.flush_console()
        
        return results
        
    except Exception as e:
        logger.error(f"Training failed for {model_name}: {str(e)}")
        return None


def main():
    parser = argparse.ArgumentParser(
        description="Deep Learning Training Framework for CIFAR-100"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="resnet20",
        help="Model architecture to train (or 'all' for batch training)",
    )
    parser.add_argument(
        "--models",
        nargs="+",
        help="Multiple models to train (alternative to --model)",
    )
    parser.add_argument(
        "--epochs", type=int, default=200, help="Number of training epochs"
    )
    parser.add_argument(
        "--batch_size", type=int, default=128, help="Batch size for training"
    )
    parser.add_argument(
        "--lr",
        type=float,
        default=None,
        help="Initial learning rate (auto-selected if not specified)",
    )
    parser.add_argument(
        "--optimizer",
        type=str,
        default=None,
        choices=["sgd", "adamw"],
        help="Optimizer type (auto-selected if not specified)",
    )
    parser.add_argument(
        "--weight_decay", type=float, default=5e-4, help="Weight decay coefficient"
    )
    parser.add_argument(
        "--data_dir", type=str, default="./data", help="Directory for dataset"
    )
    parser.add_argument(
        "--save_dir",
        type=str,
        default="./checkpoints",
        help="Directory to save checkpoints",
    )
    parser.add_argument(
        "--no_augment", action="store_true", help="Disable data augmentation"
    )
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")

    args = parser.parse_args()

    # æ£€æŸ¥ä¾èµ–
    if not HAS_TORCHINFO and not HAS_TORCHSUMMARY:
        print("Warning: Neither torchinfo nor torchsummary is installed.")
        print("Install one for better model architecture display:")
        print("  pip install torchinfo  (recommended)")
        print("  pip install torchsummary")
        print()

    # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
    all_models = [
        "resnet20",
        "improved_resnet20_v1", "improved_resnet20_v2", "improved_resnet20_v3", "improved_resnet20_v4",
        "convnext_tiny",
    ]
    
    if args.models:
        models_to_train = args.models
    elif args.model == "all":
        models_to_train = ["resnet20", "convnext_tiny", "improved_resnet20_v1", "improved_resnet20_v2", "improved_resnet20_v3", "improved_resnet20_v4"]
    elif args.model == "resnet_all":
        models_to_train = ["resnet20", "resnet32", "resnet56", "resnet20_slim", "resnet32_slim"]
    elif args.model == "improved_all":
        models_to_train = ["improved_resnet20_v1", "improved_resnet20_v2", "improved_resnet20_v3", "improved_resnet20_v4"]
    elif args.model == "convnext_all":
        models_to_train = ["convnext_tiny", "convnext_small", "convnext_base", "convnext_large"]
    else:
        models_to_train = [args.model]

    # éªŒè¯æ¨¡å‹åç§°
    available_models = list(set(all_models + ["all", "resnet_all", "improved_all", "convnext_all"]))
    invalid_models = [m for m in models_to_train if m not in all_models]
    if invalid_models:
        print(f"Error: Invalid model names: {invalid_models}")
        print(f"Available models: {available_models}")
        return

    # åˆ›å»ºä¸»æ—¥å¿—ç›®å½•
    main_save_dir = Path(args.save_dir)
    main_save_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"{'='*80}")
    print(f"{'Batch Training Started':^80}")
    print(f"{'='*80}")
    print(f"Models to train: {models_to_train}")
    print(f"Total models: {len(models_to_train)}")
    print(f"Architecture tool: {'torchinfo' if HAS_TORCHINFO else 'torchsummary' if HAS_TORCHSUMMARY else 'basic'}")
    
    # æ‰¹é‡è®­ç»ƒ
    all_results = []
    successful_trains = 0
    
    for i, model_name in enumerate(models_to_train, 1):
        print(f"\n{'='*80}")
        print(f"Training {i}/{len(models_to_train)}: {model_name}")
        print(f"{'='*80}")
        
        result = train_single_model(model_name, args)
        
        if result:
            all_results.append(result)
            successful_trains += 1
            print(f"[OK] {model_name} training completed successfully!")
        else:
            print(f"[FAIL] {model_name} training failed!")
    
    # ä¿å­˜æ‰¹é‡è®­ç»ƒæ€»ç»“
    summary = {
        "total_models": len(models_to_train),
        "successful_trains": successful_trains,
        "failed_trains": len(models_to_train) - successful_trains,
        "models_trained": models_to_train,
        "results": all_results,
        "timestamp": datetime.now().isoformat()
    }
    
    summary_file = main_save_dir / "batch_training_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # æ¸…å±å¹¶æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"{'='*80}")
    print(f"{'Batch Training Summary':^80}")
    print(f"{'='*80}")
    print(f"Total models: {len(models_to_train)}")
    print(f"Successful: {successful_trains}")
    print(f"Failed: {len(models_to_train) - successful_trains}")
    
    if all_results:
        print(f"\nResults Summary:")
        for result in sorted(all_results, key=lambda x: x['best_accuracy'], reverse=True):
            print(f"|- {result['model']}: {result['best_accuracy']:.2f}%")
    
    print(f"\nSummary saved to: {summary_file}")
    print(f"Individual logs saved in: {main_save_dir / 'logs'}")
    if not HAS_TORCHINFO:
        print(f"Tip: Install torchinfo for better model display: pip install torchinfo")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()