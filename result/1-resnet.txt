----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 16, 32, 32]           2,304
       BatchNorm2d-5           [-1, 16, 32, 32]              32
              ReLU-6           [-1, 16, 32, 32]               0
            Conv2d-7           [-1, 16, 32, 32]           2,304
       BatchNorm2d-8           [-1, 16, 32, 32]              32
              ReLU-9           [-1, 16, 32, 32]               0
       BasicBlock-10           [-1, 16, 32, 32]               0
           Conv2d-11           [-1, 16, 32, 32]           2,304
      BatchNorm2d-12           [-1, 16, 32, 32]              32
             ReLU-13           [-1, 16, 32, 32]               0
           Conv2d-14           [-1, 16, 32, 32]           2,304
      BatchNorm2d-15           [-1, 16, 32, 32]              32
             ReLU-16           [-1, 16, 32, 32]               0
       BasicBlock-17           [-1, 16, 32, 32]               0
           Conv2d-18           [-1, 16, 32, 32]           2,304
      BatchNorm2d-19           [-1, 16, 32, 32]              32
             ReLU-20           [-1, 16, 32, 32]               0
           Conv2d-21           [-1, 16, 32, 32]           2,304
      BatchNorm2d-22           [-1, 16, 32, 32]              32
             ReLU-23           [-1, 16, 32, 32]               0
       BasicBlock-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 32, 16, 16]           4,608
      BatchNorm2d-26           [-1, 32, 16, 16]              64
             ReLU-27           [-1, 32, 16, 16]               0
           Conv2d-28           [-1, 32, 16, 16]           9,216
      BatchNorm2d-29           [-1, 32, 16, 16]              64
           Conv2d-30           [-1, 32, 16, 16]             512
      BatchNorm2d-31           [-1, 32, 16, 16]              64
             ReLU-32           [-1, 32, 16, 16]               0
       BasicBlock-33           [-1, 32, 16, 16]               0
           Conv2d-34           [-1, 32, 16, 16]           9,216
      BatchNorm2d-35           [-1, 32, 16, 16]              64
             ReLU-36           [-1, 32, 16, 16]               0
           Conv2d-37           [-1, 32, 16, 16]           9,216
      BatchNorm2d-38           [-1, 32, 16, 16]              64
             ReLU-39           [-1, 32, 16, 16]               0
       BasicBlock-40           [-1, 32, 16, 16]               0
           Conv2d-41           [-1, 32, 16, 16]           9,216
      BatchNorm2d-42           [-1, 32, 16, 16]              64
             ReLU-43           [-1, 32, 16, 16]               0
           Conv2d-44           [-1, 32, 16, 16]           9,216
      BatchNorm2d-45           [-1, 32, 16, 16]              64
             ReLU-46           [-1, 32, 16, 16]               0
       BasicBlock-47           [-1, 32, 16, 16]               0
           Conv2d-48             [-1, 64, 8, 8]          18,432
      BatchNorm2d-49             [-1, 64, 8, 8]             128
             ReLU-50             [-1, 64, 8, 8]               0
           Conv2d-51             [-1, 64, 8, 8]          36,864
      BatchNorm2d-52             [-1, 64, 8, 8]             128
           Conv2d-53             [-1, 64, 8, 8]           2,048
      BatchNorm2d-54             [-1, 64, 8, 8]             128
             ReLU-55             [-1, 64, 8, 8]               0
       BasicBlock-56             [-1, 64, 8, 8]               0
           Conv2d-57             [-1, 64, 8, 8]          36,864
      BatchNorm2d-58             [-1, 64, 8, 8]             128
             ReLU-59             [-1, 64, 8, 8]               0
           Conv2d-60             [-1, 64, 8, 8]          36,864
      BatchNorm2d-61             [-1, 64, 8, 8]             128
             ReLU-62             [-1, 64, 8, 8]               0
       BasicBlock-63             [-1, 64, 8, 8]               0
           Conv2d-64             [-1, 64, 8, 8]          36,864
      BatchNorm2d-65             [-1, 64, 8, 8]             128
             ReLU-66             [-1, 64, 8, 8]               0
           Conv2d-67             [-1, 64, 8, 8]          36,864
      BatchNorm2d-68             [-1, 64, 8, 8]             128
             ReLU-69             [-1, 64, 8, 8]               0
       BasicBlock-70             [-1, 64, 8, 8]               0
AdaptiveAvgPool2d-71             [-1, 64, 1, 1]               0
           Linear-72                  [-1, 100]           6,500
================================================================
Total params: 278,324
Trainable params: 278,324
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.16
Params size (MB): 1.06
Estimated Total Size (MB): 6.23
----------------------------------------------------------------
Model: None
Start training resnet20 ...
Epoch 1: Train Loss=4.1016  Acc=6.81%
Epoch 2: Train Loss=3.4935  Acc=16.01%
Epoch 3: Train Loss=3.0975  Acc=23.20%
Epoch 4: Train Loss=2.7883  Acc=28.95%
Epoch 5: Train Loss=2.5519  Acc=33.85%
Epoch 6: Train Loss=2.3795  Acc=37.28%
Epoch 7: Train Loss=2.2528  Acc=40.06%
Epoch 8: Train Loss=2.1557  Acc=42.69%
Epoch 9: Train Loss=2.0813  Acc=43.89%
Epoch 10: Train Loss=2.0155  Acc=45.41%
resnet20 Final Test Accuracy: 42.00%
resnet20 Training Time: 59.05 minutes